{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp format\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Iterable, Union, Tuple\n",
    "from pathlib import Path\n",
    "from decimal import Decimal\n",
    "\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from fastcore.utils import listify\n",
    "\n",
    "from extracao.constants import BW, BW_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação\n",
    "\n",
    "> Este módulo possui funções auxiliares de formatação dos dados das várias fontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def input_coordenates(df: pd.DataFrame, # DataFrame a imputar coordenadas inválidas\n",
    "                      pasta: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Imputa os registros com coordenadas ausentes (NA's) com as coordenadas do município\"\"\"\n",
    "    municipios = Path(f\"{pasta}/municípios.fth\")\n",
    "    if not municipios.exists():\n",
    "        municipios = Path(f\"{pasta}/municípios.xlsx\")\n",
    "        if not municipios.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"É necessario a tabela de municípios municípios.fth | municípios.xlsx na pasta {pasta}\"\n",
    "            )\n",
    "        m = pd.read_excel(municipios, engine=\"openpyxl\")\n",
    "    else:\n",
    "        m = pd.read_feather(municipios)\n",
    "    m.loc[\n",
    "        m.Município == \"Sant'Ana do Livramento\", \"Município\"\n",
    "    ] = \"Santana do Livramento\"\n",
    "    m[\"Município\"] = m.Município.apply(unidecode).str.lower().str.replace(\"'\", \" \")\n",
    "    m[\"UF\"] = m.UF.str.lower()\n",
    "    df[\"Coordenadas_do_Município\"] = False\n",
    "    df[\"Latitude\"] = df.Latitude.str.replace(\",\", \".\")\n",
    "    df[\"Longitude\"] = df.Longitude.str.replace(\",\", \".\")\n",
    "    df.loc[df[\"Município\"] == \"Poxoréo\", \"Município\"] = \"Poxoréu\"\n",
    "    df.loc[df[\"Município\"] == \"Couto de Magalhães\", \"Município\"] = \"Couto Magalhães\"\n",
    "    df[\"Município\"] = df.Município.astype(\"string\")\n",
    "    criteria = (\n",
    "        (df.Latitude == \"\")\n",
    "        | (df.Latitude.isna())\n",
    "        | (df.Longitude == \"\")\n",
    "        | (df.Longitude.isna())\n",
    "    ) & df.Município.isna()\n",
    "    df = df[~criteria]\n",
    "    for row in df[\n",
    "        (\n",
    "            (df.Latitude == \"\")\n",
    "            | (df.Latitude.isna())\n",
    "            | (df.Longitude == \"\")\n",
    "            | (df.Longitude.isna())\n",
    "        )\n",
    "    ].itertuples():\n",
    "        try:\n",
    "            left = unidecode(row.Município).lower()\n",
    "            if m_coord := (m.loc[(m.Município == left) & (m.UF == row.UF.lower()), [\"Latitude\", \"Longitude\"],].values.flatten().tolist()):\n",
    "                df.loc[row.Index, \"Latitude\"] = m_coord[0]\n",
    "                df.loc[row.Index, \"Longitude\"] = m_coord[1]\n",
    "                df.loc[row.Index, \"Coordenadas_do_Município\"] = True\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_bw(bw: str, #Designação de Emissão (Largura + Classe) codificada como string\n",
    ") -> Tuple[float, str]: #Largura e Classe de Emissão\n",
    "    \"\"\"Parse the bandwidth string\"\"\"\n",
    "    if match := re.match(BW_pattern, bw):\n",
    "        multiplier = BW[match.group(2)]\n",
    "        if mantissa := match.group(3):\n",
    "            number = float(f\"{match.group(1)}.{mantissa}\")\n",
    "        else:\n",
    "            number = float(match.group(1))\n",
    "        classe = match.group(4)\n",
    "        return multiplier * number, classe\n",
    "    return -1, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos Tipos de dados\n",
    "A serem criados dataframes, normalmente a tipo de data é aquele com maior resolução possível, nem sempre isso é necessário, os arquivos de espectro mesmo possuem somente uma casa decimal, portanto um `float16` já é suficiente para armazená-los. As funções a seguir fazem essa otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_floats(df: pd.DataFrame, # DataFrame a ser otimizado\n",
    "exclude: Iterable[str] = None, # Colunas a serem excluidas da otimização\n",
    ")->pd.DataFrame: # DataFrame com as colunas do tipo `float` otimizadas\n",
    "    \"\"\"Otimiza os floats do dataframe para reduzir o uso de memória\"\"\"\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    floats = [c for c in floats if c not in listify(exclude)]\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_ints(df: pd.DataFrame, # Dataframe a ser otimizado\n",
    "exclude: Iterable[str] = None, # Colunas a serem excluidas da otimização\n",
    ")->pd.DataFrame: # DataFrame com as colunas do tipo `int` otimizadas\n",
    "    \"\"\"Otimiza os ints do dataframe para reduzir o uso de memória\"\"\"\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    ints = [c for c in ints if c not in listify(exclude)]\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_objects(\n",
    "    df: pd.DataFrame, # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[str] = None, # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None, # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame: # DataFrame com as colunas do tipo `object` otimizadas\n",
    "    \"\"\"Otimiza as colunas do tipo `object` no DataFrame para `category` ou `string` para reduzir a memória e tamanho de arquivo\"\"\"\n",
    "    exclude = listify(exclude)\n",
    "    datetime_features = listify(datetime_features)\n",
    "    for col in df.select_dtypes(\n",
    "        include=[\"object\", \"string\", \"category\"]\n",
    "    ).columns.tolist():\n",
    "        if col not in datetime_features:\n",
    "            if col in exclude:\n",
    "                continue\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                dtype = \"category\"\n",
    "            else:\n",
    "                dtype = \"string\"\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def df_optimize(\n",
    "    df: pd.DataFrame, # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[str] = None, # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None, # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame: # DataFrame com as colunas com tipos de dados otimizados\n",
    "    \"\"\"Função que encapsula as anteriores para otimizar os tipos de dados e reduzir o tamanho do arquivo e uso de memória\"\"\"\n",
    "    if datetime_features is None:\n",
    "        datetime_features = []\n",
    "    return optimize_floats(\n",
    "        optimize_ints(optimize_objects(df, datetime_features, exclude), exclude),\n",
    "        exclude,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def format_types(df: pd.DataFrame, # DataFrame a ser formatado\n",
    "                 stem: str = None, # Identificador do arquivo para otimização específica\n",
    ") -> pd.DataFrame:    # DataFrame formatado \n",
    "\n",
    "    \"\"\"Format the columns of a dataframe to string. Optimized when saving to parquet\"\"\"\n",
    "    if stem == \"stel\":\n",
    "        df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "        df.loc[df.Unidade == \"kHz\", \"Frequência\"] = df.loc[\n",
    "            df.Unidade == \"kHz\", \"Frequência\"\n",
    "        ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "        df.loc[df.Unidade == \"GHz\", \"Frequência\"] = df.loc[\n",
    "            df.Unidade == \"GHz\", \"Frequência\"\n",
    "        ].apply(lambda x: Decimal(x) * Decimal(1000))\n",
    "        df.drop(\"Unidade\", axis=1, inplace=True)\n",
    "    elif stem == \"radcom\":\n",
    "        a = df.Situação.isna()\n",
    "        df.loc[a, \"Classe\"] = df.loc[a, \"Fase\"]\n",
    "        df.loc[~a, \"Classe\"] = (\n",
    "            df.loc[~a, \"Fase\"].astype(\"string\")\n",
    "            + \"-\"\n",
    "            + df.loc[~a, \"Situação\"].astype(\"string\")\n",
    "        )\n",
    "        df.drop([\"Fase\", \"Situação\"], axis=1, inplace=True)\n",
    "\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anateldb')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
