{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp format\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Iterable, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.utils import listify\n",
    "from fastcore.xtras import Path\n",
    "from geopy.distance import geodesic\n",
    "from rich.progress import Progress\n",
    "from pyarrow import ArrowInvalid\n",
    "\n",
    "from extracao.constants import BW, BW_pattern\n",
    "\n",
    "RE_BW = re.compile(BW_pattern)\n",
    "\n",
    "MAX_DIST = 10  # Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _read_df(folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Lê o dataframe formado por folder / stem.[parquet.gzip | fth | xslx]\"\"\"\n",
    "    file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file)\n",
    "    except (ArrowInvalid, FileNotFoundError) as e:\n",
    "        raise e(f\"Error when reading {file}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação\n",
    "\n",
    "> Este módulo possui funções auxiliares de formatação dos dados das várias fontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_bw(\n",
    "    bw: str,  # Designação de Emissão (Largura + Classe) codificada como string\n",
    ") -> Tuple[str, str]:  # Largura e Classe de Emissão\n",
    "    \"\"\"Parse the bandwidth string\"\"\"\n",
    "    if match := re.match(RE_BW, bw):\n",
    "        multiplier = BW[match.group(2)]\n",
    "        if mantissa := match.group(3):\n",
    "            number = float(f\"{match.group(1)}.{mantissa}\")\n",
    "        else:\n",
    "            number = float(match.group(1))\n",
    "        classe = match.group(4)\n",
    "        return str(multiplier * number), str(classe)\n",
    "    return \"-1\", \"-1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclagem\n",
    "Função auxiliar para mesclar registros que são iguais das diversas bases, i.e. estão a uma distância menor que `MAX_DIST` e verificar a validade da mesclagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_close_rows(df_left, df_right):\n",
    "    \"\"\"Mescla os registros dos DataFrames `df_left` e `df_right` que estão a uma distância menor que MAX_DIST\"\"\"\n",
    "    df1 = df_left.copy().reset_index(drop=True)\n",
    "    df2 = df_right.copy().reset_index(drop=True)\n",
    "    columns = [\"Frequency\", \"Latitude\", \"Longitude\"]\n",
    "    for c in columns:\n",
    "        df1[c] = df1[c].astype(\"float\")\n",
    "        df2[c] = df2[c].astype(\"float\")\n",
    "    df1.sort_values(columns, inplace=True)\n",
    "    df2.sort_values(columns, inplace=True)\n",
    "    with Progress(transient=True, refresh_per_second=2) as progress:\n",
    "        task_left = progress.add_task(\n",
    "            \"[red]Iterando Tabela Principal...\", total=len(df1)\n",
    "        )\n",
    "        for left in df1.itertuples():\n",
    "            for right in df2[np.isclose(df2.Frequency, left.Frequency)].itertuples():\n",
    "                if (\n",
    "                    geodesic(\n",
    "                        (left.Latitude, left.Longitude),\n",
    "                        (right.Latitude, right.Longitude),\n",
    "                    ).km\n",
    "                    <= MAX_DIST\n",
    "                ):\n",
    "                    df1.loc[\n",
    "                        left.Index, \"Description\"\n",
    "                    ] = f\"{left.Description} | {right.Description}\"\n",
    "                    df2 = df2.drop(right.Index)\n",
    "                    break\n",
    "            progress.update(\n",
    "                task_left,\n",
    "                advance=1,\n",
    "                description=f\"[green] Comparando Frequências {left.Frequency}MHz\",\n",
    "            )\n",
    "        return pd.concat([df1, df2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extracao.reading import *\n",
    "from extracao.main import format_matlab\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "folder = Path.cwd().parent / 'dados'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = format_matlab(read_base(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Description</th>\n",
       "      <th>Service</th>\n",
       "      <th>Station</th>\n",
       "      <th>Class</th>\n",
       "      <th>BW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-22.662779</td>\n",
       "      <td>-43.476391</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1557670</td>\n",
       "      <td>J9E</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#2</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-23.709999</td>\n",
       "      <td>-46.273335</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1558412</td>\n",
       "      <td>J3E</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-23.441668</td>\n",
       "      <td>-46.590832</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1557823</td>\n",
       "      <td>J3E</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#4</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-22.926666</td>\n",
       "      <td>-43.264999</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>859761</td>\n",
       "      <td>J3E</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-22.774166</td>\n",
       "      <td>-47.004444</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>859753</td>\n",
       "      <td>J3E</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832361</th>\n",
       "      <td>#832362</td>\n",
       "      <td>148650.000</td>\n",
       "      <td>-2.509556</td>\n",
       "      <td>-44.294556</td>\n",
       "      <td>[MOS] L, FB, Apil Seguranca E Vigilancia Ltda ...</td>\n",
       "      <td>19</td>\n",
       "      <td>1011671368</td>\n",
       "      <td>F1D</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832362</th>\n",
       "      <td>#832363</td>\n",
       "      <td>4096125.000</td>\n",
       "      <td>-29.872139</td>\n",
       "      <td>-51.170582</td>\n",
       "      <td>[MOS] L, FX, Petroleo Brasileiro S/A Petrobras...</td>\n",
       "      <td>19</td>\n",
       "      <td>698585682</td>\n",
       "      <td>F7D</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832363</th>\n",
       "      <td>#832364</td>\n",
       "      <td>4265625.000</td>\n",
       "      <td>-29.876944</td>\n",
       "      <td>-51.170692</td>\n",
       "      <td>[MOS] L, FX, Petroleo Brasileiro S/A Petrobras...</td>\n",
       "      <td>19</td>\n",
       "      <td>698585704</td>\n",
       "      <td>F7D</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832364</th>\n",
       "      <td>#832365</td>\n",
       "      <td>4265625.000</td>\n",
       "      <td>-29.870222</td>\n",
       "      <td>-51.201305</td>\n",
       "      <td>[MOS] L, FX, Petroleo Brasileiro S/A Petrobras...</td>\n",
       "      <td>19</td>\n",
       "      <td>698801288</td>\n",
       "      <td>F7D</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832365</th>\n",
       "      <td>#832366</td>\n",
       "      <td>4265625.000</td>\n",
       "      <td>-29.867193</td>\n",
       "      <td>-51.185944</td>\n",
       "      <td>[MOS] L, FX, Petroleo Brasileiro S/A Petrobras...</td>\n",
       "      <td>19</td>\n",
       "      <td>698585690</td>\n",
       "      <td>F7D</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832366 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id    Frequency   Latitude  Longitude  \\\n",
       "0            #1        0.028 -22.662779 -43.476391   \n",
       "1            #2        0.030 -23.709999 -46.273335   \n",
       "2            #3        0.030 -23.441668 -46.590832   \n",
       "3            #4        0.030 -22.926666 -43.264999   \n",
       "4            #5        0.030 -22.774166 -47.004444   \n",
       "...         ...          ...        ...        ...   \n",
       "832361  #832362   148650.000  -2.509556 -44.294556   \n",
       "832362  #832363  4096125.000 -29.872139 -51.170582   \n",
       "832363  #832364  4265625.000 -29.876944 -51.170692   \n",
       "832364  #832365  4265625.000 -29.870222 -51.201305   \n",
       "832365  #832366  4265625.000 -29.867193 -51.185944   \n",
       "\n",
       "                                              Description  Service  \\\n",
       "0       [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19   \n",
       "1       [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19   \n",
       "2       [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19   \n",
       "3       [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19   \n",
       "4       [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19   \n",
       "...                                                   ...      ...   \n",
       "832361  [MOS] L, FB, Apil Seguranca E Vigilancia Ltda ...       19   \n",
       "832362  [MOS] L, FX, Petroleo Brasileiro S/A Petrobras...       19   \n",
       "832363  [MOS] L, FX, Petroleo Brasileiro S/A Petrobras...       19   \n",
       "832364  [MOS] L, FX, Petroleo Brasileiro S/A Petrobras...       19   \n",
       "832365  [MOS] L, FX, Petroleo Brasileiro S/A Petrobras...       19   \n",
       "\n",
       "           Station Class    BW  \n",
       "0          1557670   J9E   8.0  \n",
       "1          1558412   J3E   2.0  \n",
       "2          1557823   J3E   1.0  \n",
       "3           859761   J3E   0.5  \n",
       "4           859753   J3E   1.0  \n",
       "...            ...   ...   ...  \n",
       "832361  1011671368   F1D   7.6  \n",
       "832362   698585682   F7D  25.0  \n",
       "832363   698585704   F7D  25.0  \n",
       "832364   698801288   F7D  25.0  \n",
       "832365   698585690   F7D  25.0  \n",
       "\n",
       "[832366 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero = read_aero(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2cbab930a746e7b8b5f92b710c6610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h\r\u001b[1A\u001b[2K"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = merge_close_rows(base.iloc[-100:], aero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(base, aero, on=['Frequency'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(row):\n",
    "    return geodesic((row[0], row[1]), (row[2], row[3])).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = np.all(df[['Latitude_x', 'Longitude_x', 'Latitude_y', 'Longitude_y']].notna(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[condition, 'dist'] = df.loc[condition, ['Latitude_x', 'Longitude_x', 'Latitude_y', 'Longitude_y']].apply(distancia , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df.dist.notna()) & (df.dist <= MAX_DIST) \n",
    "df.loc[condition, 'Description_x'] = df.loc[condition, 'Description_x'] + ' | ' + df.loc[condition, 'Description_y']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884139, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(folder / 'mesclados_outer_join.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero.to_excel(folder / 'aero.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos Tipos de dados\n",
    "A serem criados dataframes, normalmente a tipo de data é aquele com maior resolução possível, nem sempre isso é necessário, os arquivos de espectro mesmo possuem somente uma casa decimal, portanto um `float16` já é suficiente para armazená-los. As funções a seguir fazem essa otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_floats(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    exclude: Iterable[str] = None,  # Colunas a serem excluidas da otimização\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `float` otimizadas\n",
    "    \"\"\"Otimiza os floats do dataframe para reduzir o uso de memória\"\"\"\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    floats = [c for c in floats if c not in listify(exclude)]\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_ints(\n",
    "    df: pd.DataFrame,  # Dataframe a ser otimizado\n",
    "    exclude: Iterable[str] = None,  # Colunas a serem excluidas da otimização\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `int` otimizadas\n",
    "    \"\"\"Otimiza os ints do dataframe para reduzir o uso de memória\"\"\"\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    ints = [c for c in ints if c not in listify(exclude)]\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def optimize_objects(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[\n",
    "        str\n",
    "    ] = None,  # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None,  # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `object` otimizadas\n",
    "    \"\"\"Otimiza as colunas do tipo `object` no DataFrame para `category` ou `string` para reduzir a memória e tamanho de arquivo\"\"\"\n",
    "    exclude = listify(exclude)\n",
    "    datetime_features = listify(datetime_features)\n",
    "    for col in df.select_dtypes(\n",
    "        include=[\"object\", \"string\", \"category\"]\n",
    "    ).columns.tolist():\n",
    "        if col not in datetime_features:\n",
    "            if col in exclude:\n",
    "                continue\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                dtype = \"category\"\n",
    "            else:\n",
    "                dtype = \"string\"\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def df_optimize(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[\n",
    "        str\n",
    "    ] = None,  # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None,  # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas com tipos de dados otimizados\n",
    "    \"\"\"Função que encapsula as anteriores para otimizar os tipos de dados e reduzir o tamanho do arquivo e uso de memória\"\"\"\n",
    "    if datetime_features is None:\n",
    "        datetime_features = []\n",
    "    return optimize_floats(\n",
    "        optimize_ints(optimize_objects(df, datetime_features, exclude), exclude),\n",
    "        exclude,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anateldb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9a7c55aa6622354e9444f8bdaee619181773912a468d6c0f51aee0fa870f7e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
