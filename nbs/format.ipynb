{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp format\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "import re\n",
    "from typing import Iterable, Tuple, Union, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.utils import listify\n",
    "from fastcore.xtras import Path\n",
    "from geopy.distance import geodesic\n",
    "from rich.progress import Progress\n",
    "from pyarrow import ArrowInvalid\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "from extracao.constants import BW, BW_pattern, APP_ANALISE_PT, APP_ANALISE_EN\n",
    "\n",
    "RE_BW = re.compile(BW_pattern)\n",
    "MAX_DIST = 10  # Km\n",
    "LIMIT_FREQ = 84812.50\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _read_df(folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Lê o dataframe formado por folder / stem.[parquet.gzip | fth | xslx]\"\"\"\n",
    "    file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file)\n",
    "    except (ArrowInvalid, FileNotFoundError) as e:\n",
    "        raise e(f\"Error when reading {file}\") from e\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação\n",
    "\n",
    "> Este módulo possui funções auxiliares de formatação dos dados das várias fontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def parse_bw(\n",
    "    bw: str,  # Designação de Emissão (Largura + Classe) codificada como string\n",
    ") -> Tuple[str, str]:  # Largura e Classe de Emissão\n",
    "    \"\"\"Parse the bandwidth string\"\"\"\n",
    "    if match := re.match(RE_BW, bw):\n",
    "        multiplier = BW[match.group(2)]\n",
    "        if mantissa := match.group(3):\n",
    "            number = float(f\"{match.group(1)}.{mantissa}\")\n",
    "        else:\n",
    "            number = float(match.group(1))\n",
    "        classe = match.group(4)\n",
    "        return str(multiplier * number), str(classe)\n",
    "    return \"-1\", \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _filter_matlab(\n",
    "    df: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "    \"\"\"Recebe a base de dados da Anatel e formata as colunas para leitura de acordo com os requisitos do Matlab\"\"\"\n",
    "    df[\"#Estação\"] = df[\"Número_Estação\"]\n",
    "    df.loc[df.Multiplicidade != \"1\", \"#Estação\"] = (\n",
    "        df.loc[df.Multiplicidade != \"1\", \"Número_Estação\"]\n",
    "        + \"+\"\n",
    "        + df.loc[df.Multiplicidade != \"1\", \"Multiplicidade\"]\n",
    "    )\n",
    "    cols_desc = [\n",
    "        \"Fonte\",\n",
    "        \"Status\",\n",
    "        \"Classe\",\n",
    "        \"Entidade\",\n",
    "        \"Fistel\",\n",
    "        \"#Estação\",\n",
    "        \"Município_IBGE\",\n",
    "        \"UF\",\n",
    "    ]\n",
    "    df.loc[:, cols_desc].fillna(\"NI\", inplace=True)\n",
    "\n",
    "    df[\"Descrição\"] = (\n",
    "        \"[\"\n",
    "        + df.Fonte\n",
    "        + \"] \"\n",
    "        + df.Status\n",
    "        + \", \"\n",
    "        + df.Classe\n",
    "        + \", \"\n",
    "        + df.Entidade.str.title()\n",
    "        + \" (\"\n",
    "        + df.Fistel\n",
    "        + \", \"\n",
    "        + df[\"#Estação\"]\n",
    "        + \"), \"\n",
    "        + df.Município_IBGE\n",
    "        + \"/\"\n",
    "        + df.UF\n",
    "    )\n",
    "\n",
    "    bad_coords = df.Coords_Valida_IBGE == \"0\"\n",
    "\n",
    "    df.loc[bad_coords, \"Descrição\"] = df.loc[bad_coords, \"Descrição\"] + \"*\"\n",
    "\n",
    "    df.loc[bad_coords, [\"Latitude\", \"Longitude\"]] = df.loc[\n",
    "        bad_coords, [\"Latitude_IBGE\", \"Longitude_IBGE\"]\n",
    "    ].values\n",
    "\n",
    "    df = df.loc[:, APP_ANALISE_PT]\n",
    "    df.columns = APP_ANALISE_EN\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _format_matlab(\n",
    "    df: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "    \"\"\"Formata o arquivo final de dados para o formato esperado pela aplicação em Matlab\"\"\"\n",
    "    df = df.astype(\"string\")\n",
    "    df.loc[len(df), :] = [\n",
    "        \"-1\",\n",
    "        \"-15.7801\",\n",
    "        \"-47.9292\",\n",
    "        \"[TEMP] L, FX, Estação do SMP licenciada (cadastro temporário)\",\n",
    "        \"10\",\n",
    "        \"999999999\",\n",
    "        \"NI\",\n",
    "        \"-1\",\n",
    "    ]  # Paliativo...\n",
    "    for c in [\"Latitude\", \"Longitude\"]:\n",
    "        df[c] = df[c].fillna(-1).astype(\"float32\")\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(\"float64\")\n",
    "    df.loc[df.Service.isin([\"\", \"-1\"]), \"Service\"] = pd.NA\n",
    "    df[\"Service\"] = df.Service.fillna(\"-1\").astype(\"int16\")\n",
    "    df.loc[df.Station.isin([\"\", \"-1\"]), \"Station\"] = pd.NA\n",
    "    df[\"Station\"] = df.Station.fillna(\"-1\").astype(\"int32\")\n",
    "    df.loc[df.BW.isin([\"\", \"-1\"]), \"BW\"] = pd.NA\n",
    "    df[\"BW\"] = df[\"BW\"].astype(\"float32\").fillna(-1)\n",
    "    df.loc[df[\"Class\"].isin([\"\", \"-1\"]), \"Class\"] = pd.NA\n",
    "    df[\"Class\"] = df.Class.fillna(\"NI\").astype(\"category\")\n",
    "    df = df[df.Frequency <= LIMIT_FREQ]\n",
    "    df.sort_values(\n",
    "        by=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"], inplace=True\n",
    "    )\n",
    "    unique_columns = df.columns.tolist().remove(\"Description\")\n",
    "    df = df.drop_duplicates(subset=unique_columns, keep=\"last\").reset_index(drop=True)\n",
    "    df[\"Id\"] = [f\"#{i+1}\" for i in df.index]\n",
    "    df[\"Id\"] = df.Id.astype(\"string\")\n",
    "    df.loc[df.Description == \"\", \"Description\"] = pd.NA\n",
    "    df[\"Description\"] = df[\"Description\"].astype(\"string\").fillna(\"NI\")\n",
    "    return df[[\"Id\"] + list(APP_ANALISE_EN)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclagem\n",
    "Função auxiliar para mesclar registros que são iguais das diversas bases, i.e. estão a uma distância menor que `MAX_DIST` e verificar a validade da mesclagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def merge_close_rows(df_left, df_right):\n",
    "    \"\"\"Mescla os registros dos DataFrames `df_left` e `df_right` que estão a uma distância menor que MAX_DIST\"\"\"\n",
    "    df1 = df_left.copy().reset_index(drop=True)\n",
    "    df2 = df_right.copy().reset_index(drop=True)\n",
    "    columns = [\"Frequency\", \"Latitude\", \"Longitude\"]\n",
    "    for c in columns:\n",
    "        df1[c] = df1[c].astype(\"float\")\n",
    "        df2[c] = df2[c].astype(\"float\")\n",
    "    df1.sort_values(columns, inplace=True)\n",
    "    df2.sort_values(columns, inplace=True)\n",
    "    with Progress(transient=True, refresh_per_second=2) as progress:\n",
    "        task_left = progress.add_task(\n",
    "            \"[red]Iterando Tabela Principal...\", total=len(df1)\n",
    "        )\n",
    "        for left in df1.itertuples():\n",
    "            for right in df2[np.isclose(df2.Frequency, left.Frequency)].itertuples():\n",
    "                if (\n",
    "                    geodesic(\n",
    "                        (left.Latitude, left.Longitude),\n",
    "                        (right.Latitude, right.Longitude),\n",
    "                    ).km\n",
    "                    <= MAX_DIST\n",
    "                ):\n",
    "                    df1.loc[\n",
    "                        left.Index, \"Description\"\n",
    "                    ] = f\"{left.Description} | {right.Description}\"\n",
    "                    df2 = df2.drop(right.Index)\n",
    "                    break\n",
    "            progress.update(\n",
    "                task_left,\n",
    "                advance=1,\n",
    "                description=f\"[green] Comparando Frequências {left.Frequency}MHz\",\n",
    "            )\n",
    "        return pd.concat([df1, df2], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclagem (Vetorial)\n",
    "Implementação vetorial da função anterior que mescla dois dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_boolean_cases(df, coords, suffixes) -> Tuple[pd.Series]:\n",
    "    x, y = suffixes\n",
    "    lat, long = coords\n",
    "\n",
    "    right: pd.Series[bool] = (df[f\"{lat}{x}\"].isna() & df[f\"{lat}{y}\"].notna()) | (\n",
    "        df[f\"{long}{x}\"].isna() & df[f\"{long}{y}\"].notna()\n",
    "    )\n",
    "\n",
    "    left: pd.Series[bool] = (df[f\"{lat}{y}\"].isna() & df[f\"{lat}{x}\"].notna()) | (\n",
    "        df[f\"{long}{y}\"].isna() & df[f\"{long}{x}\"].notna()\n",
    "    )\n",
    "\n",
    "    both: pd.Series[bool] = np.all(\n",
    "        df[[f\"{lat}{x}\", f\"{long}{x}\", f\"{lat}{y}\", f\"{long}{y}\"]].notna(),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return left, right, both\n",
    "\n",
    "\n",
    "def get_km_distance(row):\n",
    "    return geodesic((row[0], row[1]), (row[2], row[3])).km\n",
    "\n",
    "\n",
    "def merge_on_frequency(\n",
    "    df_left: pd.DataFrame,  # DataFrame da esquerda a ser mesclado\n",
    "    df_right: pd.DataFrame,  # DataFrame da direira a ser mesclado\n",
    "    on: str = \"Frequency\",  # Coluna usada como chave de mesclagem\n",
    "    coords: Tuple[str] = (\"Latitude\", \"Longitude\"),\n",
    "    description: str = \"Description\",\n",
    "    suffixes: Tuple[str] = (\"_x\", \"_y\"),  # Sufixo para as colunas que foram criadas\n",
    ") -> pd.DataFrame:  # DataFrame resultante da mesclagem\n",
    "    df: pd.DataFrame = pd.merge(\n",
    "        df_left, df_right, on=on, how=\"outer\", suffixes=suffixes, indicator=True\n",
    "    )\n",
    "\n",
    "    x, y = suffixes\n",
    "    lat, long = coords\n",
    "\n",
    "    left_cols: List[str] = [c for c in df.columns if y not in c]\n",
    "\n",
    "    right_cols: List[str] = [c for c in df.columns if x not in c]\n",
    "\n",
    "    left = df._merge == \"left_only\"\n",
    "    right = df._merge == \"right_only\"\n",
    "    both = df._merge == \"both\"\n",
    "\n",
    "    only_left = df.loc[left, left_cols].drop_duplicates().reset_index(drop=True)\n",
    "    only_left.columns = [c.removesuffix(x) for c in left_cols]\n",
    "\n",
    "    only_right = df.loc[right, right_cols].drop_duplicates().reset_index(drop=True)\n",
    "    only_right.columns = [c.removesuffix(y) for c in right_cols]\n",
    "\n",
    "    both_columns = [f\"{lat}{x}\", f\"{long}{x}\", f\"{lat}{y}\", f\"{long}{y}\"]\n",
    "\n",
    "    df.loc[both, \"Distance\"] = df.loc[both, both_columns].apply(get_km_distance, axis=1)\n",
    "\n",
    "    close = df.loc[both, \"Distance\"] <= MAX_DIST\n",
    "    df_close = df.loc[(both & close)].drop_duplicates().reset_index(drop=True)\n",
    "    df_close[f\"Description{x}\"] = (\n",
    "        df_close[f\"Description{x}\"] + \" | \" + df_close[f\"Description{y}\"]\n",
    "    )\n",
    "    df_close = df_close[left_cols]\n",
    "    df_close.columns = only_left.columns\n",
    "\n",
    "    df_far_left = (\n",
    "        df.loc[(both & ~close), left_cols].drop_duplicates().reset_index(drop=True)\n",
    "    )\n",
    "    df_far_left.columns = only_left.columns\n",
    "\n",
    "    df_far_right = (\n",
    "        df.loc[(both & ~close), right_cols].drop_duplicates().reset_index(drop=True)\n",
    "    )\n",
    "    df_far_right.columns = only_right.columns\n",
    "\n",
    "    merged_df = pd.concat(\n",
    "        [df_left, df_right, df_close, df_far_right, df_far_left], ignore_index=True\n",
    "    )\n",
    "    merged_df.drop(columns=[\"_merge\"], inplace=True)\n",
    "    return _format_matlab(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path.cwd().parent / \"dados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extracao.reading import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = _filter_matlab(read_base(folder))\n",
    "df_right = read_aero(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_on_frequency(df_left, df_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 874720 entries, 0 to 874719\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   Id           874720 non-null  string  \n",
      " 1   Frequency    874720 non-null  float64 \n",
      " 2   Latitude     874720 non-null  float32 \n",
      " 3   Longitude    874720 non-null  float32 \n",
      " 4   Description  874720 non-null  string  \n",
      " 5   Service      874720 non-null  int16   \n",
      " 6   Station      874720 non-null  int32   \n",
      " 7   Class        874720 non-null  category\n",
      " 8   BW           874720 non-null  float32 \n",
      "dtypes: category(1), float32(3), float64(1), int16(1), int32(1), string(2)\n",
      "memory usage: 35.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Description</th>\n",
       "      <th>Service</th>\n",
       "      <th>Station</th>\n",
       "      <th>Class</th>\n",
       "      <th>BW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524751</th>\n",
       "      <td>#524752</td>\n",
       "      <td>317.00000</td>\n",
       "      <td>-22.548611</td>\n",
       "      <td>-44.759998</td>\n",
       "      <td>[MOS] L, FX, Telefonica Brasil S.A. (504171794...</td>\n",
       "      <td>19</td>\n",
       "      <td>1424955</td>\n",
       "      <td>F8E</td>\n",
       "      <td>1360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714359</th>\n",
       "      <td>#714360</td>\n",
       "      <td>1870.00000</td>\n",
       "      <td>-21.760834</td>\n",
       "      <td>-43.344444</td>\n",
       "      <td>[MOS] L, FX, Telefonica Brasil S.A. (504171794...</td>\n",
       "      <td>19</td>\n",
       "      <td>697802159</td>\n",
       "      <td>G7W</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34981</th>\n",
       "      <td>#34982</td>\n",
       "      <td>94.90000</td>\n",
       "      <td>-16.360001</td>\n",
       "      <td>-49.500198</td>\n",
       "      <td>[MOS] FM-C2, E3, Cultura Fm Stereo Som Ltda (1...</td>\n",
       "      <td>230</td>\n",
       "      <td>323035310</td>\n",
       "      <td>NI</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161998</th>\n",
       "      <td>#161999</td>\n",
       "      <td>156.67500</td>\n",
       "      <td>-22.368700</td>\n",
       "      <td>-41.775101</td>\n",
       "      <td>[STEL] L, ML, Petroleo Brasileiro S A Petrobra...</td>\n",
       "      <td>604</td>\n",
       "      <td>1012639239</td>\n",
       "      <td>F3E</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399881</th>\n",
       "      <td>#399882</td>\n",
       "      <td>168.38125</td>\n",
       "      <td>-19.562222</td>\n",
       "      <td>-44.066666</td>\n",
       "      <td>[MOS] L, ML, Policia Militar Do Estado De Mina...</td>\n",
       "      <td>19</td>\n",
       "      <td>1008046741</td>\n",
       "      <td>F1W</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410847</th>\n",
       "      <td>#410848</td>\n",
       "      <td>168.49375</td>\n",
       "      <td>-19.770111</td>\n",
       "      <td>-43.932564</td>\n",
       "      <td>[MOS] L, FX, Policia Militar Do Estado De Mina...</td>\n",
       "      <td>19</td>\n",
       "      <td>1002203608</td>\n",
       "      <td>G1W</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253392</th>\n",
       "      <td>#253393</td>\n",
       "      <td>165.35000</td>\n",
       "      <td>-9.805000</td>\n",
       "      <td>-37.683334</td>\n",
       "      <td>[MOS] L, FX, Oi S.A. - Em Recuperacao Judicial...</td>\n",
       "      <td>175</td>\n",
       "      <td>487260</td>\n",
       "      <td>F3E</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32494</th>\n",
       "      <td>#32495</td>\n",
       "      <td>87.90000</td>\n",
       "      <td>-13.659722</td>\n",
       "      <td>-57.890278</td>\n",
       "      <td>[SRD] RADCOM, 3-B, Associacao Comunitaria Camp...</td>\n",
       "      <td>231</td>\n",
       "      <td>682991627</td>\n",
       "      <td>NI</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248588</th>\n",
       "      <td>#248589</td>\n",
       "      <td>164.79000</td>\n",
       "      <td>-11.419306</td>\n",
       "      <td>-58.757751</td>\n",
       "      <td>[MOS] L, FX, Oi S.A. - Em Recuperacao Judicial...</td>\n",
       "      <td>175</td>\n",
       "      <td>441540333</td>\n",
       "      <td>F3E</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817796</th>\n",
       "      <td>#817797</td>\n",
       "      <td>8088.67000</td>\n",
       "      <td>-13.688722</td>\n",
       "      <td>-46.565834</td>\n",
       "      <td>[MOS] L, FX, Oi S.A.- Em Recuperação Judicial ...</td>\n",
       "      <td>175</td>\n",
       "      <td>422353787</td>\n",
       "      <td>D7W</td>\n",
       "      <td>29700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   Frequency   Latitude  Longitude  \\\n",
       "524751  #524752   317.00000 -22.548611 -44.759998   \n",
       "714359  #714360  1870.00000 -21.760834 -43.344444   \n",
       "34981    #34982    94.90000 -16.360001 -49.500198   \n",
       "161998  #161999   156.67500 -22.368700 -41.775101   \n",
       "399881  #399882   168.38125 -19.562222 -44.066666   \n",
       "410847  #410848   168.49375 -19.770111 -43.932564   \n",
       "253392  #253393   165.35000  -9.805000 -37.683334   \n",
       "32494    #32495    87.90000 -13.659722 -57.890278   \n",
       "248588  #248589   164.79000 -11.419306 -58.757751   \n",
       "817796  #817797  8088.67000 -13.688722 -46.565834   \n",
       "\n",
       "                                              Description  Service  \\\n",
       "524751  [MOS] L, FX, Telefonica Brasil S.A. (504171794...       19   \n",
       "714359  [MOS] L, FX, Telefonica Brasil S.A. (504171794...       19   \n",
       "34981   [MOS] FM-C2, E3, Cultura Fm Stereo Som Ltda (1...      230   \n",
       "161998  [STEL] L, ML, Petroleo Brasileiro S A Petrobra...      604   \n",
       "399881  [MOS] L, ML, Policia Militar Do Estado De Mina...       19   \n",
       "410847  [MOS] L, FX, Policia Militar Do Estado De Mina...       19   \n",
       "253392  [MOS] L, FX, Oi S.A. - Em Recuperacao Judicial...      175   \n",
       "32494   [SRD] RADCOM, 3-B, Associacao Comunitaria Camp...      231   \n",
       "248588  [MOS] L, FX, Oi S.A. - Em Recuperacao Judicial...      175   \n",
       "817796  [MOS] L, FX, Oi S.A.- Em Recuperação Judicial ...      175   \n",
       "\n",
       "           Station Class       BW  \n",
       "524751     1424955   F8E   1360.0  \n",
       "714359   697802159   G7W    200.0  \n",
       "34981    323035310    NI    256.0  \n",
       "161998  1012639239   F3E     11.0  \n",
       "399881  1008046741   F1W     11.0  \n",
       "410847  1002203608   G1W      8.1  \n",
       "253392      487260   F3E     16.0  \n",
       "32494    682991627    NI    256.0  \n",
       "248588   441540333   F3E     16.0  \n",
       "817796   422353787   D7W  29700.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Description</th>\n",
       "      <th>Service</th>\n",
       "      <th>Station</th>\n",
       "      <th>Class</th>\n",
       "      <th>BW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-15.780100</td>\n",
       "      <td>-47.929199</td>\n",
       "      <td>[TEMP] L, FX, Estação do SMP licenciada (cadas...</td>\n",
       "      <td>10</td>\n",
       "      <td>999999999</td>\n",
       "      <td>NI</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#2</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-22.662779</td>\n",
       "      <td>-43.476391</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1557670</td>\n",
       "      <td>J9E</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-23.709999</td>\n",
       "      <td>-46.273335</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1558412</td>\n",
       "      <td>J3E</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#4</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-23.441668</td>\n",
       "      <td>-46.590832</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>1557823</td>\n",
       "      <td>J3E</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-22.926666</td>\n",
       "      <td>-43.264999</td>\n",
       "      <td>[MOS] L, OP, Furnas Centrais Eletricas S A (01...</td>\n",
       "      <td>19</td>\n",
       "      <td>859761</td>\n",
       "      <td>J3E</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Frequency   Latitude  Longitude  \\\n",
       "0  #1     -1.000 -15.780100 -47.929199   \n",
       "1  #2      0.028 -22.662779 -43.476391   \n",
       "2  #3      0.030 -23.709999 -46.273335   \n",
       "3  #4      0.030 -23.441668 -46.590832   \n",
       "4  #5      0.030 -22.926666 -43.264999   \n",
       "\n",
       "                                         Description  Service    Station  \\\n",
       "0  [TEMP] L, FX, Estação do SMP licenciada (cadas...       10  999999999   \n",
       "1  [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19    1557670   \n",
       "2  [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19    1558412   \n",
       "3  [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19    1557823   \n",
       "4  [MOS] L, OP, Furnas Centrais Eletricas S A (01...       19     859761   \n",
       "\n",
       "  Class   BW  \n",
       "0    NI -1.0  \n",
       "1   J9E  8.0  \n",
       "2   J3E  2.0  \n",
       "3   J3E  1.0  \n",
       "4   J3E  0.5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(818001, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos Tipos de dados\n",
    "A serem criados dataframes, normalmente a tipo de data é aquele com maior resolução possível, nem sempre isso é necessário, os arquivos de espectro mesmo possuem somente uma casa decimal, portanto um `float16` já é suficiente para armazená-los. As funções a seguir fazem essa otimização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def optimize_floats(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    exclude: Iterable[str] = None,  # Colunas a serem excluidas da otimização\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `float` otimizadas\n",
    "    \"\"\"Otimiza os floats do dataframe para reduzir o uso de memória\"\"\"\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    floats = [c for c in floats if c not in listify(exclude)]\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def optimize_ints(\n",
    "    df: pd.DataFrame,  # Dataframe a ser otimizado\n",
    "    exclude: Iterable[str] = None,  # Colunas a serem excluidas da otimização\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `int` otimizadas\n",
    "    \"\"\"Otimiza os ints do dataframe para reduzir o uso de memória\"\"\"\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    ints = [c for c in ints if c not in listify(exclude)]\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def optimize_objects(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[\n",
    "        str\n",
    "    ] = None,  # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None,  # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas do tipo `object` otimizadas\n",
    "    \"\"\"Otimiza as colunas do tipo `object` no DataFrame para `category` ou `string` para reduzir a memória e tamanho de arquivo\"\"\"\n",
    "    exclude = listify(exclude)\n",
    "    datetime_features = listify(datetime_features)\n",
    "    for col in df.select_dtypes(\n",
    "        include=[\"object\", \"string\", \"category\"]\n",
    "    ).columns.tolist():\n",
    "        if col not in datetime_features:\n",
    "            if col in exclude:\n",
    "                continue\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                dtype = \"category\"\n",
    "            else:\n",
    "                dtype = \"string\"\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def df_optimize(\n",
    "    df: pd.DataFrame,  # DataFrame a ser otimizado\n",
    "    datetime_features: Iterable[\n",
    "        str\n",
    "    ] = None,  # Colunas que serão convertidas para datetime\n",
    "    exclude: Iterable[str] = None,  # Colunas que não serão convertidas\n",
    ") -> pd.DataFrame:  # DataFrame com as colunas com tipos de dados otimizados\n",
    "    \"\"\"Função que encapsula as anteriores para otimizar os tipos de dados e reduzir o tamanho do arquivo e uso de memória\"\"\"\n",
    "    if datetime_features is None:\n",
    "        datetime_features = []\n",
    "    return optimize_floats(\n",
    "        optimize_ints(optimize_objects(df, datetime_features, exclude), exclude),\n",
    "        exclude,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
