{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasources.smp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys,os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "os.chdir(Path.cwd().parent / 'extracao')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serviço Móvel Pessoal\n",
    "> Módulo para encapsular a extração e processamento do Serviço Móvel Pessoal - Telefonia e Banda Larga Móvel - 2G, 3G, 4G e 5G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from extracao.constants import (\n",
    "\tAGG_SMP,\n",
    "\tCHANNELS,\n",
    "\tCOLUNAS,\n",
    "\tDICT_LICENCIAMENTO,\n",
    "\tIBGE_MUNICIPIOS,\n",
    "\tMONGO_SMP,\n",
    "\tPROJECTION_LICENCIAMENTO,\n",
    ")\n",
    "from extracao.datasources.mosaico import Mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide: true\n",
    "#| eval:false\n",
    "__file__ = Path.cwd().parent / 'extracao' / 'datasources.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "MONGO_URI = os.environ.get('MONGO_URI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SMP(Mosaico):\n",
    "\t\"\"\"Classe para encapsular a lógica de extração do SMP\"\"\"\n",
    "\n",
    "\tdef __init__(self, mongo_uri: str = MONGO_URI, limit: int = 0) -> None:\n",
    "\t\tsuper().__init__(mongo_uri)\n",
    "\t\tself.limit = limit\n",
    "\n",
    "\t@property\n",
    "\tdef stem(self):\n",
    "\t\treturn 'smp'\n",
    "\n",
    "\t@property\n",
    "\tdef collection(self):\n",
    "\t\treturn 'licenciamento'\n",
    "\n",
    "\t@property\n",
    "\tdef query(self):\n",
    "\t\treturn MONGO_SMP\n",
    "\n",
    "\t@property\n",
    "\tdef projection(self):\n",
    "\t\treturn PROJECTION_LICENCIAMENTO\n",
    "\n",
    "\t@property\n",
    "\tdef columns(self):\n",
    "\t\treturn COLUNAS\n",
    "\n",
    "\t@property\n",
    "\tdef cols_mapping(self):\n",
    "\t\treturn DICT_LICENCIAMENTO\n",
    "\n",
    "\tdef extraction(self) -> pd.DataFrame:\n",
    "\t\tpipeline = [{'$match': self.query}, {'$project': self.projection}]\n",
    "\t\tif self.limit > 0:\n",
    "\t\t\tpipeline.append({'$limit': self.limit})\n",
    "\t\tdf = self._extract(self.collection, pipeline)\n",
    "\t\tdf['Log'] = ''\n",
    "\t\treturn df\n",
    "\n",
    "\tdef exclude_duplicated(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame com os dados de Estações\n",
    "\t) -> pd.DataFrame:  # DataFrame com os dados duplicados excluídos\n",
    "\t\tf\"\"\"Exclui os registros duplicados\n",
    "        O subconjunto de colunas consideradas é {AGG_SMP}\n",
    "        \"\"\"\n",
    "\t\tdf['Estação'] = df['Estação'].astype('int')\n",
    "\t\tdf = df.sort_values('Estação', ignore_index=True)\n",
    "\t\tdf['Largura_Emissão(kHz)'] = pd.to_numeric(df['Largura_Emissão(kHz)'], errors='coerce')\n",
    "\t\t# df['Largura_Emissão(kHz)'] = df['Largura_Emissão(kHz)'].fillna(0)\n",
    "\t\t# df['Classe_Emissão'] = df['Classe_Emissão'].fillna('NI')\n",
    "\t\t# df['Tecnologia'] = df['Tecnologia'].fillna('NI')\n",
    "\t\tduplicated = df.duplicated(subset=AGG_SMP, keep='first')\n",
    "\t\tdf_sub = df[~duplicated].copy().reset_index(drop=True)\n",
    "\t\t# discarded = df[duplicated].copy().reset_index(drop=True)\n",
    "\t\t# log = f\"\"\"[(\"Colunas\", {AGG_SMP}),\n",
    "\t\t#         (\"Processamento\", \"Registro agrupado e descartado do arquivo final\")]\"\"\"\n",
    "\t\t# self.append2discarded(self.register_log(discarded, log))\n",
    "\t\t# for col in AGG_SMP:\n",
    "\t\t#     discarded_with_na = df_sub[df_sub[col].isna()]\n",
    "\t\t#     log = f\"\"\"[(\"Colunas\", {col}),\n",
    "\t\t#             (\"Processamento\", \"Registro com valor nulo presente\")]\"\"\"\n",
    "\t\t#     self.append2discarded(self.register_log(discarded_with_na, log))\n",
    "\t\tdf_sub.dropna(subset=AGG_SMP, inplace=True)\n",
    "\t\tdf_sub['Multiplicidade'] = (\n",
    "\t\t\tdf.groupby(AGG_SMP, dropna=True, sort=False, observed=True).size().values\n",
    "\t\t)\n",
    "\t\tlog = f'[(\"Colunas\", {AGG_SMP}), (\"Processamento\", \"Agrupamento\")]'\n",
    "\t\treturn self.register_log(df_sub, log, df_sub['Multiplicidade'] > 1)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef read_channels():\n",
    "\t\tchannels = pd.read_csv(CHANNELS, dtype='string')\n",
    "\t\tcols = ['Downlink_Inicial', 'Downlink_Final', 'Uplink_Inicial', 'Uplink_Final']\n",
    "\t\tchannels[cols] = channels[cols].astype('float')\n",
    "\t\tchannels = channels.sort_values(['Downlink_Inicial'], ignore_index=True)\n",
    "\t\tchannels['N_Bloco'] = channels['N_Bloco'].str.strip()\n",
    "\t\tchannels['Faixa'] = channels['Faixa'].str.strip()\n",
    "\t\treturn channels\n",
    "\n",
    "\tdef exclude_invalid_channels(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame de Origem\n",
    "\t) -> pd.DataFrame:  # DataFrame com os canais inválidos excluídos\n",
    "\t\tdf_sub = df[df.Canalização == 'Downlink'].reset_index(drop=True)\n",
    "\t\t# for flag in [\"Uplink\", \"Inválida\"]:\n",
    "\t\t#     discarded = df[df.Canalização == flag]\n",
    "\t\t#     if not discarded.empty:\n",
    "\t\t#         log = f\"\"\"[(\"Colunas\", (\"Frequência\", \"Largura_Emissão(kHz)\")),\n",
    "\t\t#                  (\"Processamento\", \"Canalização {flag}\")]\"\"\"\n",
    "\t\t#         self.append2discarded(self.register_log(discarded, log))\n",
    "\t\treturn df_sub\n",
    "\n",
    "\tdef validate_channels(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame with the original channels info\n",
    "\t) -> pd.DataFrame:  # DataFrame with the channels validated and added info\n",
    "\t\t\"\"\"Read the SMP channels file, validate and merge the channels present in df\"\"\"\n",
    "\t\tbw = df['Largura_Emissão(kHz)'].astype('float') / 2000  # Unidade em kHz\n",
    "\t\tdf['Início_Canal_Down'] = df.Frequência.astype(float) - bw\n",
    "\t\tdf['Fim_Canal_Down'] = df.Frequência.astype(float) + bw\n",
    "\t\tchannels = self.read_channels()\n",
    "\t\tgrouped_channels = df.groupby(\n",
    "\t\t\t['Início_Canal_Down', 'Fim_Canal_Down'], as_index=False\n",
    "\t\t).size()\n",
    "\t\tgrouped_channels.sort_values('size', ascending=False, inplace=True, ignore_index=True)\n",
    "\t\tgrouped_channels['Canalização'] = 'Inválida'\n",
    "\t\tgrouped_channels.loc[:, 'Offset'] = np.nan\n",
    "\t\tgrouped_channels.loc[:, ['Blocos_Downlink', 'Faixas']] = pd.NA\n",
    "\t\tgrouped_channels.loc[\n",
    "\t\t\t:, ['Blocos_Downlink', 'Faixas', 'Canalização']\n",
    "\t\t] = grouped_channels.loc[:, ['Blocos_Downlink', 'Faixas', 'Canalização']].astype('string')\n",
    "\t\tgrouped_channels.loc[:, 'Offset'] = grouped_channels.loc[:, 'Offset'].astype('float')\n",
    "\n",
    "\t\tfor row in grouped_channels.itertuples():\n",
    "\t\t\tinterval = channels[\n",
    "\t\t\t\t(row.Início_Canal_Down < channels['Downlink_Final'])\n",
    "\t\t\t\t& (row.Fim_Canal_Down > channels['Downlink_Inicial'])\n",
    "\t\t\t]\n",
    "\t\t\tfaixa = 'Downlink'\n",
    "\t\t\tif interval.empty:\n",
    "\t\t\t\tinterval = channels[\n",
    "\t\t\t\t\t(row.Início_Canal_Down < channels['Uplink_Final'])\n",
    "\t\t\t\t\t& (row.Fim_Canal_Down > channels['Uplink_Inicial'])\n",
    "\t\t\t\t]\n",
    "\t\t\t\tif interval.empty:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tfaixa = 'Uplink'\n",
    "\n",
    "\t\t\tdown = ' | '.join(\n",
    "\t\t\t\tinterval[['Downlink_Inicial', 'Downlink_Final']].apply(\n",
    "\t\t\t\t\tlambda x: f'{x.iloc[0]}-{x.iloc[1]}', axis=1\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t\tfaixas = ' | '.join(interval.Faixa.unique())\n",
    "\t\t\tif len(offset := interval.Offset.unique()) != 1:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tgrouped_channels.loc[\n",
    "\t\t\t\trow.Index, ['Blocos_Downlink', 'Faixas', 'Canalização', 'Offset']\n",
    "\t\t\t] = (down, faixas, faixa, float(offset[0]))\n",
    "\t\tgrouped_channels = grouped_channels[\n",
    "\t\t\t[\n",
    "\t\t\t\t'Início_Canal_Down',\n",
    "\t\t\t\t'Fim_Canal_Down',\n",
    "\t\t\t\t'Blocos_Downlink',\n",
    "\t\t\t\t'Faixas',\n",
    "\t\t\t\t'Canalização',\n",
    "\t\t\t\t'Offset',\n",
    "\t\t\t]\n",
    "\t\t]\n",
    "\t\tdf = pd.merge(df, grouped_channels, how='left', on=['Início_Canal_Down', 'Fim_Canal_Down'])\n",
    "\t\treturn self.exclude_invalid_channels(df)\n",
    "\n",
    "\tdef generate_uplink(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame de Origem\n",
    "\t) -> pd.DataFrame:  # DataFrame com os canais de Uplink adicionados\n",
    "\t\tdf['Offset'] = pd.to_numeric(df['Offset'], errors='coerce').astype('float')\n",
    "\t\tdf['Largura_Emissão(kHz)'] = pd.to_numeric(\n",
    "\t\t\tdf['Largura_Emissão(kHz)'], errors='coerce'\n",
    "\t\t).astype('float')\n",
    "\t\tvalid = (\n",
    "\t\t\t(df.Offset.notna())\n",
    "\t\t\t& (~np.isclose(df.Offset, 0))\n",
    "\t\t\t& (df['Largura_Emissão(kHz)'].notna())\n",
    "\t\t\t& (~np.isclose(df['Largura_Emissão(kHz)'], 0))\n",
    "\t\t)\n",
    "\t\tdf[['Frequência', 'Offset']] = df[['Frequência', 'Offset']].astype('float')\n",
    "\t\tdf.loc[valid, 'Frequência_Recepção'] = df.loc[valid, 'Frequência'] - df.loc[valid, 'Offset']\n",
    "\t\treturn df\n",
    "\n",
    "\tdef substitute_coordenates(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\tibge = pd.read_csv(\n",
    "\t\t\tIBGE_MUNICIPIOS,\n",
    "\t\t\tdtype='string',\n",
    "\t\t\tusecols=['Código_Município', 'Município', 'Latitude', 'Longitude'],\n",
    "\t\t)\n",
    "\t\tibge.columns = ['Código_Município', 'Município', 'Latitude', 'Longitude']\n",
    "\t\tcoords = pd.merge(\n",
    "\t\t\tdf.loc[df.Multiplicidade > 1, 'Código_Município'],\n",
    "\t\t\tibge[['Código_Município', 'Latitude', 'Longitude']],\n",
    "\t\t\ton='Código_Município',\n",
    "\t\t\thow='left',\n",
    "\t\t)\n",
    "\t\tdf[['Latitude', 'Longitude']] = df[['Latitude', 'Longitude']].astype('float')\n",
    "\t\tdf.loc[df.Multiplicidade > 1, ['Latitude', 'Longitude']] = coords[\n",
    "\t\t\t['Latitude', 'Longitude']\n",
    "\t\t].values.astype('float')\n",
    "\t\tlog = \"\"\"[(\"Colunas\", (\"Latitude\", \"Longitude\")), \n",
    "        (\"Processamento\", \"Substituição por Coordenadas do Município (Agrupamento)\")]\"\"\"\n",
    "\t\treturn self.register_log(df, log, df.Multiplicidade > 1)\n",
    "\n",
    "\tdef input_fixed_columns(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame de Origem\n",
    "\t) -> pd.DataFrame:  # DataFrame com os canais de downlink e uplink contenados e formatados\n",
    "\t\tdf['Status'] = 'L'\n",
    "\t\tdf['Serviço'] = '010'\n",
    "\t\tdown = df.drop('Frequência_Recepção', axis=1)\n",
    "\t\tdown['Fonte'] = 'MOSAICO-LICENCIAMENTO'\n",
    "\t\tdown['Classe'] = 'FB'\n",
    "\t\tup = df.drop('Frequência', axis=1)\n",
    "\t\tup = up.rename(columns={'Frequência_Recepção': 'Frequência'})\n",
    "\t\tup.dropna(subset='Frequência', inplace=True)\n",
    "\t\tup['Fonte'] = 'CANALIZACAO-SMP'\n",
    "\t\tup['Classe'] = 'ML'\n",
    "\t\treturn pd.concat([down, up], ignore_index=True)\n",
    "\n",
    "\tdef _format(\n",
    "\t\tself,\n",
    "\t\tdf: pd.DataFrame,  # DataFrame com os dados de Estações e Plano_Básico mesclados\n",
    "\t) -> pd.DataFrame:  # DataFrame com os dados mesclados e limpos\n",
    "\t\t\"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "\t\tdf = df.rename(columns=self.cols_mapping)\n",
    "\t\tdf = self.split_designacao(df)\n",
    "\t\tdf = self.exclude_duplicated(df)\n",
    "\t\tdf = self.validate_channels(df)\n",
    "\t\tdf = self.generate_uplink(df)\n",
    "\t\tdf = self.substitute_coordenates(df)\n",
    "\t\tdf = self.input_fixed_columns(df)\n",
    "\t\treturn df.loc[:, self.columns]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
