{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasources.smp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys,os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "os.chdir(Path.cwd().parent / 'extracao')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serviço Móvel Pessoal\n",
    "> Módulo para encapsular a extração e processamento do Serviço Móvel Pessoal - Telefonia e Banda Larga Móvel - 2G, 3G, 4G e 5G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from extracao.constants import (\n",
    "    AGG_SMP,\n",
    "    CHANNELS,\n",
    "    COLUNAS,\n",
    "    DICT_LICENCIAMENTO,\n",
    "    IBGE_MUNICIPIOS,\n",
    "    MONGO_SMP,\n",
    "    PROJECTION_LICENCIAMENTO,\n",
    ")\n",
    "from extracao.datasources.mosaico import Mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide: true\n",
    "#| eval:false\n",
    "__file__ = Path.cwd().parent / 'extracao' / 'datasources.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SMP(Mosaico):\n",
    "    \"\"\"Classe para encapsular a lógica de extração do SMP\"\"\"\n",
    "\n",
    "    def __init__(self, mongo_uri: str = MONGO_URI, limit: int = 0) -> None:\n",
    "        super().__init__(mongo_uri)\n",
    "        self.limit = limit\n",
    "\n",
    "    @property\n",
    "    def stem(self):\n",
    "        return \"smp\"\n",
    "\n",
    "    @property\n",
    "    def collection(self):\n",
    "        return \"licenciamento\"\n",
    "\n",
    "    @property\n",
    "    def query(self):\n",
    "        return MONGO_SMP\n",
    "\n",
    "    @property\n",
    "    def projection(self):\n",
    "        return PROJECTION_LICENCIAMENTO\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return COLUNAS\n",
    "\n",
    "    @property\n",
    "    def cols_mapping(self):\n",
    "        return DICT_LICENCIAMENTO\n",
    "\n",
    "    def extraction(self) -> pd.DataFrame:\n",
    "        pipeline = [{\"$match\": self.query}, {\"$project\": self.projection}]\n",
    "        if self.limit > 0:\n",
    "            pipeline.append({\"$limit\": self.limit})\n",
    "        df = self._extract(self.collection, pipeline)\n",
    "        df[\"Log\"] = \"\"\n",
    "        return df\n",
    "\n",
    "    def exclude_duplicated(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame com os dados de Estações\n",
    "    ) -> pd.DataFrame:  # DataFrame com os dados duplicados excluídos\n",
    "        f\"\"\"Exclui os registros duplicados\n",
    "        O subconjunto de colunas consideradas é {AGG_SMP}\n",
    "        \"\"\"\n",
    "        df[\"Número_Estação\"] = df[\"Número_Estação\"].astype(\"int\")\n",
    "        df = df.sort_values(\"Número_Estação\", ignore_index=True)\n",
    "        df[\"Largura_Emissão(kHz)\"] = pd.to_numeric(\n",
    "            df[\"Largura_Emissão(kHz)\"], errors=\"coerce\"\n",
    "        )\n",
    "        # df['Largura_Emissão(kHz)'] = df['Largura_Emissão(kHz)'].fillna(0)\n",
    "        # df['Classe_Emissão'] = df['Classe_Emissão'].fillna('NI')\n",
    "        # df['Tecnologia'] = df['Tecnologia'].fillna('NI')\n",
    "        duplicated = df.duplicated(subset=AGG_SMP, keep=\"first\")\n",
    "        df_sub = df[~duplicated].copy().reset_index(drop=True)\n",
    "        # discarded = df[duplicated].copy().reset_index(drop=True)\n",
    "        # log = f\"\"\"[(\"Colunas\", {AGG_SMP}),\n",
    "        #         (\"Processamento\", \"Registro agrupado e descartado do arquivo final\")]\"\"\"\n",
    "        # self.append2discarded(self.register_log(discarded, log))\n",
    "        # for col in AGG_SMP:\n",
    "        #     discarded_with_na = df_sub[df_sub[col].isna()]\n",
    "        #     log = f\"\"\"[(\"Colunas\", {col}),\n",
    "        #             (\"Processamento\", \"Registro com valor nulo presente\")]\"\"\"\n",
    "        #     self.append2discarded(self.register_log(discarded_with_na, log))\n",
    "        df_sub.dropna(subset=AGG_SMP, inplace=True)\n",
    "        df_sub[\"Multiplicidade\"] = (\n",
    "            df.groupby(AGG_SMP, dropna=True, sort=False, observed=True).size().values\n",
    "        )\n",
    "        log = f'[(\"Colunas\", {AGG_SMP}), (\"Processamento\", \"Agrupamento\")]'\n",
    "        return self.register_log(df_sub, log, df_sub[\"Multiplicidade\"] > 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_channels():\n",
    "        channels = pd.read_csv(CHANNELS, dtype=\"string\")\n",
    "        cols = [\"Downlink_Inicial\", \"Downlink_Final\", \"Uplink_Inicial\", \"Uplink_Final\"]\n",
    "        channels[cols] = channels[cols].astype(\"float\")\n",
    "        channels = channels.sort_values([\"Downlink_Inicial\"], ignore_index=True)\n",
    "        channels[\"N_Bloco\"] = channels[\"N_Bloco\"].str.strip()\n",
    "        channels[\"Faixa\"] = channels[\"Faixa\"].str.strip()\n",
    "        return channels\n",
    "\n",
    "    def exclude_invalid_channels(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame de Origem\n",
    "    ) -> pd.DataFrame:  # DataFrame com os canais inválidos excluídos\n",
    "        df_sub = df[df.Canalização == \"Downlink\"].reset_index(drop=True)\n",
    "        # for flag in [\"Uplink\", \"Inválida\"]:\n",
    "        #     discarded = df[df.Canalização == flag]\n",
    "        #     if not discarded.empty:\n",
    "        #         log = f\"\"\"[(\"Colunas\", (\"Frequência\", \"Largura_Emissão(kHz)\")),\n",
    "        #                  (\"Processamento\", \"Canalização {flag}\")]\"\"\"\n",
    "        #         self.append2discarded(self.register_log(discarded, log))\n",
    "        return df_sub\n",
    "\n",
    "    def validate_channels(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame with the original channels info\n",
    "    ) -> pd.DataFrame:  # DataFrame with the channels validated and added info\n",
    "        \"\"\"Read the SMP channels file, validate and merge the channels present in df\"\"\"\n",
    "        bw = df[\"Largura_Emissão(kHz)\"].astype(\"float\") / 2000  # Unidade em kHz\n",
    "        df[\"Início_Canal_Down\"] = df.Frequência.astype(float) - bw\n",
    "        df[\"Fim_Canal_Down\"] = df.Frequência.astype(float) + bw\n",
    "        channels = self.read_channels()\n",
    "        grouped_channels = df.groupby(\n",
    "            [\"Início_Canal_Down\", \"Fim_Canal_Down\"], as_index=False\n",
    "        ).size()\n",
    "        grouped_channels.sort_values(\n",
    "            \"size\", ascending=False, inplace=True, ignore_index=True\n",
    "        )\n",
    "        grouped_channels[\"Canalização\"] = \"Inválida\"\n",
    "        grouped_channels.loc[:, \"Offset\"] = np.nan\n",
    "        grouped_channels.loc[:, [\"Blocos_Downlink\", \"Faixas\"]] = pd.NA\n",
    "        grouped_channels.loc[\n",
    "            :, [\"Blocos_Downlink\", \"Faixas\", \"Canalização\"]\n",
    "        ] = grouped_channels.loc[\n",
    "            :, [\"Blocos_Downlink\", \"Faixas\", \"Canalização\"]\n",
    "        ].astype(\n",
    "            \"string\"\n",
    "        )\n",
    "        grouped_channels.loc[:, \"Offset\"] = grouped_channels.loc[:, \"Offset\"].astype(\n",
    "            \"float\"\n",
    "        )\n",
    "\n",
    "        for row in grouped_channels.itertuples():\n",
    "            interval = channels[\n",
    "                (row.Início_Canal_Down < channels[\"Downlink_Final\"])\n",
    "                & (row.Fim_Canal_Down > channels[\"Downlink_Inicial\"])\n",
    "            ]\n",
    "            faixa = \"Downlink\"\n",
    "            if interval.empty:\n",
    "                interval = channels[\n",
    "                    (row.Início_Canal_Down < channels[\"Uplink_Final\"])\n",
    "                    & (row.Fim_Canal_Down > channels[\"Uplink_Inicial\"])\n",
    "                ]\n",
    "                if interval.empty:\n",
    "                    continue\n",
    "                faixa = \"Uplink\"\n",
    "\n",
    "            down = \" | \".join(\n",
    "                interval[[\"Downlink_Inicial\", \"Downlink_Final\"]].apply(\n",
    "                    lambda x: f\"{x.iloc[0]}-{x.iloc[1]}\", axis=1\n",
    "                )\n",
    "            )\n",
    "            faixas = \" | \".join(interval.Faixa.unique())\n",
    "            if len(offset := interval.Offset.unique()) != 1:\n",
    "                continue\n",
    "            grouped_channels.loc[\n",
    "                row.Index, [\"Blocos_Downlink\", \"Faixas\", \"Canalização\", \"Offset\"]\n",
    "            ] = (down, faixas, faixa, float(offset[0]))\n",
    "        grouped_channels = grouped_channels[\n",
    "            [\n",
    "                \"Início_Canal_Down\",\n",
    "                \"Fim_Canal_Down\",\n",
    "                \"Blocos_Downlink\",\n",
    "                \"Faixas\",\n",
    "                \"Canalização\",\n",
    "                \"Offset\",\n",
    "            ]\n",
    "        ]\n",
    "        df = pd.merge(\n",
    "            df, grouped_channels, how=\"left\", on=[\"Início_Canal_Down\", \"Fim_Canal_Down\"]\n",
    "        )\n",
    "        return self.exclude_invalid_channels(df)\n",
    "\n",
    "    def generate_uplink(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame de Origem\n",
    "    ) -> pd.DataFrame:  # DataFrame com os canais de Uplink adicionados\n",
    "        df[\"Offset\"] = pd.to_numeric(df[\"Offset\"], errors=\"coerce\").astype(\"float\")\n",
    "        df[\"Largura_Emissão(kHz)\"] = pd.to_numeric(\n",
    "            df[\"Largura_Emissão(kHz)\"], errors=\"coerce\"\n",
    "        ).astype(\"float\")\n",
    "        valid = (\n",
    "            (df.Offset.notna())\n",
    "            & (~np.isclose(df.Offset, 0))\n",
    "            & (df[\"Largura_Emissão(kHz)\"].notna())\n",
    "            & (~np.isclose(df[\"Largura_Emissão(kHz)\"], 0))\n",
    "        )\n",
    "        df[[\"Frequência\", \"Offset\"]] = df[[\"Frequência\", \"Offset\"]].astype(\"float\")\n",
    "        df.loc[valid, \"Frequência_Recepção\"] = (\n",
    "            df.loc[valid, \"Frequência\"] - df.loc[valid, \"Offset\"]\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def substitute_coordenates(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        ibge = pd.read_csv(\n",
    "            IBGE_MUNICIPIOS,\n",
    "            dtype=\"string\",\n",
    "            usecols=[\"Código_Município\", \"Município\", \"Latitude\", \"Longitude\"],\n",
    "        )\n",
    "        ibge.columns = [\"Código_Município\", \"Município\", \"Latitude\", \"Longitude\"]\n",
    "        coords = pd.merge(\n",
    "            df.loc[df.Multiplicidade > 1, \"Código_Município\"],\n",
    "            ibge[[\"Código_Município\", \"Latitude\", \"Longitude\"]],\n",
    "            on=\"Código_Município\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        df[[\"Latitude\", \"Longitude\"]] = df[[\"Latitude\", \"Longitude\"]].astype(\"float\")\n",
    "        df.loc[df.Multiplicidade > 1, [\"Latitude\", \"Longitude\"]] = coords[\n",
    "            [\"Latitude\", \"Longitude\"]\n",
    "        ].values.astype(\"float\")\n",
    "        log = \"\"\"[(\"Colunas\", (\"Latitude\", \"Longitude\")), \n",
    "        (\"Processamento\", \"Substituição por Coordenadas do Município (Agrupamento)\")]\"\"\"\n",
    "        return self.register_log(df, log, df.Multiplicidade > 1)\n",
    "\n",
    "    def input_fixed_columns(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame de Origem\n",
    "    ) -> (\n",
    "        pd.DataFrame\n",
    "    ):  # DataFrame com os canais de downlink e uplink contenados e formatados\n",
    "        df[\"Status\"] = \"L\"\n",
    "        df[\"Num_Serviço\"] = \"010\"\n",
    "        down = df.drop(\"Frequência_Recepção\", axis=1)\n",
    "        down[\"Fonte\"] = \"MOSAICO-LICENCIAMENTO\"\n",
    "        down[\"Classe\"] = \"FB\"\n",
    "        up = df.drop(\"Frequência\", axis=1)\n",
    "        up = up.rename(columns={\"Frequência_Recepção\": \"Frequência\"})\n",
    "        up.dropna(subset=\"Frequência\", inplace=True)\n",
    "        up[\"Fonte\"] = \"CANALIZACAO-SMP\"\n",
    "        up[\"Classe\"] = \"ML\"\n",
    "        return pd.concat([down, up], ignore_index=True)\n",
    "\n",
    "    def _format(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame com os dados de Estações e Plano_Básico mesclados\n",
    "    ) -> pd.DataFrame:  # DataFrame com os dados mesclados e limpos\n",
    "        \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "        df = df.rename(columns=self.cols_mapping)\n",
    "        df = self.split_designacao(df)\n",
    "        df = self.exclude_duplicated(df)\n",
    "        df = self.validate_channels(df)\n",
    "        df = self.generate_uplink(df)\n",
    "        df = self.substitute_coordenates(df)\n",
    "        df = self.input_fixed_columns(df)\n",
    "        return df.loc[:, self.columns]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
