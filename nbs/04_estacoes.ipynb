{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp estacoes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatel\n",
    "\n",
    "> Este módulo consolida as bases da Anatel e realiza pós-processamento dos dados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import urllib.request\n",
    "from typing import List\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fastcore.foundation import L\n",
    "from fastcore.parallel import parallel\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "from extracao.constants import COLS_SRD, IBGE_MUNICIPIOS, IBGE_POLIGONO, MALHA_IBGE\n",
    "from extracao.datasources.aeronautica import Aero\n",
    "from extracao.datasources.base import Base\n",
    "from extracao.datasources.mosaico import MONGO_URI\n",
    "from extracao.datasources.sitarweb import SQLSERVER_PARAMS, Radcom, Stel\n",
    "from extracao.datasources.smp import SMP\n",
    "from extracao.datasources.srd import SRD\n",
    "from extracao.datasources.telecom import Telecom\n",
    "from extracao.format import merge_on_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Consolidada ANATEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<<<<<<< HEAD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class Estacoes(Base):\n",
    "    \"\"\"Classe auxiliar para agregar os dados originários da Anatel\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sql_params: dict = SQLSERVER_PARAMS,\n",
    "        mongo_uri: str = MONGO_URI,\n",
    "        limit: int = 0,\n",
    "        parallel: bool = True,\n",
    "    ):\n",
    "        self.sql_params = sql_params\n",
    "        self.mongo_uri = mongo_uri\n",
    "        self.limit = limit\n",
    "        self.parallel = parallel\n",
    "        self.init_data_sources()\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return COLS_SRD\n",
    "\n",
    "    def build_from_sources(self) -> pd.DataFrame:\n",
    "        return self._format([s.df() for s in self.sources.values()])\n",
    "\n",
    "    @property\n",
    "    def stem(self):\n",
    "        return \"anatel\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _update_source(class_instance):\n",
    "        class_instance.update()\n",
    "        class_instance.save()\n",
    "        return class_instance\n",
    "\n",
    "    def init_data_sources(self):\n",
    "        self.sources = {\n",
    "            \"telecom\": Telecom(self.mongo_uri, self.limit),\n",
    "            \"smp\": SMP(self.mongo_uri, self.limit),\n",
    "            \"srd\": SRD(self.mongo_uri),\n",
    "            \"stel\": Stel(self.sql_params),\n",
    "            \"radcom\": Radcom(self.sql_params),\n",
    "            \"aero\": Aero(),\n",
    "        }\n",
    "\n",
    "    def extraction(self) -> L:\n",
    "        if self.parallel:\n",
    "            sources = parallel(\n",
    "                Estacoes._update_source,\n",
    "                self.sources.values(),\n",
    "                n_workers=len(self.sources),\n",
    "                progress=True,\n",
    "            )\n",
    "        else:\n",
    "            sources = L(self._update_source(s) for s in self.sources.values())\n",
    "        return sources.attrgot(\"df\")\n",
    "\n",
    "    @staticmethod\n",
    "    def verify_shapefile_folder():\n",
    "        # Convert the file paths to Path objects\n",
    "        shapefile_path = Path(IBGE_POLIGONO)\n",
    "        parent_folder = shapefile_path.parent\n",
    "        parent_folder.mkdir(exist_ok=True, parents=True)\n",
    "        zip_file_path = parent_folder.with_suffix(\".zip\")\n",
    "\n",
    "        # Check if all required files exist\n",
    "        required_files = L(\".cpg\", \".dbf\", \".prj\", \".shx\").map(\n",
    "            shapefile_path.with_suffix\n",
    "        )\n",
    "        if not all(required_files.map(Path.is_file)):\n",
    "            # shutil.rmtree(str(shapefile_path.parent), ignore_errors=True)\n",
    "            parent_folder.ls().map(Path.unlink)\n",
    "            # Download and unzip the zipped folder\n",
    "            urllib.request.urlretrieve(MALHA_IBGE, zip_file_path)\n",
    "            with ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(parent_folder)\n",
    "            zip_file_path.unlink()\n",
    "\n",
    "    def fill_nan_coordinates(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame com os dados da Anatel\n",
    "    ) -> pd.DataFrame:  # DataFrame com as coordenadas validadas na base do IBGE\n",
    "        \"\"\"Valida as coordenadas consultado a Base Corporativa do IBGE, excluindo o que já está no cache na versão anterior\"\"\"\n",
    "\n",
    "        municipios = pd.read_csv(\n",
    "            IBGE_MUNICIPIOS,\n",
    "            usecols=[\"Código_Município\", \"Latitude\", \"Longitude\"],\n",
    "            dtype=\"string[pyarrow]\",\n",
    "            dtype_backend=\"pyarrow\",\n",
    "        )\n",
    "\n",
    "        df = pd.merge(df, municipios, on=\"Código_Município\", how=\"left\", copy=False)\n",
    "\n",
    "        null_coords = df.Latitude_x.isna() | df.Longitude_x.isna()\n",
    "\n",
    "        df.loc[null_coords, [\"Latitude_x\", \"Longitude_x\"]] = df.loc[\n",
    "            null_coords, [\"Latitude_y\", \"Longitude_y\"]\n",
    "        ]\n",
    "\n",
    "        log = \"\"\"[(\"Colunas\", [\"Latitude\", \"Longitude\"]),\n",
    "\t\t           (\"Processamento\", \"Coordenadas Ausentes. Inserido coordenadas do Município\")]\"\"\"\n",
    "        df = self.register_log(df, log, null_coords)\n",
    "\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Latitude_x\": \"Latitude\",\n",
    "                \"Longitude_x\": \"Longitude\",\n",
    "                \"Latitude_y\": \"Latitude_ibge\",\n",
    "                \"Longitude_y\": \"Longitude_ibge\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def intersect_coordinates_on_poligon(\n",
    "        self, df: pd.DataFrame, check_municipio: bool = True\n",
    "    ):\n",
    "        for column in [\"Latitude\", \"Longitude\"]:\n",
    "            df[column] = pd.to_numeric(df[column], errors=\"coerce\").astype(\"float\")\n",
    "        regions = gpd.read_file(IBGE_POLIGONO)\n",
    "\n",
    "        # Convert pandas dataframe to geopandas df with geometry point given coordinates\n",
    "        gdf_points = gpd.GeoDataFrame(\n",
    "            df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude)\n",
    "        )\n",
    "\n",
    "        # Set the same coordinate reference system (CRS) as the regions shapefile\n",
    "        gdf_points.crs = regions.crs\n",
    "\n",
    "        # Spatial join points to the regions\n",
    "        gdf = gpd.sjoin(gdf_points, regions, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "        if check_municipio:\n",
    "            # Check correctness of Coordinates\n",
    "            check_coords = gdf.Código_Município != gdf.CD_MUN\n",
    "\n",
    "            log = \"\"\"[(\"Colunas\", [\"Código_Município\", \"Município\", \"UF\"]),\n",
    "\t\t\t\t  \t (\"Processamento\", \"Informações substituídas  pela localização correta das coordenadas.\")\t\t      \n",
    "\t\t\t\t  \"\"\"\n",
    "\t\t\tself.register_log(gdf, log, check_coords)\n",
    "\n",
    "\t\t\tgdf.drop(['Código_Município', 'Município', 'UF'], axis=1, inplace=True)\n",
    "\n",
    "\t\tgdf.rename(\n",
    "\t\t\tcolumns={\n",
    "\t\t\t\t'CD_MUN': 'Código_Município',\n",
    "\t\t\t\t'NM_MUN': 'Município',\n",
    "\t\t\t\t'SIGLA_UF': 'UF',\n",
    "\t\t\t},\n",
    "\t\t\tinplace=True,\n",
    "\t\t)\n",
    "\n",
    "\t\treturn gdf\n",
    "\n",
    "\tdef validate_coordinates(self, df: pd.DataFrame, check_municipio: bool = True) -> pd.DataFrame:\n",
    "\t\t\"\"\"\n",
    "\t\tValidates the coordinates in the given DataFrame.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t        df: The DataFrame containing the coordinates to be validated.\n",
    "\t\t        check_municipio: A boolean indicating whether to check the municipality information (default: True).\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t        pd.DataFrame: The DataFrame with validated coordinates.\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t        None\n",
    "\t\t\"\"\"\n",
    "\t\tself.verify_shapefile_folder()\n",
    "\t\tif check_municipio:\n",
    "\t\t\tdf = self.fill_nan_coordinates(df)\n",
    "\t\treturn self.intersect_coordinates_on_poligon(df, check_municipio)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef _simplify_sources(df):\n",
    "\t\tdf['Fonte'] = df['Fonte'].str.replace(\n",
    "\t\t\t'ICAO-CANALIZACAO-VOR/ILS/DME | AISWEB-CANALIZACAO-VOR/ILS/DME',\n",
    "\t\t\t'CANALIZACAO-VOR/ILS/DME',\n",
    "\t\t)\n",
    "\t\tdf['Fonte'] = df['Fonte'].str.replace(\n",
    "\t\t\tr'(ICAO-)?(AISWEB-)?CANALIZACAO-VOR/ILS/DME', 'CANALIZACAO-VOR/ILS/DME', regex=True\n",
    "\t\t)\n",
    "\n",
    "\t\treturn df\n",
    "\n",
    "\tdef _format(\n",
    "\t\tself,\n",
    "\t\tdfs: List,  # List with the individual API sources\n",
    "\t) -> pd.DataFrame:  # Processed DataFrame\n",
    "\t\taero = dfs.pop()\n",
    "\t\tanatel = pd.concat(dfs, ignore_index=True)\n",
    "\t\tdf = merge_on_frequency(anatel, aero)\n",
    "\t\tdf = self.validate_coordinates(df)\n",
    "\t\tdf = self._simplify_sources(df)\n",
    "\t\tdf.sort_values(['Frequência', 'Latitude', 'Longitude'], ignore_index=True, inplace=True)\n",
    "\t\treturn df.loc[:, self.columns]\n",
    "\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = Estacoes(limit=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`=======`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class Estacoes(Base):\n",
    "    \"\"\"Classe auxiliar para agregar os dados originários da Anatel\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sql_params: dict = SQLSERVER_PARAMS,\n",
    "        mongo_uri: str = MONGO_URI,\n",
    "        limit: int = 0,\n",
    "        parallel: bool = True,\n",
    "    ):\n",
    "        self.sql_params = sql_params\n",
    "        self.mongo_uri = mongo_uri\n",
    "        self.limit = limit\n",
    "        self.parallel = parallel\n",
    "        self.init_data_sources()\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return COLS_SRD\n",
    "\n",
    "    def build_from_sources(self) -> pd.DataFrame:\n",
    "        return self._format([s.df() for s in self.sources.values()])\n",
    "\n",
    "    @property\n",
    "    def stem(self):\n",
    "        return \"anatel\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _update_source(class_instance):\n",
    "        class_instance.update()\n",
    "        class_instance.save()\n",
    "        return class_instance\n",
    "\n",
    "    def init_data_sources(self):\n",
    "        self.sources = {\n",
    "            \"telecom\": Telecom(self.mongo_uri, self.limit),\n",
    "            \"smp\": SMP(self.mongo_uri, self.limit),\n",
    "            \"srd\": SRD(self.mongo_uri),\n",
    "            \"stel\": Stel(self.sql_params),\n",
    "            \"radcom\": Radcom(self.sql_params),\n",
    "            \"aero\": Aero(),\n",
    "        }\n",
    "\n",
    "    def extraction(self) -> L:\n",
    "        if self.parallel:\n",
    "            sources = parallel(\n",
    "                Estacoes._update_source,\n",
    "                self.sources.values(),\n",
    "                n_workers=len(self.sources),\n",
    "                progress=True,\n",
    "            )\n",
    "        else:\n",
    "            sources = L(self._update_source(s) for s in self.sources.values())\n",
    "        return sources.attrgot(\"df\")\n",
    "\n",
    "    @staticmethod\n",
    "    def verify_shapefile_folder():\n",
    "        # Convert the file paths to Path objects\n",
    "        shapefile_path = Path(IBGE_POLIGONO)\n",
    "        parent_folder = shapefile_path.parent\n",
    "        parent_folder.mkdir(exist_ok=True, parents=True)\n",
    "        zip_file_path = parent_folder.with_suffix(\".zip\")\n",
    "\n",
    "        # Check if all required files exist\n",
    "        required_files = L(\".cpg\", \".dbf\", \".prj\", \".shx\").map(\n",
    "            shapefile_path.with_suffix\n",
    "        )\n",
    "        if not all(required_files.map(Path.is_file)):\n",
    "            # shutil.rmtree(str(shapefile_path.parent), ignore_errors=True)\n",
    "            parent_folder.ls().map(Path.unlink)\n",
    "            # Download and unzip the zipped folder\n",
    "            urllib.request.urlretrieve(MALHA_IBGE, zip_file_path)\n",
    "            with ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(parent_folder)\n",
    "            zip_file_path.unlink()\n",
    "\n",
    "    def fill_nan_coordinates(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame com os dados da Anatel\n",
    "    ) -> pd.DataFrame:  # DataFrame com as coordenadas validadas na base do IBGE\n",
    "        \"\"\"Valida as coordenadas consultado a Base Corporativa do IBGE, excluindo o que já está no cache na versão anterior\"\"\"\n",
    "\n",
    "        municipios = pd.read_csv(\n",
    "            IBGE_MUNICIPIOS,\n",
    "            usecols=[\"Código_Município\", \"Latitude\", \"Longitude\"],\n",
    "            dtype=\"string[pyarrow]\",\n",
    "            dtype_backend=\"pyarrow\",\n",
    "        )\n",
    "\n",
    "        df = pd.merge(df, municipios, on=\"Código_Município\", how=\"left\", copy=False)\n",
    "\n",
    "        null_coords = df.Latitude_x.isna() | df.Longitude_x.isna()\n",
    "\n",
    "        df.loc[null_coords, [\"Latitude_x\", \"Longitude_x\"]] = df.loc[\n",
    "            null_coords, [\"Latitude_y\", \"Longitude_y\"]\n",
    "        ]\n",
    "\n",
    "        log = \"\"\"[(\"Colunas\", [\"Latitude\", \"Longitude\"]),\n",
    "\t\t           (\"Processamento\", \"Coordenadas Ausentes. Inserido coordenadas do Município\")]\"\"\"\n",
    "        df = self.register_log(df, log, null_coords)\n",
    "\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Latitude_x\": \"Latitude\",\n",
    "                \"Longitude_x\": \"Longitude\",\n",
    "                \"Latitude_y\": \"Latitude_ibge\",\n",
    "                \"Longitude_y\": \"Longitude_ibge\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def intersect_coordinates_on_poligon(\n",
    "        self, df: pd.DataFrame, check_municipio: bool = True\n",
    "    ):\n",
    "        for column in [\"Latitude\", \"Longitude\"]:\n",
    "            df[column] = pd.to_numeric(df[column], errors=\"coerce\").astype(\"float\")\n",
    "        regions = gpd.read_file(IBGE_POLIGONO)\n",
    "\n",
    "        # Convert pandas dataframe to geopandas df with geometry point given coordinates\n",
    "        gdf_points = gpd.GeoDataFrame(\n",
    "            df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude)\n",
    "        )\n",
    "\n",
    "        # Set the same coordinate reference system (CRS) as the regions shapefile\n",
    "        gdf_points.crs = regions.crs\n",
    "\n",
    "        # Spatial join points to the regions\n",
    "        gdf = gpd.sjoin(gdf_points, regions, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "        if check_municipio:\n",
    "            # Check correctness of Coordinates\n",
    "            check_coords = gdf.Código_Município != gdf.CD_MUN\n",
    "\n",
    "            log = \"\"\"[(\"Colunas\", [\"Código_Município\", \"Município\", \"UF\"]),\n",
    "\t\t\t\t  \t (\"Processamento\", \"Informações substituídas  pela localização correta das coordenadas.\")\t\t      \n",
    "\t\t\t\t  \"\"\"\n",
    "            self.register_log(gdf, log, check_coords)\n",
    "\n",
    "            gdf.drop([\"Código_Município\", \"Município\", \"UF\"], axis=1, inplace=True)\n",
    "\n",
    "        gdf.rename(\n",
    "            columns={\n",
    "                \"CD_MUN\": \"Código_Município\",\n",
    "                \"NM_MUN\": \"Município\",\n",
    "                \"SIGLA_UF\": \"UF\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        return gdf\n",
    "\n",
    "    def validate_coordinates(\n",
    "        self, df: pd.DataFrame, check_municipio: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Validates the coordinates in the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "                df: The DataFrame containing the coordinates to be validated.\n",
    "                check_municipio: A boolean indicating whether to check the municipality information (default: True).\n",
    "\n",
    "        Returns:\n",
    "                pd.DataFrame: The DataFrame with validated coordinates.\n",
    "\n",
    "        Raises:\n",
    "                None\n",
    "        \"\"\"\n",
    "        self.verify_shapefile_folder()\n",
    "        if check_municipio:\n",
    "            df = self.fill_nan_coordinates(df)\n",
    "        return self.intersect_coordinates_on_poligon(df, check_municipio)\n",
    "\n",
    "    def _format(\n",
    "        self,\n",
    "        dfs: List,  # List with the individual API sources\n",
    "    ) -> pd.DataFrame:  # Processed DataFrame\n",
    "        aero = dfs.pop()\n",
    "        anatel = pd.concat(dfs, ignore_index=True)\n",
    "        df = self.validate_coordinates(merge_on_frequency(anatel, aero))\n",
    "        df.sort_values(\n",
    "            [\"Frequência\", \"Latitude\", \"Longitude\"], ignore_index=True, inplace=True\n",
    "        )\n",
    "        return df.loc[:, self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: fals\n",
    "SQLSERVER_PARAMS = dict(\n",
    "\tdriver='{ODBC Driver 17 for SQL Server}',\n",
    "\tserver='ANATELBDRO05',\n",
    "\tdatabase='SITARWEB',\n",
    "\ttrusted_conn=False,\n",
    "\tmult_results=True,\n",
    "\tencrypt=False,\n",
    "\tusername=os.environ['USERNAME'],\n",
    "\tpassword=os.environ['PASSWORD'],\n",
    "\ttimeout=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = Estacoes(sql_params=SQLSERVER_PARAMS, limit=100000, parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>>>>>> 097aa98614b8d9e9f7c01af2511baaef3968e366`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "anatelbdro06:27017: [Errno -2] Name or service not known, Timeout: 5.0s, Topology Description: <TopologyDescription id: 65521e9835f63e2badf88e13, topology_type: Unknown, servers: [<ServerDescription ('anatelbdro06', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('anatelbdro06:27017: [Errno -2] Name or service not known')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/concurrent/futures/process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/concurrent/futures/process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/fastcore/parallel.py\", line 46, in _call\n    return g(item)\n  File \"/tmp/ipykernel_44908/951249670.py\", line 31, in _update_source\n    class_instance.update()\n  File \"/mnt/c/Users/rsilva/OneDrive - ANATEL/Code/anateldb/extracao/datasources/base.py\", line 125, in update\n    self.df = self._format(self.extraction())\n  File \"/mnt/c/Users/rsilva/OneDrive - ANATEL/Code/anateldb/extracao/datasources/telecom.py\", line 66, in extraction\n    df = self._extract(self.collection, pipeline)\n  File \"/mnt/c/Users/rsilva/OneDrive - ANATEL/Code/anateldb/extracao/datasources/mosaico.py\", line 51, in _extract\n    [c for c in collection.aggregate(pipeline)], copy=False, dtype=dtype\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/collection.py\", line 2721, in aggregate\n    with self.__database.client._tmp_session(session, close=False) as s:\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/contextlib.py\", line 113, in __enter__\n    return next(self.gen)\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/mongo_client.py\", line 1885, in _tmp_session\n    s = self._ensure_session(session)\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/mongo_client.py\", line 1868, in _ensure_session\n    return self.__start_session(True, causal_consistency=False)\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/mongo_client.py\", line 1811, in __start_session\n    self._topology._check_implicit_session_support()\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/topology.py\", line 583, in _check_implicit_session_support\n    self._check_session_support()\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/topology.py\", line 599, in _check_session_support\n    self._select_servers_loop(\n  File \"/home/melinda/micromamba/envs/dados/lib/python3.8/site-packages/pymongo/topology.py\", line 269, in _select_servers_loop\n    raise ServerSelectionTimeoutError(\npymongo.errors.ServerSelectionTimeoutError: anatelbdro06:27017: [Errno -2] Name or service not known, Timeout: 5.0s, Topology Description: <TopologyDescription id: 65521e9835f63e2badf88e13, topology_type: Unknown, servers: [<ServerDescription ('anatelbdro06', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('anatelbdro06:27017: [Errno -2] Name or service not known')>]>\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dfs \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39;49mextraction()\n",
      "\u001b[1;32m/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextraction\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m L:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \t\tsources \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \t\t\tEstacoes\u001b[39m.\u001b[39;49m_update_source,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \t\t\t\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msources\u001b[39m.\u001b[39;49mvalues(),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \t\t\tn_workers\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msources),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \t\t\tprogress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \t\t)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \t\u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/melinda/code/wincode/anateldb/nbs/04_estacoes.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \t\tsources \u001b[39m=\u001b[39m L(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_source(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastcore/parallel.py:117\u001b[0m, in \u001b[0;36mparallel\u001b[0;34m(f, items, n_workers, total, progress, pause, method, threadpool, timeout, chunksize, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m total \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(items)\n\u001b[1;32m    116\u001b[0m     r \u001b[39m=\u001b[39m progress_bar(r, total\u001b[39m=\u001b[39mtotal, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m L(r)\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastcore/foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastcore/foundation.py:106\u001b[0m, in \u001b[0;36mL.__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39mrest, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m (use_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_array(items):\n\u001b[0;32m--> 106\u001b[0m         items \u001b[39m=\u001b[39m listify(items, \u001b[39m*\u001b[39;49mrest, use_list\u001b[39m=\u001b[39;49muse_list, match\u001b[39m=\u001b[39;49mmatch)\n\u001b[1;32m    107\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(items)\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastcore/basics.py:66\u001b[0m, in \u001b[0;36mlistify\u001b[0;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mlist\u001b[39m): res \u001b[39m=\u001b[39m o\n\u001b[1;32m     65\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_array(o): res \u001b[39m=\u001b[39m [o]\n\u001b[0;32m---> 66\u001b[0m \u001b[39melif\u001b[39;00m is_iter(o): res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(o)\n\u001b[1;32m     67\u001b[0m \u001b[39melse\u001b[39;00m: res \u001b[39m=\u001b[39m [o]\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m match \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastprogress/fastprogress.py:50\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_interrupt()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mfor\u001b[39;00m i,o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen):\n\u001b[1;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal: \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[39myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/concurrent/futures/process.py:484\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    479\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    485\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    486\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/micromamba/envs/dados/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: anatelbdro06:27017: [Errno -2] Name or service not known, Timeout: 5.0s, Topology Description: <TopologyDescription id: 65521e9835f63e2badf88e13, topology_type: Unknown, servers: [<ServerDescription ('anatelbdro06', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('anatelbdro06:27017: [Errno -2] Name or service not known')>]>"
     ]
    }
   ],
   "source": [
    "dfs = st.extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<<<<<<< HEAD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`=======`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Fonte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1143</td>\n",
       "      <td>-32.340056</td>\n",
       "      <td>-54.223889</td>\n",
       "      <td>NDB - MELO</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>-22.923333</td>\n",
       "      <td>-42.071500</td>\n",
       "      <td>NDB - CABO FRIO</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2050</td>\n",
       "      <td>-5.386167</td>\n",
       "      <td>-35.531000</td>\n",
       "      <td>NDB - MAXARANGUAPE</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2100</td>\n",
       "      <td>-19.561000</td>\n",
       "      <td>-46.964667</td>\n",
       "      <td>NDB - ARAXA</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2250</td>\n",
       "      <td>-25.408667</td>\n",
       "      <td>-54.621667</td>\n",
       "      <td>NDB - ITAIPU</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>995.0000</td>\n",
       "      <td>-23.631380</td>\n",
       "      <td>-46.652060</td>\n",
       "      <td>DME - AEROPORTO DE CONGONHAS 34X</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>995.0000</td>\n",
       "      <td>-5.771808</td>\n",
       "      <td>-35.350192</td>\n",
       "      <td>DME - SAO GONCALO 34X</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>995.0000</td>\n",
       "      <td>-9.336946</td>\n",
       "      <td>-54.952428</td>\n",
       "      <td>DME - CACHIMBO 34X</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>995.0000</td>\n",
       "      <td>-9.509805</td>\n",
       "      <td>-35.786944</td>\n",
       "      <td>DME - IMC 34X</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>997.0000</td>\n",
       "      <td>-15.878367</td>\n",
       "      <td>-47.906864</td>\n",
       "      <td>DME - BRASILIA 36X</td>\n",
       "      <td>AISGEO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2995 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequência   Latitude  Longitude                          Entidade  \\\n",
       "0         0.1143 -32.340056 -54.223889                       NDB - MELO    \n",
       "1         0.2000 -22.923333 -42.071500                  NDB - CABO FRIO    \n",
       "2         0.2050  -5.386167 -35.531000               NDB - MAXARANGUAPE    \n",
       "3         0.2100 -19.561000 -46.964667                      NDB - ARAXA    \n",
       "4         0.2250 -25.408667 -54.621667                     NDB - ITAIPU    \n",
       "...          ...        ...        ...                               ...   \n",
       "2990    995.0000 -23.631380 -46.652060  DME - AEROPORTO DE CONGONHAS 34X   \n",
       "2991    995.0000  -5.771808 -35.350192             DME - SAO GONCALO 34X   \n",
       "2992    995.0000  -9.336946 -54.952428                DME - CACHIMBO 34X   \n",
       "2993    995.0000  -9.509805 -35.786944                     DME - IMC 34X   \n",
       "2994    997.0000 -15.878367 -47.906864                DME - BRASILIA 36X   \n",
       "\n",
       "       Fonte  \n",
       "0     AISGEO  \n",
       "1     AISGEO  \n",
       "2     AISGEO  \n",
       "3     AISGEO  \n",
       "4     AISGEO  \n",
       "...      ...  \n",
       "2990  AISGEO  \n",
       "2991  AISGEO  \n",
       "2992  AISGEO  \n",
       "2993  AISGEO  \n",
       "2994  AISGEO  \n",
       "\n",
       "[2995 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aero = dfs.pop()\n",
    "aero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fonte\n",
       "ICAO                                             1871\n",
       "ICAO | AISWEB                                     265\n",
       "AISGEO                                            230\n",
       "ICAO-CANALIZACAO-VOR                              174\n",
       "RADARES                                           154\n",
       "AISWEB                                            103\n",
       "AISWEB-CANALIZACAO-VOR                             78\n",
       "ICAO-CANALIZACAO-VOR | AISWEB-CANALIZACAO-VOR      48\n",
       "ICAO | AISGEO                                      46\n",
       "REDEMET                                            26\n",
       "Name: count, dtype: Int64"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aero.Fonte.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "O Agrupamento por colunas únicas não tem o comprimento esperado: 0!= 2110",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/rsilva/rfdatahub/nbs/04_estacoes.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsas.anatel.gov.br/home/rsilva/rfdatahub/nbs/04_estacoes.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m anatel \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsas.anatel.gov.br/home/rsilva/rfdatahub/nbs/04_estacoes.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m merge_on_frequency(anatel, aero)\n",
      "File \u001b[0;32m/home/rsilva/rfdatahub/extracao/format.py:198\u001b[0m, in \u001b[0;36mmerge_on_frequency\u001b[0;34m(df_left, df_right, on, cols2merge)\u001b[0m\n\u001b[1;32m    194\u001b[0m df_both_left \u001b[39m=\u001b[39m df_both\u001b[39m.\u001b[39mgroupby(filter_left_cols, as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mfirst()\n\u001b[1;32m    195\u001b[0m df_both_right \u001b[39m=\u001b[39m df_both\u001b[39m.\u001b[39mgroupby(filter_right_cols, as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mfirst()\n\u001b[1;32m    197\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mlen\u001b[39m(df_both_left) \u001b[39m==\u001b[39m intersection_left\n\u001b[1;32m    199\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mO Agrupamento por colunas únicas não tem o comprimento esperado: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df_both_left)\u001b[39m}\u001b[39;00m\u001b[39m!= \u001b[39m\u001b[39m{\u001b[39;00mintersection_left\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    202\u001b[0m     \u001b[39mlen\u001b[39m(df_both_right) \u001b[39m==\u001b[39m intersection_right\n\u001b[1;32m    203\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df_both_right)\u001b[39m}\u001b[39;00m\u001b[39m!= \u001b[39m\u001b[39m{\u001b[39;00mintersection_right\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m df_both_far_left \u001b[39m=\u001b[39m df_both_left[df_both_left\u001b[39m.\u001b[39mDistance \u001b[39m>\u001b[39m MAX_DIST]\n",
      "\u001b[0;31mAssertionError\u001b[0m: O Agrupamento por colunas únicas não tem o comprimento esperado: 0!= 2110"
     ]
    }
   ],
   "source": [
    "anatel = pd.concat(dfs, ignore_index=True)\n",
    "df = merge_on_frequency(anatel, aero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/rsilva/rfdatahub/extracao/format.py\u001b[0m(198)\u001b[0;36mmerge_on_frequency\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    196 \u001b[0;31m\tassert (\n",
      "\u001b[0m\u001b[0;32m    197 \u001b[0;31m                \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_both_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mintersection_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 198 \u001b[0;31m\t), f'O Agrupamento por colunas únicas não tem o comprimento esperado: {len(df_both_left)}!= {intersection_left}'\n",
      "\u001b[0m\u001b[0;32m    199 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    200 \u001b[0;31m\tassert (\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frequência', 'Entidade_x', 'Fistel', 'Número_Estação', 'Município', 'Código_Município', 'UF', 'Latitude_x', 'Longitude_x', 'Classe', 'Num_Serviço', 'Classe_Emissão', 'Largura_Emissão(kHz)', 'Validade_RF', 'Status', 'Fonte_x', 'Multiplicidade', 'Log', 'Altura_Estação', 'Potência_Transmissor(W)', 'Ganho_Antena(dBd)', 'Ângulo_Elevação_Antena', 'Azimute_Antena', 'Altura_Antena(m)', 'Atenuação_Linha(db/100m)', 'Perdas_Acessórias_Linha(db)', 'Padrão_Antena(dBd)']\n",
      "['Frequência', 'Entidade_x', 'Fistel', 'Número_Estação', 'Município', 'Código_Município', 'UF', 'Latitude_x', 'Longitude_x', 'Classe', 'Num_Serviço', 'Classe_Emissão', 'Largura_Emissão(kHz)', 'Validade_RF', 'Status', 'Fonte_x', 'Multiplicidade', 'Log', 'Altura_Estação', 'Potência_Transmissor(W)', 'Ganho_Antena(dBd)', 'Ângulo_Elevação_Antena', 'Azimute_Antena', 'Altura_Antena(m)', 'Atenuação_Linha(db/100m)', 'Perdas_Acessórias_Linha(db)', 'Padrão_Antena(dBd)']\n"
     ]
    }
   ],
   "source": [
    "%debug]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>>>>>> 097aa98614b8d9e9f7c01af2511baaef3968e366`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
