{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp updates\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização\n",
    "\n",
    "> Este módulo atualiza as bases. Executa as queries sql do STEL, RADCOM e baixa os arquivos de estações e plano básico do MOSAICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Union\n",
    "from urllib.request import urlretrieve, URLError\n",
    "import xmltodict\n",
    "from zipfile import ZipFile\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid, ArrowTypeError\n",
    "from unidecode import unidecode\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.foundation import L\n",
    "from fastcore.test import test_eq\n",
    "from tqdm.auto import tqdm\n",
    "import pyodbc\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from anateldb.constants import *\n",
    "from anateldb.format import parse_bw, format_types, input_coordenates\n",
    "from anateldb.functionsdb import ConsultaSRD\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def connect_db(server: str = 'ANATELBDRO05', # Servidor do Banco de Dados\n",
    "               database: str = 'SITARWEB', # Nome do Banco de Dados\n",
    "               trusted_conn: str = 'yes', # Conexão Segura: yes | no\n",
    "               mult_results: bool = True, # Múltiplos Resultados\n",
    "              )->pyodbc.Connection:\n",
    "    \"\"\"Conecta ao Banco `server` e retorna o 'cursor' (iterador) do Banco\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        f\"Trusted_Connection={trusted_conn};\"\n",
    "        f\"MultipleActiveResultSets={mult_results};\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#echo: false\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM,STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_estações(row: dict)->dict:\n",
    "    \"\"\"Given a row in a MongoDB ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    \n",
    "    d = {k.replace('@', '').lower():row[k] for k in (\"@SiglaServico\", \"@id\", \"@state\",\n",
    "        \"@entidade\",\n",
    "        \"@fistel\",\n",
    "        \"@cnpj\",\n",
    "        \"@municipio\",\n",
    "        \"@uf\")}\n",
    "    entidade = row.get('entidade', {})\n",
    "    d.update({k.replace('@', '').lower():entidade[k] for k in ('@num_servico', '@habilitacao_DataValFreq')})\n",
    "    administrativo = row.get('administrativo', {})\n",
    "    d['numero_estacao'] = administrativo.get('@numero_estacao')\n",
    "    estacao = row.get('estacao_principal', {})\n",
    "    d.update({k.replace('@', '').lower():estacao[k] for k in ('@latitude', '@longitude')})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_estações(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    \n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('estacao_rd.xml') as myfile:\n",
    "            estacoes = xmltodict.parse(myfile.read())\n",
    "            \n",
    "    assert 'estacao_rd' in estacoes, \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    assert 'row' in estacoes['estacao_rd'], \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    \n",
    "    df = pd.DataFrame(L(estacoes['estacao_rd']['row']).map(_parse_estações))\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df.columns = NEW_ESTACOES    \n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_pb(row: dict)->dict:\n",
    "    \"\"\"Given a row in the MongoDB file canais.zip ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    return {unidecode(k).lower().replace(\"@\", \"\"): v  for k,v in row.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_plano_basico(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe\"\"\"    \n",
    "    df = L()\n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('plano_basicoTVFM.xml') as myfile:\n",
    "            pbtvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('plano_basicoAM.xml') as myfile:\n",
    "            pbam = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosTVFM.xml') as myfile:\n",
    "            stvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosAM.xml') as myfile:\n",
    "            sam = xmltodict.parse(myfile.read())    \n",
    "            \n",
    "    for base in (pbtvfm, stvfm, pbam, sam):\n",
    "        assert 'plano_basico' in base, \"The xml files inside canais.zip is not in the expected format\"\n",
    "        assert 'row' in base['plano_basico'], \"The xml file inside canais.zip is not in the expected format\"\n",
    "        df.extend(L(base['plano_basico']['row']).map(_parse_pb))\n",
    "        \n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)    \n",
    "    df.columns = NEW_PB\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df.loc[:, 'Frequência'] = df.Frequência.str.replace(',', '.')\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == '', c] = pd.NA\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_mosaico(df: pd.DataFrame, # DataFrame com os dados de Estações e Plano_Básico mesclados \n",
    "                pasta: Union[str, Path], # Pasta com os dados de municípios para imputar coordenadas ausentes\n",
    ") -> pd.DataFrame: # DataFrame com os dados mesclados e limpos\n",
    "    \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        df.loc[df[col_x].isna(), col_x] = df.loc[df[col_x].isna(), col_y]\n",
    "        df.loc[df[col_y].isna(), col_y] = df.loc[df[col_y].isna(), col_x]\n",
    "        if df[col_x].notna().sum() > df[col_y].notna().sum():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    # df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor == \"\", \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor == \"\", \"Longitude_Estação\"\n",
    "    # ]\n",
    "    \n",
    "    # df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor.isna(), \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor.isna(), \"Longitude_Estação\"\n",
    "    # ]\n",
    "    # df.drop([\"Latitude_Estação\", \"Longitude_Estação\"], axis=1, inplace=True)\n",
    "    # df.rename(\n",
    "    #     columns={\n",
    "    #         \"Latitude_Transmissor\": \"Latitude\",\n",
    "    #         \"Longitude_Transmissor\": \"Longitude\",\n",
    "    #     },\n",
    "    #     inplace=True,\n",
    "    # )\n",
    "\n",
    "    df = input_coordenates(df, pasta)\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.str.replace(\",\", \".\")    \n",
    "    df = df[df.Frequência.notna()].reset_index(drop=True)\n",
    "\n",
    "    # Removido o código abaixo devido a inconsistência no Mosaico\n",
    "    # if freq_nans := df[df.Frequência.isna()].Id.tolist():\n",
    "    #     complement_df = scrape_dataframe(freq_nans)\n",
    "    #     df.loc[\n",
    "    #         df.Frequência.isna(),\n",
    "    #         [\n",
    "    #             \"Status\",\n",
    "    #             \"Entidade\",\n",
    "    #             \"Fistel\",\n",
    "    #             \"Frequência\",\n",
    "    #             \"Classe\",\n",
    "    #             \"Num_Serviço\",\n",
    "    #             \"Município\",\n",
    "    #             \"UF\",\n",
    "    #         ],\n",
    "    #     ] = complement_df.values\n",
    "\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "    df.loc[df.Serviço == \"OM\", \"Frequência\"] = df.loc[\n",
    "        df.Serviço == \"OM\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    return df.drop_duplicates(keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_df(df: pd.DataFrame, folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Format, Save and return a dataframe\"\"\"\n",
    "    df = format_types(df, stem)\n",
    "    df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    df = df.dropna(subset=['Latitude', 'Longitude']).reset_index(drop=True)\n",
    "    try:\n",
    "        file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "        df.to_parquet(file, compression=\"gzip\", index=False)\n",
    "    except (ArrowInvalid, ArrowTypeError):\n",
    "        file.unlink(missing_ok=True)\n",
    "        try:\n",
    "            file = Path(f\"{folder}/{stem}.fth\")\n",
    "            df.to_feather(file)\n",
    "        except (ArrowInvalid, ArrowTypeError):\n",
    "            file.unlink(missing_ok=True)\n",
    "            try:\n",
    "                file = Path(f\"{folder}/{stem}.xlsx\")\n",
    "                with pd.ExcelWriter(file) as wb:\n",
    "                    df.to_excel(\n",
    "                        wb, sheet_name=\"DataBase\", engine=\"openpyxl\", index=False\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Could not save {stem} to {file}\") from e\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_radcom(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    "        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            return _save_df(df, folder, \"radcom\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_stel(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder:Union[str, Path] # Pasta onde salvar os arquivos        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"bouncingBall\",\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            return _save_df(df, folder, \"stel\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stel = update_stel(Path.cwd().parent / 'dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_mosaico(        \n",
    "        mongo_client: MongoClient, # Objeto de conexão com o MongoDB\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela de Radiodifusão no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"Consolidando os dados do Mosaico...\", spinner=\"clock\"\n",
    "    ) as status:  \n",
    "        \n",
    "        database = mongo_client[\"sms\"]\n",
    "        # Database com as informações de Radio e difusão\n",
    "        collection = database[\"srd\"]\n",
    "\n",
    "        query = {}\n",
    "        projection = {\"SiglaServico\": 1.0, \"Status.state\": 1.0, \"licensee\": 1.0, \"NumFistel\": 1.0, \"frequency\": 1.0, \"stnClass\": 1.0, \"srd_planobasico.NomeMunicipio\": 1.0, \"srd_planobasico.SiglaUF\": 1.0, \"NumServico\": 1.0, \"estacao.NumEstacao\": 1.0, \"estacao.MedLatitudeDecimal\": 1.0, \"estacao.MedLongitudeDecimal\": 1.0, \"habilitacao.DataValFreq\": 1.0}\n",
    "\n",
    "        list_data = list(collection.find(query, projection = projection))\n",
    "        mosaico_df = pd.json_normalize(list_data)\n",
    "        mosaico_df = mosaico_df.drop(columns=['estacao'])\n",
    "        mosaico_df = mosaico_df[[\"frequency\",\n",
    "                                \"licensee\",\n",
    "                                \"NumFistel\",\n",
    "                                \"estacao.NumEstacao\",\n",
    "                                \"srd_planobasico.NomeMunicipio\",\n",
    "                                \"srd_planobasico.SiglaUF\",\n",
    "                                \"estacao.MedLatitudeDecimal\",\n",
    "                                \"estacao.MedLongitudeDecimal\",\n",
    "                                \"stnClass\",\n",
    "                                \"NumServico\",\n",
    "                                \"habilitacao.DataValFreq\",\n",
    "                                \"Status.state\"]]\n",
    "\n",
    "        mosaico_df.columns = RADIODIFUSAO\n",
    "        mosaico_df = mosaico_df[mosaico_df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\", na=False)].reset_index(drop=True)\n",
    "        for c in mosaico_df.columns:\n",
    "            mosaico_df.loc[mosaico_df[c] == \"\", c] = pd.NA\n",
    "        mosaico_df = mosaico_df.dropna(subset=['UF'])\n",
    "        mosaico_df = mosaico_df[mosaico_df.Frequência.notna()].reset_index(drop=True)\n",
    "\n",
    "        df = clean_mosaico(mosaico_df, folder)\n",
    "    return _save_df(df, folder, \"mosaico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update_licenciamento(mongo_client: MongoClient, # Objeto de conexão com o MongoDB\n",
    "                         folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    ")-> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela `licenciamento` no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "    database = mongo_client[\"sms\"]\n",
    "    collection = database[\"licenciamento\"]    \n",
    "    c = collection.find(MONGO_LIC, projection={k:1.0 for k in LICENCIAMENTO.keys()})\n",
    "    result = L()\n",
    "    for doc in tqdm(c):\n",
    "        result.append(doc)\n",
    "    df = pd.json_normalize(result)\n",
    "    df.drop('_id', axis=1, inplace=True)\n",
    "    df.rename(LICENCIAMENTO, axis=1, inplace=True)\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.replace(',', ' ')\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.strip().str.lstrip().str.rstrip().str.upper()\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.split(' ')\n",
    "    df = df.explode('Designacao_Emissão')\n",
    "    df.loc[df.Designacao_Emissão == '/', 'Designacao_Emissão'] = ''\n",
    "    df.loc[:, ['Largura_Emissão', 'Classe_Emissão']]  = df.Designacao_Emissão.apply(parse_bw).tolist()\n",
    "    df.drop('Designacao_Emissão', axis=1, inplace=True)\n",
    "    subset = ['Entidade', 'Longitude', 'Latitude', 'Classe', 'Frequência', 'Num_Serviço', 'Largura_Emissão', 'Classe_Emissão']\n",
    "    df_sub = df[~df.duplicated(subset=subset, keep='first')].reset_index(drop=True).copy()\n",
    "    df_sub = df_sub.set_index(subset).sort_index()\n",
    "    df_sub['Count'] = (df.groupby(subset).count()['Número_Estação']).tolist()\n",
    "    del df ; gc.collect()\n",
    "    df_sub = df_sub.reset_index()\n",
    "    return _save_df(df_sub, folder, 'licenciamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '4.0.5',\n",
       " 'gitVersion': '3739429dd92b92d1b0ab120911a23d50bf03c412',\n",
       " 'targetMinOS': 'Windows 7/Windows Server 2008 R2',\n",
       " 'modules': [],\n",
       " 'allocator': 'tcmalloc',\n",
       " 'javascriptEngine': 'mozjs',\n",
       " 'sysInfo': 'deprecated',\n",
       " 'versionArray': [4, 0, 5, 0],\n",
       " 'openssl': {'running': 'Windows SChannel'},\n",
       " 'buildEnvironment': {'distmod': '2008plus-ssl',\n",
       "  'distarch': 'x86_64',\n",
       "  'cc': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'ccflags': '/nologo /EHsc /W3 /wd4355 /wd4800 /wd4267 /wd4244 /wd4290 /wd4068 /wd4351 /wd4373 /we4013 /we4099 /we4930 /WX /errorReport:none /MD /O2 /Oy- /bigobj /utf-8 /Zc:rvalueCast /Zc:strictStrings /volatile:iso /Gw /Gy /Zc:inline',\n",
       "  'cxx': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'cxxflags': '/TP',\n",
       "  'linkflags': '/nologo /DEBUG /INCREMENTAL:NO /LARGEADDRESSAWARE /OPT:REF',\n",
       "  'target_arch': 'x86_64',\n",
       "  'target_os': 'windows'},\n",
       " 'bits': 64,\n",
       " 'debug': False,\n",
       " 'maxBsonObjectSize': 16777216,\n",
       " 'storageEngines': ['devnull', 'ephemeralForTest', 'mmapv1', 'wiredTiger'],\n",
       " 'ok': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "uri = input()\n",
    "mongo_client = MongoClient(uri)\n",
    "mongo_client.server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='install \"ipywidgets\" for Jupyter support')\n",
    "\n",
    "folder = Path.cwd().parent / 'dados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b71ec28f884fa2994f805d89055222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = update_licenciamento(mongo_client, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Num_Serviço</th>\n",
       "      <th>Largura_Emissão</th>\n",
       "      <th>Classe_Emissão</th>\n",
       "      <th>UF</th>\n",
       "      <th>Cod_Município</th>\n",
       "      <th>Município</th>\n",
       "      <th>Data_de_Validade</th>\n",
       "      <th>Número_Estação</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>Status</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>-42.0827</td>\n",
       "      <td>-4.02389</td>\n",
       "      <td>FX</td>\n",
       "      <td>7807.0</td>\n",
       "      <td>019</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>D7W</td>\n",
       "      <td>PI</td>\n",
       "      <td>2201507</td>\n",
       "      <td>BATALHA</td>\n",
       "      <td>2039-11-28</td>\n",
       "      <td>1012185475</td>\n",
       "      <td>50418766738</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALVES &amp; BATISTA ALARMES LTDA - ME</td>\n",
       "      <td>-48.984178</td>\n",
       "      <td>-23.115239</td>\n",
       "      <td>FX</td>\n",
       "      <td>149.19</td>\n",
       "      <td>019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3504503</td>\n",
       "      <td></td>\n",
       "      <td>2038-05-24</td>\n",
       "      <td>1006566675</td>\n",
       "      <td>50415983045</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALVES &amp; BATISTA ALARMES LTDA - ME</td>\n",
       "      <td>-48.984178</td>\n",
       "      <td>-23.115239</td>\n",
       "      <td>FX</td>\n",
       "      <td>149.19</td>\n",
       "      <td>019</td>\n",
       "      <td>16.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3504503</td>\n",
       "      <td></td>\n",
       "      <td>2038-05-24</td>\n",
       "      <td>1006566675</td>\n",
       "      <td>50415983045</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALVES &amp; BATISTA ALARMES LTDA - ME</td>\n",
       "      <td>-48.928081</td>\n",
       "      <td>-23.098297</td>\n",
       "      <td>FX</td>\n",
       "      <td>149.19</td>\n",
       "      <td>019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3504503</td>\n",
       "      <td></td>\n",
       "      <td>2038-05-24</td>\n",
       "      <td>1006566640</td>\n",
       "      <td>50415983045</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALVES &amp; BATISTA ALARMES LTDA - ME</td>\n",
       "      <td>-48.928081</td>\n",
       "      <td>-23.098297</td>\n",
       "      <td>FX</td>\n",
       "      <td>149.19</td>\n",
       "      <td>019</td>\n",
       "      <td>16.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3504503</td>\n",
       "      <td></td>\n",
       "      <td>2038-05-24</td>\n",
       "      <td>1006566640</td>\n",
       "      <td>50415983045</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735507</th>\n",
       "      <td>pedro luis lorenzetti</td>\n",
       "      <td>-48.836389</td>\n",
       "      <td>-22.631667</td>\n",
       "      <td>BR</td>\n",
       "      <td>171.06875</td>\n",
       "      <td>019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3526803</td>\n",
       "      <td></td>\n",
       "      <td>2030-09-05</td>\n",
       "      <td>534834183</td>\n",
       "      <td>50009553231</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735508</th>\n",
       "      <td>pedro luis lorenzetti</td>\n",
       "      <td>-48.836389</td>\n",
       "      <td>-22.631667</td>\n",
       "      <td>ML</td>\n",
       "      <td>166.46875</td>\n",
       "      <td>019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F3E</td>\n",
       "      <td>SP</td>\n",
       "      <td>3526803</td>\n",
       "      <td></td>\n",
       "      <td>2030-09-05 00:00:00.000</td>\n",
       "      <td>534834205</td>\n",
       "      <td>50009553231</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735509</th>\n",
       "      <td>willian diogo da costa</td>\n",
       "      <td>-53.486667</td>\n",
       "      <td>-24.948889</td>\n",
       "      <td>ML</td>\n",
       "      <td>157.58125</td>\n",
       "      <td>019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>F1W</td>\n",
       "      <td>PR</td>\n",
       "      <td>4104808</td>\n",
       "      <td></td>\n",
       "      <td>2033-12-11</td>\n",
       "      <td>699459265</td>\n",
       "      <td>50410908827</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735510</th>\n",
       "      <td>ÔMEGA SEGURANÇA E VIGILÂNCIA PATRIMONIAL LTDA ME</td>\n",
       "      <td>-35.734883</td>\n",
       "      <td>-9.627794</td>\n",
       "      <td>FB</td>\n",
       "      <td>161.37</td>\n",
       "      <td>019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>F1D</td>\n",
       "      <td>AL</td>\n",
       "      <td>2704302</td>\n",
       "      <td></td>\n",
       "      <td>2033-10-10</td>\n",
       "      <td>699260540</td>\n",
       "      <td>50410720518</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735511</th>\n",
       "      <td>ÔMEGA SEGURANÇA E VIGILÂNCIA PATRIMONIAL LTDA ME</td>\n",
       "      <td>-35.734883</td>\n",
       "      <td>-9.627794</td>\n",
       "      <td>ML</td>\n",
       "      <td>161.37</td>\n",
       "      <td>019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>F1D</td>\n",
       "      <td>AL</td>\n",
       "      <td>2704302</td>\n",
       "      <td></td>\n",
       "      <td>2033-10-10</td>\n",
       "      <td>699260531</td>\n",
       "      <td>50410720518</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735512 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Entidade   Longitude  \\\n",
       "0                                                           -42.0827   \n",
       "1                      ALVES & BATISTA ALARMES LTDA - ME  -48.984178   \n",
       "2                      ALVES & BATISTA ALARMES LTDA - ME  -48.984178   \n",
       "3                      ALVES & BATISTA ALARMES LTDA - ME  -48.928081   \n",
       "4                      ALVES & BATISTA ALARMES LTDA - ME  -48.928081   \n",
       "...                                                  ...         ...   \n",
       "735507                             pedro luis lorenzetti  -48.836389   \n",
       "735508                             pedro luis lorenzetti  -48.836389   \n",
       "735509                            willian diogo da costa  -53.486667   \n",
       "735510  ÔMEGA SEGURANÇA E VIGILÂNCIA PATRIMONIAL LTDA ME  -35.734883   \n",
       "735511  ÔMEGA SEGURANÇA E VIGILÂNCIA PATRIMONIAL LTDA ME  -35.734883   \n",
       "\n",
       "          Latitude Classe Frequência Num_Serviço Largura_Emissão  \\\n",
       "0         -4.02389     FX     7807.0         019         28000.0   \n",
       "1       -23.115239     FX     149.19         019            11.0   \n",
       "2       -23.115239     FX     149.19         019            16.0   \n",
       "3       -23.098297     FX     149.19         019            11.0   \n",
       "4       -23.098297     FX     149.19         019            16.0   \n",
       "...            ...    ...        ...         ...             ...   \n",
       "735507  -22.631667     BR  171.06875         019            11.0   \n",
       "735508  -22.631667     ML  166.46875         019            11.0   \n",
       "735509  -24.948889     ML  157.58125         019             7.6   \n",
       "735510   -9.627794     FB     161.37         019             7.6   \n",
       "735511   -9.627794     ML     161.37         019             7.6   \n",
       "\n",
       "       Classe_Emissão  UF Cod_Município Município         Data_de_Validade  \\\n",
       "0                 D7W  PI       2201507   BATALHA               2039-11-28   \n",
       "1                 F3E  SP       3504503                         2038-05-24   \n",
       "2                 F3E  SP       3504503                         2038-05-24   \n",
       "3                 F3E  SP       3504503                         2038-05-24   \n",
       "4                 F3E  SP       3504503                         2038-05-24   \n",
       "...               ...  ..           ...       ...                      ...   \n",
       "735507            F3E  SP       3526803                         2030-09-05   \n",
       "735508            F3E  SP       3526803            2030-09-05 00:00:00.000   \n",
       "735509            F1W  PR       4104808                         2033-12-11   \n",
       "735510            F1D  AL       2704302                         2033-10-10   \n",
       "735511            F1D  AL       2704302                         2033-10-10   \n",
       "\n",
       "       Número_Estação       Fistel      Status Count  \n",
       "0          1012185475  50418766738  LIC-LIC-01     1  \n",
       "1          1006566675  50415983045  LIC-LIC-01     1  \n",
       "2          1006566675  50415983045  LIC-LIC-01     1  \n",
       "3          1006566640  50415983045  LIC-LIC-01     1  \n",
       "4          1006566640  50415983045  LIC-LIC-01     1  \n",
       "...               ...          ...         ...   ...  \n",
       "735507      534834183  50009553231  LIC-LIC-01     1  \n",
       "735508      534834205  50009553231  LIC-LIC-01    92  \n",
       "735509      699459265  50410908827  LIC-LIC-01    12  \n",
       "735510      699260540  50410720518  LIC-LIC-01     1  \n",
       "735511      699260531  50410720518  LIC-LIC-01     1  \n",
       "\n",
       "[735512 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_base(\n",
    "    conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "    clientMongoDB: MongoClient, # Ojeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path] # Pasta onde salvar os arquivos    \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    # sourcery skip: use-fstring-for-concatenation\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na folder `folder`\"\"\"\n",
    "    stel = update_stel(conn, folder, ).loc[:, TELECOM]\n",
    "    radcom = update_radcom(conn, folder).loc[:, SRD]\n",
    "    mosaico = update_mosaico(clientMongoDB, folder).loc[:, RADIODIFUSAO]    \n",
    "    radcom[\"Num_Serviço\"] = \"231\"\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe_Emissão\"] = pd.NA\n",
    "    radcom[\"Largura_Emissão\"] = BW_MAP[\"231\"]\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Validade_RF\"] = pd.NA\n",
    "    radcom[\"Fonte\"] = \"SRD\"\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    mosaico[\"Fonte\"] = \"MOS\"\n",
    "    mosaico[\"Classe_Emissão\"] = pd.NA\n",
    "    mosaico[\"Largura_Emissão\"] = mosaico.Num_Serviço.map(BW_MAP)\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel])\n",
    "        .sort_values([\"Frequência\", \"Latitude\", \"Longitude\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd = rd.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    rd[\"BW(kHz)\"] = rd.Largura_Emissão.astype('string').fillna('-1').apply(parse_bw)\n",
    "    return _save_df(rd, folder, \"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import Request, urlopen\n",
    "# from urllib.error import URLError\n",
    "# req = Request(ESTACAO)\n",
    "# try:\n",
    "#     response = urlopen(req)\n",
    "# except URLError as e:\n",
    "#     if hasattr(e, 'reason'):\n",
    "#         print('We failed to reach a server.')\n",
    "#         print('Reason: ', e.reason)\n",
    "#     elif hasattr(e, 'code'):\n",
    "#         print('The server couldn\\'t fulfill the request.')\n",
    "#         print('Error code: ', e.code)\n",
    "# else:\n",
    "#     Path.cwd().joinpath('estações.zip').write_bytes(response.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anateldb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37a0fa21125bc68b41a424f43d92a26fa97b5ebccfac6eecdcaf85c09668024f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
