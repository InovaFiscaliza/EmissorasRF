{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp updates\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização\n",
    "\n",
    "> Este módulo atualiza as bases. Executa as queries sql do STEL, RADCOM e baixa os arquivos de estações e plano básico do MOSAICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Union\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid, ArrowTypeError\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.test import test_eq\n",
    "from fastcore.foundation import L\n",
    "from tqdm.auto import tqdm\n",
    "import pyodbc\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from extracao.constants import *\n",
    "from extracao.format import parse_bw\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def connect_db(\n",
    "    server: str = \"ANATELBDRO05\",  # Servidor do Banco de Dados\n",
    "    database: str = \"SITARWEB\",  # Nome do Banco de Dados\n",
    "    trusted_conn: str = \"yes\",  # Conexão Segura: yes | no\n",
    "    mult_results: bool = True,  # Múltiplos Resultados\n",
    ") -> pyodbc.Connection:\n",
    "    \"\"\"Conecta ao Banco `server` e retorna o 'cursor' (iterador) do Banco\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        f\"Trusted_Connection={trusted_conn};\"\n",
    "        f\"MultipleActiveResultSets={mult_results};\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#echo: false\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (SQL_RADCOM,SQL_STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_mosaico(\n",
    "    df: pd.DataFrame,  # DataFrame com os dados de Estações e Plano_Básico mesclados\n",
    "    pasta: Union[\n",
    "        str, Path\n",
    "    ],  # Pasta com os dados de municípios para imputar coordenadas ausentes\n",
    ") -> pd.DataFrame:  # DataFrame com os dados mesclados e limpos\n",
    "    \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "    # df = input_coordenates(df, pasta) # TODO: Implementar função de verificação de coordenadas diretamente no arquivo final base e eliminar essa chamada\n",
    "    df = df[\n",
    "        df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\", na=False)\n",
    "    ].reset_index(drop=True)\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    df.loc[\"Frequência\"] = df.Frequência.astype(\"str\").str.replace(\",\", \".\")\n",
    "    df = df[df.Frequência.notna()].reset_index(drop=True)\n",
    "    df.loc[\"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "    df.loc[df.Num_Serviço == \"205\", \"Frequência\"] = df.loc[\n",
    "        df.Num_Serviço == \"205\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    return df[df.Código_Município.notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_df(df: pd.DataFrame, folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Format, Save and return a dataframe\"\"\"\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\").str.lstrip().str.rstrip()\n",
    "    df = df.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    if \"Código_Município\" in df:\n",
    "        df = df[df.Código_Município.notna()].reset_index(drop=True)\n",
    "    try:\n",
    "        file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "        df.to_parquet(file, compression=\"gzip\", index=False)\n",
    "    except (ArrowInvalid, ArrowTypeError):\n",
    "        file.unlink(missing_ok=True)\n",
    "        try:\n",
    "            file = Path(f\"{folder}/{stem}.xlsx\")\n",
    "            with pd.ExcelWriter(file) as wb:\n",
    "                df.to_excel(wb, sheet_name=\"DataBase\", engine=\"openpyxl\", index=False)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not save {stem} to {file}\") from e\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_radcom(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`, com tratamento de erro de conectividade.\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:\n",
    "            return _extract_radcom(conn, folder)\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e\n",
    "\n",
    "\n",
    "def _extract_radcom(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    df = pd.read_sql_query(SQL_RADCOM, conn)\n",
    "    df[\"Entidade\"] = df.Entidade.str.rstrip().str.lstrip()\n",
    "    df[\"Num_Serviço\"] = \"231\"\n",
    "    df[\"Classe_Emissão\"] = pd.NA\n",
    "    df[\"Largura_Emissão(kHz)\"] = \"256\"\n",
    "    df[\"Validade_RF\"] = pd.NA\n",
    "    df[\"Status\"] = \"RADCOM\"\n",
    "    df[\"Fonte\"] = \"SRD\"\n",
    "    df[\"Multiplicidade\"] = \"1\"\n",
    "    a = df.Situação.isna()\n",
    "    df.loc[a, \"Classe\"] = df.loc[a, \"Fase\"]\n",
    "    df.loc[~a, \"Classe\"] = (\n",
    "        df.loc[~a, \"Fase\"].astype(\"string\")\n",
    "        + \"-\"\n",
    "        + df.loc[~a, \"Situação\"].astype(\"string\")\n",
    "    )\n",
    "    df.drop([\"Fase\", \"Situação\"], axis=1, inplace=True)\n",
    "    df = df.loc[:, COLUNAS]\n",
    "    return _save_df(df, folder, \"radcom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message='install \"ipywidgets\" for Jupyter support')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "folder = Path.cwd().parent / 'dados'\n",
    "# conn = connect_db()\n",
    "# radcom = update_radcom(conn, folder)\n",
    "# radcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_stel(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`, com tratamento de erro de conectividade.\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL\",\n",
    "        spinner=\"bouncingBall\",\n",
    "    ) as status:\n",
    "        try:\n",
    "            return _extract_stel(conn, folder)\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e\n",
    "\n",
    "\n",
    "def _extract_stel(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    stel = pd.read_sql_query(SQL_STEL, conn)\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    stel.loc[:, [\"Largura_Emissão(kHz)\", \"_\"]] = (\n",
    "        stel.Largura_Emissão.fillna(\"\").apply(parse_bw).tolist()\n",
    "    )\n",
    "    stel.drop([\"Largura_Emissão\", \"_\"], axis=1, inplace=True)\n",
    "    stel.loc[:, \"Validade_RF\"] = stel.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    stel.loc[stel.Unidade == \"kHz\", \"Frequência\"] = stel.loc[\n",
    "        stel.Unidade == \"kHz\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    stel.loc[stel.Unidade == \"GHz\", \"Frequência\"] = stel.loc[\n",
    "        stel.Unidade == \"GHz\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) * Decimal(1000))\n",
    "    stel.drop(\"Unidade\", axis=1, inplace=True)\n",
    "    stel[\"Multiplicidade\"] = 1\n",
    "    stel = stel.loc[:, COLUNAS]\n",
    "    return _save_df(stel, folder, \"stel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# stel = update_stel(conn, folder)\n",
    "# stel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_mosaico(\n",
    "    mongo_client: MongoClient,  # Objeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela de Radiodifusão no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"Consolidando os dados do Mosaico...\", spinner=\"clock\"\n",
    "    ) as status:\n",
    "\n",
    "        database = mongo_client[\"sms\"]\n",
    "        collection = database[\"srd\"]\n",
    "        list_data = list(collection.find(MONGO_SRD, projection=COLS_SRD.keys()))\n",
    "        mosaico = pd.json_normalize(list_data)\n",
    "        mosaico = mosaico.drop(columns=[\"estacao\"])\n",
    "        mosaico = mosaico[list(COLS_SRD.keys())]\n",
    "        mosaico.rename(COLS_SRD, axis=1, inplace=True)\n",
    "        mosaico = clean_mosaico(mosaico, folder)\n",
    "        mosaico[\"Fonte\"] = \"MOS\"\n",
    "        mosaico.loc[:, [\"Largura_Emissão(kHz)\", \"Classe_Emissão\"]] = (\n",
    "            mosaico.Num_Serviço.astype(\"string\").map(BW_MAP).apply(parse_bw).tolist()\n",
    "        )\n",
    "        mosaico.loc[mosaico.Classe_Emissão == \"\", \"Classe_Emissão\"] = pd.NA\n",
    "        mosaico[\"Multiplicidade\"] = 1\n",
    "        mosaico = mosaico.loc[:, COLUNAS]\n",
    "    return _save_df(mosaico, folder, \"mosaico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '4.0.5',\n",
       " 'gitVersion': '3739429dd92b92d1b0ab120911a23d50bf03c412',\n",
       " 'targetMinOS': 'Windows 7/Windows Server 2008 R2',\n",
       " 'modules': [],\n",
       " 'allocator': 'tcmalloc',\n",
       " 'javascriptEngine': 'mozjs',\n",
       " 'sysInfo': 'deprecated',\n",
       " 'versionArray': [4, 0, 5, 0],\n",
       " 'openssl': {'running': 'Windows SChannel'},\n",
       " 'buildEnvironment': {'distmod': '2008plus-ssl',\n",
       "  'distarch': 'x86_64',\n",
       "  'cc': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'ccflags': '/nologo /EHsc /W3 /wd4355 /wd4800 /wd4267 /wd4244 /wd4290 /wd4068 /wd4351 /wd4373 /we4013 /we4099 /we4930 /WX /errorReport:none /MD /O2 /Oy- /bigobj /utf-8 /Zc:rvalueCast /Zc:strictStrings /volatile:iso /Gw /Gy /Zc:inline',\n",
       "  'cxx': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'cxxflags': '/TP',\n",
       "  'linkflags': '/nologo /DEBUG /INCREMENTAL:NO /LARGEADDRESSAWARE /OPT:REF',\n",
       "  'target_arch': 'x86_64',\n",
       "  'target_os': 'windows'},\n",
       " 'bits': 64,\n",
       " 'debug': False,\n",
       " 'maxBsonObjectSize': 16777216,\n",
       " 'storageEngines': ['devnull', 'ephemeralForTest', 'mmapv1', 'wiredTiger'],\n",
       " 'ok': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "# uri = input()\n",
    "uri = 'mongodb://UserPython:Ox6TT1QvNhf#Ez#J*B@anatelbdro06:27017/?serverSelectionTimeoutMS=5000&connectTimeoutMS=10000&authSource=admin'\n",
    "mongo_client = MongoClient(uri)\n",
    "mongo_client.server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# mosaico = update_mosaico(mongo_client, folder)\n",
    "# mosaico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update_telecom(\n",
    "    mongo_client: MongoClient,  # Objeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela `licenciamento` no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados de Licenciamento do Mosaico. Processo Lento, aguarde...\",\n",
    "        spinner=\"bouncingBall\",\n",
    "    ) as status:\n",
    "\n",
    "        database = mongo_client[\"sms\"]\n",
    "        collection = database[\"licenciamento\"]\n",
    "        c = collection.find(\n",
    "            MONGO_TELECOM, projection={k: 1.0 for k in COLS_TELECOM.keys()}\n",
    "        )\n",
    "        result = L()\n",
    "        for doc in tqdm(c):\n",
    "            result.append(doc)\n",
    "        df = pd.json_normalize(result)\n",
    "        df.drop(\"_id\", axis=1, inplace=True)\n",
    "        df.rename(COLS_TELECOM, axis=1, inplace=True)\n",
    "        df[\"Designacao_Emissão\"] = df.Designacao_Emissão.str.replace(\",\", \" \")\n",
    "        df[\"Designacao_Emissão\"] = (\n",
    "            df.Designacao_Emissão.str.strip().str.lstrip().str.rstrip().str.upper()\n",
    "        )\n",
    "        df[\"Designacao_Emissão\"] = df.Designacao_Emissão.str.split(\" \")\n",
    "        df = df.explode(\"Designacao_Emissão\")\n",
    "        df.loc[df.Designacao_Emissão == \"/\", \"Designacao_Emissão\"] = \"\"\n",
    "        df.loc[\n",
    "            :, [\"Largura_Emissão(kHz)\", \"Classe_Emissão\"]\n",
    "        ] = df.Designacao_Emissão.apply(parse_bw).tolist()\n",
    "        df.drop(\"Designacao_Emissão\", axis=1, inplace=True)\n",
    "        _save_df(df, folder, \"telecom_raw\")\n",
    "        subset = [\n",
    "            \"Entidade\",\n",
    "            \"Longitude\",\n",
    "            \"Latitude\",\n",
    "            \"Classe\",\n",
    "            \"Frequência\",\n",
    "            \"Num_Serviço\",\n",
    "            \"Largura_Emissão(kHz)\",\n",
    "            \"Classe_Emissão\",\n",
    "        ]\n",
    "        df.dropna(subset=subset, axis=0, inplace=True)\n",
    "        df_sub = (\n",
    "            df[~df.duplicated(subset=subset, keep=\"first\")]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "        )\n",
    "        # df_sub = df_sub.set_index(subset).sort_index()\n",
    "        df_sub[\"Multiplicidade\"] = (\n",
    "            df.groupby(subset, sort=False).count()[\"Número_Estação\"]\n",
    "        ).tolist()\n",
    "        df_sub[\"Status\"] = \"L\"\n",
    "        df_sub[\"Fonte\"] = \"MOS\"\n",
    "        del df\n",
    "        gc.collect()\n",
    "        df_sub = df_sub.reset_index()\n",
    "        df_sub = df_sub.loc[:, COLUNAS]\n",
    "    return _save_df(df_sub, folder, \"telecom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a300ed268643ba8484779a79bbdbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a58d3cb28a4d2f8006d88dcd6313bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (730841) does not match length of index (730905)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#| eval: false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m telecom \u001b[39m=\u001b[39m update_telecom(mongo_client, folder)\n\u001b[0;32m      3\u001b[0m telecom\n",
      "Cell \u001b[1;32mIn [37], line 53\u001b[0m, in \u001b[0;36mupdate_telecom\u001b[1;34m(mongo_client, folder)\u001b[0m\n\u001b[0;32m     47\u001b[0m df_sub \u001b[39m=\u001b[39m (\n\u001b[0;32m     48\u001b[0m     df[\u001b[39m~\u001b[39mdf\u001b[39m.\u001b[39mduplicated(subset\u001b[39m=\u001b[39msubset, keep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m     49\u001b[0m     \u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     50\u001b[0m     \u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m df_sub \u001b[39m=\u001b[39m df_sub\u001b[39m.\u001b[39mset_index(subset)\u001b[39m.\u001b[39msort_index()\n\u001b[1;32m---> 53\u001b[0m df_sub[\u001b[39m\"\u001b[39;49m\u001b[39mMultiplicidade\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m (\n\u001b[0;32m     54\u001b[0m     df\u001b[39m.\u001b[39mgroupby(subset)\u001b[39m.\u001b[39mcount()[\u001b[39m\"\u001b[39m\u001b[39mNúmero_Estação\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     55\u001b[0m )\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     56\u001b[0m df_sub[\u001b[39m\"\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m df_sub[\u001b[39m\"\u001b[39m\u001b[39mFonte\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMOS\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\miniforge3\\envs\\db\\lib\\site-packages\\pandas\\core\\frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3977\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3978\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\miniforge3\\envs\\db\\lib\\site-packages\\pandas\\core\\frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4163\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4165\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4170\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4174\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4175\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4176\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4177\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4178\u001b[0m     ):\n\u001b[0;32m   4179\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4180\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\miniforge3\\envs\\db\\lib\\site-packages\\pandas\\core\\frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4909\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4911\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4912\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4913\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\miniforge3\\envs\\db\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (730841) does not match length of index (730905)"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "telecom = update_telecom(mongo_client, folder)\n",
    "telecom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def valida_coords(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    row: pd.Series,  # Linha de um DataFrame\n",
    ") -> tuple:  # DataFrame com dados do município\n",
    "    \"\"\"Valida os dados de coordenadas e município em `row` no polígono dos municípios em banco corporativo\"\"\"\n",
    "\n",
    "    sql = SQL_VALIDA_COORD.format(\n",
    "        row[\"Longitude\"], row[\"Latitude\"], row[\"Código_Município\"]\n",
    "    )\n",
    "    crsr = conn.cursor()\n",
    "    crsr.execute(sql)\n",
    "    result = crsr.fetchone()\n",
    "    if result is None:\n",
    "        return (row[\"Município\"], row[\"Longitude\"], row[\"Latitude\"], \"-1\")\n",
    "    elif result.COORD_VALIDA == 1:\n",
    "        return result\n",
    "    else:\n",
    "        return (\n",
    "            result.NO_MUNICIPIO,\n",
    "            result.NU_LONGITUDE,\n",
    "            result.NU_LATITUDE,\n",
    "            result.COORD_VALIDA,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_base(\n",
    "    conn: pyodbc.Connection,  # Objeto de conexão de banco\n",
    "    clientMongoDB: MongoClient,  # Ojeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path],  # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame:  # DataFrame com os dados atualizados\n",
    "    # sourcery skip: use-fstring-for-concatenation\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as 4 bases indicadas anteriormente, as combina e salva o arquivo consolidado na folder `folder`\"\"\"\n",
    "    stel = update_stel(\n",
    "        conn,\n",
    "        folder,\n",
    "    )\n",
    "    radcom = update_radcom(conn, folder)\n",
    "    mosaico = update_mosaico(clientMongoDB, folder)\n",
    "    telecom = update_telecom(clientMongoDB, folder)\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel, telecom])\n",
    "        .sort_values([\"Frequência\", \"Latitude\", \"Longitude\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd.loc[:, [\"Latitude\", \"Longitude\"]] = rd.loc[:, [\"Latitude\", \"Longitude\"]].fillna(\n",
    "        \"-1\"\n",
    "    )  # Validando Coordenadas\n",
    "    rd[\"Coords_Valida\"] = pd.NA\n",
    "    rd[[\"Município\", \"Longitude\", \"Latitude\", \"Coords_Valida\"]] = rd.apply(\n",
    "        lambda row: pd.Series(list(valida_coords(conn, row))), axis=1\n",
    "    )\n",
    "    rd = rd.drop(rd[rd.Coords_Valida == \"-1\"].index)\n",
    "    return _save_df(rd, folder, \"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# base = update_base(conn, mongo_client, folder)\n",
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yum Yum</td>\n",
       "      <td>cup</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yum Yum</td>\n",
       "      <td>cup</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>cup</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>pack</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>pack</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand style  rating\n",
       "0  Yum Yum   cup     4.0\n",
       "1  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "3  Indomie  pack    15.0\n",
       "4  Indomie  pack     5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yum Yum</td>\n",
       "      <td>cup</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>cup</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>pack</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indomie</td>\n",
       "      <td>pack</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand style  rating\n",
       "0  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "3  Indomie  pack    15.0\n",
       "4  Indomie  pack     5.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = ['brand', 'style', 'rating']\n",
    "df[~df.duplicated(subset=subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <th>style</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yum Yum</th>\n",
       "      <th>cup</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Indomie</th>\n",
       "      <th>cup</th>\n",
       "      <th>3.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pack</th>\n",
       "      <th>15.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(Yum Yum, cup, 4.0), (Indomie, cup, 3.5), (Indomie, pack, 15.0), (Indomie, pack, 5.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=subset, sort=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc0c9c419a5a59e8a5d5bf28d023951ba56e2f8744a354d21e9b69280dbe5840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
