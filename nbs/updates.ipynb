{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp updates\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização\n",
    "\n",
    "> Este módulo atualiza as bases. Executa as queries sql do STEL, RADCOM e baixa os arquivos de estações e plano básico do MOSAICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Union\n",
    "from urllib.request import urlretrieve, URLError\n",
    "import xmltodict\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid, ArrowTypeError\n",
    "from unidecode import unidecode\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.foundation import L\n",
    "from fastcore.test import test_eq\n",
    "from tqdm.auto import tqdm\n",
    "import pyodbc\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from anateldb.constants import *\n",
    "from anateldb.format import parse_bw, format_types, input_coordenates\n",
    "from anateldb.functionsdb import ConsultaSRD\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def connect_db(server: str = 'ANATELBDRO05', # Servidor do Banco de Dados\n",
    "               database: str = 'SITARWEB', # Nome do Banco de Dados\n",
    "               trusted_conn: str = 'yes', # Conexão Segura: yes | no\n",
    "               mult_results: bool = True, # Múltiplos Resultados\n",
    "              )->pyodbc.Connection:\n",
    "    \"\"\"Conecta ao Banco `server` e retorna o 'cursor' (iterador) do Banco\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        f\"Trusted_Connection={trusted_conn};\"\n",
    "        f\"MultipleActiveResultSets={mult_results};\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#echo: false\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM,STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_estações(row: dict)->dict:\n",
    "    \"\"\"Given a row in a MongoDB ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    \n",
    "    d = {k.replace('@', '').lower():row[k] for k in (\"@SiglaServico\", \"@id\", \"@state\",\n",
    "        \"@entidade\",\n",
    "        \"@fistel\",\n",
    "        \"@cnpj\",\n",
    "        \"@municipio\",\n",
    "        \"@uf\")}\n",
    "    entidade = row.get('entidade', {})\n",
    "    d.update({k.replace('@', '').lower():entidade[k] for k in ('@num_servico', '@habilitacao_DataValFreq')})\n",
    "    administrativo = row.get('administrativo', {})\n",
    "    d['numero_estacao'] = administrativo.get('@numero_estacao')\n",
    "    estacao = row.get('estacao_principal', {})\n",
    "    d.update({k.replace('@', '').lower():estacao[k] for k in ('@latitude', '@longitude')})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_estações(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    \n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('estacao_rd.xml') as myfile:\n",
    "            estacoes = xmltodict.parse(myfile.read())\n",
    "            \n",
    "    assert 'estacao_rd' in estacoes, \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    assert 'row' in estacoes['estacao_rd'], \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    \n",
    "    df = pd.DataFrame(L(estacoes['estacao_rd']['row']).map(_parse_estações))\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df.columns = NEW_ESTACOES    \n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_pb(row: dict)->dict:\n",
    "    \"\"\"Given a row in the MongoDB file canais.zip ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    return {unidecode(k).lower().replace(\"@\", \"\"): v  for k,v in row.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_plano_basico(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe\"\"\"    \n",
    "    df = L()\n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('plano_basicoTVFM.xml') as myfile:\n",
    "            pbtvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('plano_basicoAM.xml') as myfile:\n",
    "            pbam = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosTVFM.xml') as myfile:\n",
    "            stvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosAM.xml') as myfile:\n",
    "            sam = xmltodict.parse(myfile.read())    \n",
    "            \n",
    "    for base in (pbtvfm, stvfm, pbam, sam):\n",
    "        assert 'plano_basico' in base, \"The xml files inside canais.zip is not in the expected format\"\n",
    "        assert 'row' in base['plano_basico'], \"The xml file inside canais.zip is not in the expected format\"\n",
    "        df.extend(L(base['plano_basico']['row']).map(_parse_pb))\n",
    "        \n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)    \n",
    "    df.columns = NEW_PB\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df.loc[:, 'Frequência'] = df.Frequência.str.replace(',', '.')\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == '', c] = pd.NA\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_mosaico(df: pd.DataFrame, # DataFrame com os dados de Estações e Plano_Básico mesclados \n",
    "                pasta: Union[str, Path], # Pasta com os dados de municípios para imputar coordenadas ausentes\n",
    ") -> pd.DataFrame: # DataFrame com os dados mesclados e limpos\n",
    "    \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        df.loc[df[col_x].isna(), col_x] = df.loc[df[col_x].isna(), col_y]\n",
    "        df.loc[df[col_y].isna(), col_y] = df.loc[df[col_y].isna(), col_x]\n",
    "        if df[col_x].notna().sum() > df[col_y].notna().sum():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    # df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor == \"\", \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor == \"\", \"Longitude_Estação\"\n",
    "    # ]\n",
    "    \n",
    "    # df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor.isna(), \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor.isna(), \"Longitude_Estação\"\n",
    "    # ]\n",
    "    # df.drop([\"Latitude_Estação\", \"Longitude_Estação\"], axis=1, inplace=True)\n",
    "    # df.rename(\n",
    "    #     columns={\n",
    "    #         \"Latitude_Transmissor\": \"Latitude\",\n",
    "    #         \"Longitude_Transmissor\": \"Longitude\",\n",
    "    #     },\n",
    "    #     inplace=True,\n",
    "    # )\n",
    "\n",
    "    df = input_coordenates(df, pasta)\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.str.replace(\",\", \".\")    \n",
    "    df = df[df.Frequência.notna()].reset_index(drop=True)\n",
    "\n",
    "    # Removido o código abaixo devido a inconsistência no Mosaico\n",
    "    # if freq_nans := df[df.Frequência.isna()].Id.tolist():\n",
    "    #     complement_df = scrape_dataframe(freq_nans)\n",
    "    #     df.loc[\n",
    "    #         df.Frequência.isna(),\n",
    "    #         [\n",
    "    #             \"Status\",\n",
    "    #             \"Entidade\",\n",
    "    #             \"Fistel\",\n",
    "    #             \"Frequência\",\n",
    "    #             \"Classe\",\n",
    "    #             \"Num_Serviço\",\n",
    "    #             \"Município\",\n",
    "    #             \"UF\",\n",
    "    #         ],\n",
    "    #     ] = complement_df.values\n",
    "\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "    df.loc[df.Serviço == \"OM\", \"Frequência\"] = df.loc[\n",
    "        df.Serviço == \"OM\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    return df.drop_duplicates(keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_df(df: pd.DataFrame, folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Format, Save and return a dataframe\"\"\"\n",
    "    df = format_types(df, stem)\n",
    "    df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    df = df.dropna(subset=['Latitude', 'Longitude']).reset_index(drop=True)\n",
    "    try:\n",
    "        file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "        df.to_parquet(file, compression=\"gzip\", index=False)\n",
    "    except (ArrowInvalid, ArrowTypeError):\n",
    "        file.unlink(missing_ok=True)\n",
    "        try:\n",
    "            file = Path(f\"{folder}/{stem}.fth\")\n",
    "            df.to_feather(file)\n",
    "        except (ArrowInvalid, ArrowTypeError):\n",
    "            file.unlink(missing_ok=True)\n",
    "            try:\n",
    "                file = Path(f\"{folder}/{stem}.xlsx\")\n",
    "                with pd.ExcelWriter(file) as wb:\n",
    "                    df.to_excel(\n",
    "                        wb, sheet_name=\"DataBase\", engine=\"openpyxl\", index=False\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Could not save {stem} to {file}\") from e\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_radcom(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    "        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            return _save_df(df, folder, \"radcom\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_stel(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder:Union[str, Path] # Pasta onde salvar os arquivos        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"bouncingBall\",\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            return _save_df(df, folder, \"stel\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stel = update_stel(Path.cwd().parent / 'dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def update_mosaico(        \n",
    "        mongo_client: MongoClient, # Objeto de conexão com o MongoDB\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela de Radiodifusão no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"Consolidando os dados do Mosaico...\", spinner=\"clock\"\n",
    "    ) as status:  \n",
    "        \n",
    "        df = ConsultaSRD(mongo_client)\n",
    "        df = clean_mosaico(df, folder)\n",
    "    return _save_df(df, folder, \"mosaico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update_licenciamento(mongo_client: MongoClient, # Objeto de conexão com o MongoDB\n",
    "                         folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    ")-> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Efetua a query na tabela `licenciamento` no banco mongoDB `mongo_client` e atualiza o arquivo local\"\"\"\n",
    "    database = mongo_client[\"sms\"]\n",
    "    collection = database[\"licenciamento\"]    \n",
    "    c = collection.find(MONGO_LIC, projection={k:1.0 for k in LICENCIAMENTO.keys()})\n",
    "    result = L()\n",
    "    for doc in tqdm(c):\n",
    "        result.append(doc)\n",
    "    df = pd.json_normalize(result)\n",
    "    df.drop('_id', axis=1, inplace=True)\n",
    "    df.rename(LICENCIAMENTO, axis=1, inplace=True)\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.strip().str.lstrip().str.rstrip().str.upper()\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.replace(',', '')\n",
    "    df['Designacao_Emissão'] = df.Designacao_Emissão.str.split(' ')\n",
    "    df = df.explode('Designacao_Emissão')\n",
    "    df.loc[df.Designacao_Emissão == '/', 'Designacao_Emissão'] = ''\n",
    "    df.loc[:, ['Largura_Emissão', 'Classe_Emissão']]  = df.Designacao_Emissão.apply(parse_bw).tolist()\n",
    "    df.drop('Designacao_Emissão', axis=1, inplace=True)\n",
    "    df = df[df.Frequência > 0].reset_index(drop=True) #Added in query\n",
    "\n",
    "    return _save_df(df, folder, 'licenciamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path.cwd().parent / 'dados'\n",
    "df = pd.read_parquet(f\"{folder}/licenciamento.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>UF</th>\n",
       "      <th>Cod_Município</th>\n",
       "      <th>Município</th>\n",
       "      <th>Data_de_Validade</th>\n",
       "      <th>Número_Estação</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>Num_Serviço</th>\n",
       "      <th>Status</th>\n",
       "      <th>Largura_Emissão</th>\n",
       "      <th>Classe_Emissão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>-45336389.0</td>\n",
       "      <td>-9827222.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>2204402</td>\n",
       "      <td>Gilbués</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008723689</td>\n",
       "      <td>FX</td>\n",
       "      <td>6197.24</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>-45336389.0</td>\n",
       "      <td>-9827222.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>2204402</td>\n",
       "      <td>Gilbués</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008723689</td>\n",
       "      <td>FX</td>\n",
       "      <td>6226.89</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>-41789028.0</td>\n",
       "      <td>-6118083.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>2200905</td>\n",
       "      <td>AROAZES</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008726807</td>\n",
       "      <td>FX</td>\n",
       "      <td>6830.0</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>-41789028.0</td>\n",
       "      <td>-6118083.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>2200905</td>\n",
       "      <td>AROAZES</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008726807</td>\n",
       "      <td>FX</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>-41789028.0</td>\n",
       "      <td>-6118083.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>2200905</td>\n",
       "      <td>AROAZES</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008726807</td>\n",
       "      <td>FX</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616807</th>\n",
       "      <td>Supermercados Bh Comercio de Alimentos S.A.</td>\n",
       "      <td>43.9233</td>\n",
       "      <td>-19.87572</td>\n",
       "      <td>MG</td>\n",
       "      <td>3106200</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>2041-11-23</td>\n",
       "      <td>1013217885</td>\n",
       "      <td>ML</td>\n",
       "      <td>159.47</td>\n",
       "      <td>50440365449</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>7.6</td>\n",
       "      <td>F1W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616808</th>\n",
       "      <td>Supermercados Bh Comercio de Alimentos S.A.</td>\n",
       "      <td>43.9233</td>\n",
       "      <td>-19.87572</td>\n",
       "      <td>MG</td>\n",
       "      <td>3106200</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>2041-11-23</td>\n",
       "      <td>1013217893</td>\n",
       "      <td>ML</td>\n",
       "      <td>159.47</td>\n",
       "      <td>50440365449</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>7.6</td>\n",
       "      <td>F1W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616809</th>\n",
       "      <td>TIM S A</td>\n",
       "      <td>47.97408</td>\n",
       "      <td>16.01242</td>\n",
       "      <td>DF</td>\n",
       "      <td>5300108</td>\n",
       "      <td>BRASILIA</td>\n",
       "      <td>2032-08-31</td>\n",
       "      <td>1005075791</td>\n",
       "      <td>FX</td>\n",
       "      <td>7554.0</td>\n",
       "      <td>50417425295</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616810</th>\n",
       "      <td>MIRAGEM SEGURANÇA LTDA</td>\n",
       "      <td>54.6193557</td>\n",
       "      <td>-20.553295</td>\n",
       "      <td>MS</td>\n",
       "      <td>5002704</td>\n",
       "      <td>Campo Grande</td>\n",
       "      <td>2040-02-23</td>\n",
       "      <td>1012865476</td>\n",
       "      <td>FB</td>\n",
       "      <td>148.53</td>\n",
       "      <td>50406671249</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>F3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616811</th>\n",
       "      <td>MIRAGEM SEGURANÇA LTDA</td>\n",
       "      <td>54.6193557</td>\n",
       "      <td>-20.553295</td>\n",
       "      <td>MS</td>\n",
       "      <td>5002704</td>\n",
       "      <td>Campo Grande</td>\n",
       "      <td>2040-02-23</td>\n",
       "      <td>1012865484</td>\n",
       "      <td>ML</td>\n",
       "      <td>148.53</td>\n",
       "      <td>50406671249</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>F3E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6616812 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Entidade    Longitude    Latitude  \\\n",
       "0                             TELEFONICA BRASIL S.A.  -45336389.0  -9827222.0   \n",
       "1                             TELEFONICA BRASIL S.A.  -45336389.0  -9827222.0   \n",
       "2                             TELEFONICA BRASIL S.A.  -41789028.0  -6118083.0   \n",
       "3                             TELEFONICA BRASIL S.A.  -41789028.0  -6118083.0   \n",
       "4                             TELEFONICA BRASIL S.A.  -41789028.0  -6118083.0   \n",
       "...                                              ...          ...         ...   \n",
       "6616807  Supermercados Bh Comercio de Alimentos S.A.      43.9233   -19.87572   \n",
       "6616808  Supermercados Bh Comercio de Alimentos S.A.      43.9233   -19.87572   \n",
       "6616809                                      TIM S A     47.97408    16.01242   \n",
       "6616810                       MIRAGEM SEGURANÇA LTDA   54.6193557  -20.553295   \n",
       "6616811                       MIRAGEM SEGURANÇA LTDA   54.6193557  -20.553295   \n",
       "\n",
       "         UF Cod_Município       Município Data_de_Validade Número_Estação  \\\n",
       "0        PI       2204402         Gilbués       2039-02-08     1008723689   \n",
       "1        PI       2204402         Gilbués       2039-02-08     1008723689   \n",
       "2        PI       2200905         AROAZES       2039-02-08     1008726807   \n",
       "3        PI       2200905         AROAZES       2039-02-08     1008726807   \n",
       "4        PI       2200905         AROAZES       2039-02-08     1008726807   \n",
       "...      ..           ...             ...              ...            ...   \n",
       "6616807  MG       3106200  Belo Horizonte       2041-11-23     1013217885   \n",
       "6616808  MG       3106200  Belo Horizonte       2041-11-23     1013217893   \n",
       "6616809  DF       5300108        BRASILIA       2032-08-31     1005075791   \n",
       "6616810  MS       5002704    Campo Grande       2040-02-23     1012865476   \n",
       "6616811  MS       5002704    Campo Grande       2040-02-23     1012865484   \n",
       "\n",
       "        Classe Frequência       Fistel Num_Serviço      Status  \\\n",
       "0           FX    6197.24  50417179405         019  LIC-LIC-01   \n",
       "1           FX    6226.89  50417179405         019  LIC-LIC-01   \n",
       "2           FX     6830.0  50417179405         019  LIC-LIC-01   \n",
       "3           FX     6860.0  50417179405         019  LIC-LIC-01   \n",
       "4           FX     7040.0  50417179405         019  LIC-LIC-01   \n",
       "...        ...        ...          ...         ...         ...   \n",
       "6616807     ML     159.47  50440365449         019  LIC-LIC-01   \n",
       "6616808     ML     159.47  50440365449         019  LIC-LIC-01   \n",
       "6616809     FX     7554.0  50417425295         019  LIC-LIC-01   \n",
       "6616810     FB     148.53  50406671249         019  LIC-LIC-01   \n",
       "6616811     ML     148.53  50406671249         019  LIC-LIC-01   \n",
       "\n",
       "        Largura_Emissão Classe_Emissão  \n",
       "0               29600.0            D7W  \n",
       "1               29600.0            D7W  \n",
       "2               30000.0            D7W  \n",
       "3               30000.0            D7W  \n",
       "4               30000.0            D7W  \n",
       "...                 ...            ...  \n",
       "6616807             7.6            F1W  \n",
       "6616808             7.6            F1W  \n",
       "6616809         28000.0            D7W  \n",
       "6616810            16.0            F3E  \n",
       "6616811            16.0            F3E  \n",
       "\n",
       "[6616812 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='install \"ipywidgets\" for Jupyter support')\n",
    "\n",
    "folder = Path.cwd().parent / 'dados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '4.0.5',\n",
       " 'gitVersion': '3739429dd92b92d1b0ab120911a23d50bf03c412',\n",
       " 'targetMinOS': 'Windows 7/Windows Server 2008 R2',\n",
       " 'modules': [],\n",
       " 'allocator': 'tcmalloc',\n",
       " 'javascriptEngine': 'mozjs',\n",
       " 'sysInfo': 'deprecated',\n",
       " 'versionArray': [4, 0, 5, 0],\n",
       " 'openssl': {'running': 'Windows SChannel'},\n",
       " 'buildEnvironment': {'distmod': '2008plus-ssl',\n",
       "  'distarch': 'x86_64',\n",
       "  'cc': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'ccflags': '/nologo /EHsc /W3 /wd4355 /wd4800 /wd4267 /wd4244 /wd4290 /wd4068 /wd4351 /wd4373 /we4013 /we4099 /we4930 /WX /errorReport:none /MD /O2 /Oy- /bigobj /utf-8 /Zc:rvalueCast /Zc:strictStrings /volatile:iso /Gw /Gy /Zc:inline',\n",
       "  'cxx': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24223 for x64',\n",
       "  'cxxflags': '/TP',\n",
       "  'linkflags': '/nologo /DEBUG /INCREMENTAL:NO /LARGEADDRESSAWARE /OPT:REF',\n",
       "  'target_arch': 'x86_64',\n",
       "  'target_os': 'windows'},\n",
       " 'bits': 64,\n",
       " 'debug': False,\n",
       " 'maxBsonObjectSize': 16777216,\n",
       " 'storageEngines': ['devnull', 'ephemeralForTest', 'mmapv1', 'wiredTiger'],\n",
       " 'ok': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri = 'mongodb://UserPython:Ox6TT1QvNhf#Ez#J*B@anatelbdro06:27017/?serverSelectionTimeoutMS=5000&connectTimeoutMS=10000&authSource=admin'\n",
    "\n",
    "mongo_client = MongoClient(uri)\n",
    "mongo_client.server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e832976d70b44defb1909b493a6bb223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "database = mongo_client[\"sms\"]\n",
    "collection = database[\"licenciamento\"]    \n",
    "c = collection.find(MONGO_LIC, projection={k:1.0 for k in LICENCIAMENTO.keys()})\n",
    "result = L()\n",
    "for doc in tqdm(c):\n",
    "    result.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(result)\n",
    "df.drop('_id', axis=1, inplace=True)\n",
    "df.rename(LICENCIAMENTO, axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Designacao_Emissão'] = df.Designacao_Emissão.str.strip().str.lstrip().str.rstrip().str.upper()\n",
    "df['Designacao_Emissão'] = df.Designacao_Emissão.str.replace(',', '')\n",
    "df['Designacao_Emissão'] = df.Designacao_Emissão.str.split(' ')\n",
    "df = df.explode('Designacao_Emissão')\n",
    "df.loc[df.Designacao_Emissão == '/', 'Designacao_Emissão'] = ''\n",
    "df.loc[:, ['Largura_Emissão', 'Classe_Emissão']]  = df.Designacao_Emissão.apply(parse_bw).tolist()\n",
    "df.drop('Designacao_Emissão', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LIC-LIC-01', 'LIC-EXC-01', 'ED-ED-01', 'ED-EX-01'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Status == 'LIC-LIC-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6858289, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6617215, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241074"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6858289 - 6617215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entidade</th>\n",
       "      <th>UF</th>\n",
       "      <th>Cod_Município</th>\n",
       "      <th>Município</th>\n",
       "      <th>Data_de_Validade</th>\n",
       "      <th>Número_Estação</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>Num_Serviço</th>\n",
       "      <th>Status</th>\n",
       "      <th>Largura_Emissão</th>\n",
       "      <th>Classe_Emissão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>PI</td>\n",
       "      <td>2204402</td>\n",
       "      <td>Gilbués</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008723689</td>\n",
       "      <td>FX</td>\n",
       "      <td>6197.24</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>PI</td>\n",
       "      <td>2204402</td>\n",
       "      <td>Gilbués</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1008723689</td>\n",
       "      <td>FX</td>\n",
       "      <td>6226.89</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CLARO S.A.</td>\n",
       "      <td>AC</td>\n",
       "      <td>1200336</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-08</td>\n",
       "      <td>1000812453</td>\n",
       "      <td>FX</td>\n",
       "      <td>882.80</td>\n",
       "      <td>11021017965</td>\n",
       "      <td>175</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>G7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CLARO S.A.</td>\n",
       "      <td>AC</td>\n",
       "      <td>1200336</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-08</td>\n",
       "      <td>1000812453</td>\n",
       "      <td>FX</td>\n",
       "      <td>882.80</td>\n",
       "      <td>11021017965</td>\n",
       "      <td>175</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>G7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CLARO S.A.</td>\n",
       "      <td>AC</td>\n",
       "      <td>1200336</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-08</td>\n",
       "      <td>1000812453</td>\n",
       "      <td>FB</td>\n",
       "      <td>882.80</td>\n",
       "      <td>11021017965</td>\n",
       "      <td>175</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>G7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857427</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>CE</td>\n",
       "      <td>2301950</td>\n",
       "      <td>Barreira</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1012153948</td>\n",
       "      <td>FX</td>\n",
       "      <td>7010.00</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857429</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>CE</td>\n",
       "      <td>2301950</td>\n",
       "      <td>Barreira</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1012153948</td>\n",
       "      <td>FX</td>\n",
       "      <td>7040.00</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858276</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>RN</td>\n",
       "      <td>2412203</td>\n",
       "      <td>São José de Mipibu</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1011318374</td>\n",
       "      <td>FX</td>\n",
       "      <td>6375.14</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858277</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>RN</td>\n",
       "      <td>2412203</td>\n",
       "      <td>São José de Mipibu</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1011318374</td>\n",
       "      <td>FX</td>\n",
       "      <td>6404.79</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858279</th>\n",
       "      <td>TELEFONICA BRASIL S.A.</td>\n",
       "      <td>PE</td>\n",
       "      <td>2611101</td>\n",
       "      <td>Petrolina</td>\n",
       "      <td>2039-02-08</td>\n",
       "      <td>1012153913</td>\n",
       "      <td>FX</td>\n",
       "      <td>14865.00</td>\n",
       "      <td>50417179405</td>\n",
       "      <td>019</td>\n",
       "      <td>LIC-LIC-01</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>D7W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241074 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Entidade  UF Cod_Município           Município  \\\n",
       "1        TELEFONICA BRASIL S.A.  PI       2204402             Gilbués   \n",
       "3        TELEFONICA BRASIL S.A.  PI       2204402             Gilbués   \n",
       "21                   CLARO S.A.  AC       1200336                None   \n",
       "22                   CLARO S.A.  AC       1200336                None   \n",
       "26                   CLARO S.A.  AC       1200336                None   \n",
       "...                         ...  ..           ...                 ...   \n",
       "6857427  TELEFONICA BRASIL S.A.  CE       2301950            Barreira   \n",
       "6857429  TELEFONICA BRASIL S.A.  CE       2301950            Barreira   \n",
       "6858276  TELEFONICA BRASIL S.A.  RN       2412203  São José de Mipibu   \n",
       "6858277  TELEFONICA BRASIL S.A.  RN       2412203  São José de Mipibu   \n",
       "6858279  TELEFONICA BRASIL S.A.  PE       2611101           Petrolina   \n",
       "\n",
       "        Data_de_Validade Número_Estação Classe  Frequência       Fistel  \\\n",
       "1             2039-02-08     1008723689     FX     6197.24  50417179405   \n",
       "3             2039-02-08     1008723689     FX     6226.89  50417179405   \n",
       "21            2024-02-08     1000812453     FX      882.80  11021017965   \n",
       "22            2024-02-08     1000812453     FX      882.80  11021017965   \n",
       "26            2024-02-08     1000812453     FB      882.80  11021017965   \n",
       "...                  ...            ...    ...         ...          ...   \n",
       "6857427       2039-02-08     1012153948     FX     7010.00  50417179405   \n",
       "6857429       2039-02-08     1012153948     FX     7040.00  50417179405   \n",
       "6858276       2039-02-08     1011318374     FX     6375.14  50417179405   \n",
       "6858277       2039-02-08     1011318374     FX     6404.79  50417179405   \n",
       "6858279       2039-02-08     1012153913     FX    14865.00  50417179405   \n",
       "\n",
       "        Num_Serviço      Status  Largura_Emissão Classe_Emissão  \n",
       "1               019  LIC-LIC-01          29600.0            D7W  \n",
       "3               019  LIC-LIC-01          29600.0            D7W  \n",
       "21              175  LIC-LIC-01           5000.0            G7W  \n",
       "22              175  LIC-LIC-01           5000.0            G7W  \n",
       "26              175  LIC-LIC-01           5000.0            G7W  \n",
       "...             ...         ...              ...            ...  \n",
       "6857427         019  LIC-LIC-01          30000.0            D7W  \n",
       "6857429         019  LIC-LIC-01          30000.0            D7W  \n",
       "6858276         019  LIC-LIC-01          29600.0            D7W  \n",
       "6858277         019  LIC-LIC-01          29600.0            D7W  \n",
       "6858279         019  LIC-LIC-01          56000.0            D7W  \n",
       "\n",
       "[241074 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['Latitude', 'Longitude'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\OneDrive - ANATEL\\anateldb\\nbs\\updates.ipynb Célula: 28\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/updates.ipynb#Y153sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m subset \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mFrequência\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/updates.ipynb#Y153sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[df\u001b[39m.\u001b[39;49mduplicated(subset\u001b[39m=\u001b[39;49msubset)]\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\anateldb\\lib\\site-packages\\pandas\\core\\frame.py:6256\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6254\u001b[0m diff \u001b[39m=\u001b[39m Index(subset)\u001b[39m.\u001b[39mdifference(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m   6255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m diff\u001b[39m.\u001b[39mempty:\n\u001b[1;32m-> 6256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(diff)\n\u001b[0;32m   6258\u001b[0m vals \u001b[39m=\u001b[39m (col\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m name, col \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m subset)\n\u001b[0;32m   6259\u001b[0m labels, shape \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(f, vals)))\n",
      "\u001b[1;31mKeyError\u001b[0m: Index(['Latitude', 'Longitude'], dtype='object')"
     ]
    }
   ],
   "source": [
    "subset = ['Frequência', 'Latitude', 'Longitude']\n",
    "df[df.duplicated(subset=subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_base(\n",
    "    conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "    clientMongoDB: MongoClient, # Ojeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path] # Pasta onde salvar os arquivos    \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    # sourcery skip: use-fstring-for-concatenation\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na folder `folder`\"\"\"\n",
    "    stel = update_stel(conn, folder, ).loc[:, TELECOM]\n",
    "    radcom = update_radcom(conn, folder).loc[:, SRD]\n",
    "    mosaico = update_mosaico(clientMongoDB, folder).loc[:, RADIODIFUSAO]    \n",
    "    radcom[\"Num_Serviço\"] = \"231\"\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe_Emissão\"] = pd.NA\n",
    "    radcom[\"Largura_Emissão\"] = BW_MAP[\"231\"]\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Validade_RF\"] = pd.NA\n",
    "    radcom[\"Fonte\"] = \"SRD\"\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    mosaico[\"Fonte\"] = \"MOS\"\n",
    "    mosaico[\"Classe_Emissão\"] = pd.NA\n",
    "    mosaico[\"Largura_Emissão\"] = mosaico.Num_Serviço.map(BW_MAP)\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel])\n",
    "        .sort_values([\"Frequência\", \"Latitude\", \"Longitude\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd = rd.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    rd[\"BW(kHz)\"] = rd.Largura_Emissão.astype('string').fillna('-1').apply(parse_bw)\n",
    "    return _save_df(rd, folder, \"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import Request, urlopen\n",
    "# from urllib.error import URLError\n",
    "# req = Request(ESTACAO)\n",
    "# try:\n",
    "#     response = urlopen(req)\n",
    "# except URLError as e:\n",
    "#     if hasattr(e, 'reason'):\n",
    "#         print('We failed to reach a server.')\n",
    "#         print('Reason: ', e.reason)\n",
    "#     elif hasattr(e, 'code'):\n",
    "#         print('The server couldn\\'t fulfill the request.')\n",
    "#         print('Error code: ', e.code)\n",
    "# else:\n",
    "#     Path.cwd().joinpath('estações.zip').write_bytes(response.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anateldb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37a0fa21125bc68b41a424f43d92a26fa97b5ebccfac6eecdcaf85c09668024f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
