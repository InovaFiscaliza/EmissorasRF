{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp updates\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização\n",
    "\n",
    "> Este módulo atualiza as bases. Executa as queries sql do STEL, RADCOM e baixa os arquivos de estações e plano básico do MOSAICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Union\n",
    "from urllib.request import urlretrieve, URLError\n",
    "import xmltodict\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid, ArrowTypeError\n",
    "from unidecode import unidecode\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.foundation import L\n",
    "from fastcore.test import test_eq\n",
    "import pyodbc\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from anateldb.constants import *\n",
    "from anateldb.format import parse_bw, format_types, input_coordenates\n",
    "from anateldb.functionsdb import ConsultaSRD\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def connect_db(server: str = 'ANATELBDRO05', # Servidor do Banco de Dados\n",
    "               database: str = 'SITARWEB', # Nome do Banco de Dados\n",
    "               trusted_conn: str = 'yes', # Conexão Segura: yes | no\n",
    "               mult_results: bool = True, # Múltiplos Resultados\n",
    "              )->pyodbc.Connection:\n",
    "    \"\"\"Conecta ao Banco `server` e retorna o 'cursor' (iterador) do Banco\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        f\"Trusted_Connection={trusted_conn};\"\n",
    "        f\"MultipleActiveResultSets={mult_results};\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#echo: false\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM,STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_estações(row: dict)->dict:\n",
    "    \"\"\"Given a row in a MongoDB ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    \n",
    "    d = {k.replace('@', '').lower():row[k] for k in (\"@SiglaServico\", \"@id\", \"@state\",\n",
    "        \"@entidade\",\n",
    "        \"@fistel\",\n",
    "        \"@cnpj\",\n",
    "        \"@municipio\",\n",
    "        \"@uf\")}\n",
    "    entidade = row.get('entidade', {})\n",
    "    d.update({k.replace('@', '').lower():entidade[k] for k in ('@num_servico', '@habilitacao_DataValFreq')})\n",
    "    administrativo = row.get('administrativo', {})\n",
    "    d['numero_estacao'] = administrativo.get('@numero_estacao')\n",
    "    estacao = row.get('estacao_principal', {})\n",
    "    d.update({k.replace('@', '').lower():estacao[k] for k in ('@latitude', '@longitude')})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_estações(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    \n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('estacao_rd.xml') as myfile:\n",
    "            estacoes = xmltodict.parse(myfile.read())\n",
    "            \n",
    "    assert 'estacao_rd' in estacoes, \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    assert 'row' in estacoes['estacao_rd'], \"The xml file inside estacoes.zip is not in the expected format\"\n",
    "    \n",
    "    df = pd.DataFrame(L(estacoes['estacao_rd']['row']).map(_parse_estações))\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df.columns = NEW_ESTACOES    \n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serviço                  object\n",
      "Num_Serviço              object\n",
      "Status                   object\n",
      "Entidade                 object\n",
      "Fistel                   object\n",
      "UF                       object\n",
      "Id                       object\n",
      "Número_Estação           object\n",
      "Latitude_Transmissor     object\n",
      "Longitude_Transmissor    object\n",
      "CNPJ                     object\n",
      "Validade_RF              object\n",
      "dtype: object\n",
      "30163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serviço</th>\n",
       "      <th>Num_Serviço</th>\n",
       "      <th>Status</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>UF</th>\n",
       "      <th>Id</th>\n",
       "      <th>Número_Estação</th>\n",
       "      <th>Latitude_Transmissor</th>\n",
       "      <th>Longitude_Transmissor</th>\n",
       "      <th>CNPJ</th>\n",
       "      <th>Validade_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TV</td>\n",
       "      <td>248</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>REDE DE COMUNICACOES ACREANA LTDA</td>\n",
       "      <td>50442889933</td>\n",
       "      <td>AC</td>\n",
       "      <td>57dbaad04f6cc</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>01865469000156</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV</td>\n",
       "      <td>248</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>X-MEDIAGROUP S.A.</td>\n",
       "      <td>50410887137</td>\n",
       "      <td>AC</td>\n",
       "      <td>57dbaad053c60</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>03211814000163</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TV</td>\n",
       "      <td>248</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>TELEVISAO OESTE BAIANO LTDA</td>\n",
       "      <td>06030116240</td>\n",
       "      <td>BA</td>\n",
       "      <td>57dbaad0dc4e3</td>\n",
       "      <td>322647029</td>\n",
       "      <td>-12.101388888889</td>\n",
       "      <td>-44.993611111111</td>\n",
       "      <td>16395923000120</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV</td>\n",
       "      <td>248</td>\n",
       "      <td>TV-C2</td>\n",
       "      <td>TELEVISAO SANTA CRUZ LTDA</td>\n",
       "      <td>06020355110</td>\n",
       "      <td>BA</td>\n",
       "      <td>57dbaad0eb54a</td>\n",
       "      <td>322623553</td>\n",
       "      <td>-14.779444444444</td>\n",
       "      <td>-39.262222222222</td>\n",
       "      <td>13476833000175</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV</td>\n",
       "      <td>248</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>TV CABRALIA LTDA</td>\n",
       "      <td>06020354903</td>\n",
       "      <td>BA</td>\n",
       "      <td>57dbaad0ef8af</td>\n",
       "      <td>322623537</td>\n",
       "      <td>-14.78167</td>\n",
       "      <td>-39.26167</td>\n",
       "      <td>13494265000135</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Serviço Num_Serviço Status                           Entidade       Fistel  \\\n",
       "0      TV         248  TV-C1  REDE DE COMUNICACOES ACREANA LTDA  50442889933   \n",
       "1      TV         248  TV-C1                  X-MEDIAGROUP S.A.  50410887137   \n",
       "2      TV         248  TV-C4        TELEVISAO OESTE BAIANO LTDA  06030116240   \n",
       "3      TV         248  TV-C2          TELEVISAO SANTA CRUZ LTDA  06020355110   \n",
       "4      TV         248  TV-C4                   TV CABRALIA LTDA  06020354903   \n",
       "\n",
       "   UF             Id Número_Estação Latitude_Transmissor  \\\n",
       "0  AC  57dbaad04f6cc           <NA>                 <NA>   \n",
       "1  AC  57dbaad053c60           <NA>                 <NA>   \n",
       "2  BA  57dbaad0dc4e3      322647029     -12.101388888889   \n",
       "3  BA  57dbaad0eb54a      322623553     -14.779444444444   \n",
       "4  BA  57dbaad0ef8af      322623537            -14.78167   \n",
       "\n",
       "  Longitude_Transmissor            CNPJ Validade_RF  \n",
       "0                  <NA>  01865469000156        <NA>  \n",
       "1                  <NA>  03211814000163        <NA>  \n",
       "2      -44.993611111111  16395923000120  2023-12-31  \n",
       "3      -39.262222222222  13476833000175  2023-12-31  \n",
       "4             -39.26167  13494265000135  2023-12-31  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estacoes_df = _read_estações('../dados/estações.zip')\n",
    "print(estacoes_df.dtypes)\n",
    "print(len(estacoes_df.index))\n",
    "estacoes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _parse_pb(row: dict)->dict:\n",
    "    \"\"\"Given a row in the MongoDB file canais.zip ( a dict of dicts ), it travels some keys and return a subset dict\"\"\"\n",
    "    return {unidecode(k).lower().replace(\"@\", \"\"): v  for k,v in row.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _read_plano_basico(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe\"\"\"    \n",
    "    df = L()\n",
    "    with ZipFile(path) as myzip:\n",
    "        with myzip.open('plano_basicoTVFM.xml') as myfile:\n",
    "            pbtvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('plano_basicoAM.xml') as myfile:\n",
    "            pbam = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosTVFM.xml') as myfile:\n",
    "            stvfm = xmltodict.parse(myfile.read())\n",
    "        with myzip.open('secundariosAM.xml') as myfile:\n",
    "            sam = xmltodict.parse(myfile.read())    \n",
    "            \n",
    "    for base in (pbtvfm, stvfm, pbam, sam):\n",
    "        assert 'plano_basico' in base, \"The xml files inside canais.zip is not in the expected format\"\n",
    "        assert 'row' in base['plano_basico'], \"The xml file inside canais.zip is not in the expected format\"\n",
    "        df.extend(L(base['plano_basico']['row']).map(_parse_pb))\n",
    "        \n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)    \n",
    "    df.columns = NEW_PB\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(drop=True)\n",
    "    df.loc[:, 'Frequência'] = df.Frequência.str.replace(',', '.')\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == '', c] = pd.NA\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                   object\n",
      "Município            object\n",
      "Frequência           object\n",
      "Classe               object\n",
      "Serviço              object\n",
      "Entidade             object\n",
      "Latitude_Estação     object\n",
      "Longitude_Estação    object\n",
      "UF                   object\n",
      "Status               object\n",
      "CNPJ                 object\n",
      "Fistel               object\n",
      "dtype: object\n",
      "48386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Município</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Serviço</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>Latitude_Estação</th>\n",
       "      <th>Longitude_Estação</th>\n",
       "      <th>UF</th>\n",
       "      <th>Status</th>\n",
       "      <th>CNPJ</th>\n",
       "      <th>Fistel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57dbaad04f6cc</td>\n",
       "      <td>Cruzeiro do Sul</td>\n",
       "      <td>207</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>REDE DE COMUNICACOES ACREANA LTDA</td>\n",
       "      <td>-7,631111111111</td>\n",
       "      <td>-72,67</td>\n",
       "      <td>AC</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>01865469000156</td>\n",
       "      <td>50442889933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57dbaad053c60</td>\n",
       "      <td>Mâncio Lima</td>\n",
       "      <td>539</td>\n",
       "      <td>C</td>\n",
       "      <td>TV</td>\n",
       "      <td>X-MEDIAGROUP S.A.</td>\n",
       "      <td>-7,6141666666667</td>\n",
       "      <td>-72,895833333333</td>\n",
       "      <td>AC</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>03211814000163</td>\n",
       "      <td>50410887137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57dbaad0dc4e3</td>\n",
       "      <td>Barreiras</td>\n",
       "      <td>79</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>TELEVISAO OESTE BAIANO LTDA</td>\n",
       "      <td>-12,102222222222</td>\n",
       "      <td>-44,994444444444</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>16395923000120</td>\n",
       "      <td>06030116240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57dbaad0eb54a</td>\n",
       "      <td>Itabuna</td>\n",
       "      <td>69</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>TELEVISAO SANTA CRUZ LTDA</td>\n",
       "      <td>-14,780555555555</td>\n",
       "      <td>-39,261944444444</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C2</td>\n",
       "      <td>13476833000175</td>\n",
       "      <td>06020355110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57dbaad0ef8af</td>\n",
       "      <td>Itabuna</td>\n",
       "      <td>177</td>\n",
       "      <td>B</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV CABRALIA LTDA</td>\n",
       "      <td>-14,78</td>\n",
       "      <td>-39,260833333333</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>13494265000135</td>\n",
       "      <td>06020354903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id        Município Frequência Classe Serviço  \\\n",
       "0  57dbaad04f6cc  Cruzeiro do Sul        207      A      TV   \n",
       "1  57dbaad053c60      Mâncio Lima        539      C      TV   \n",
       "2  57dbaad0dc4e3        Barreiras         79      A      TV   \n",
       "3  57dbaad0eb54a          Itabuna         69      A      TV   \n",
       "4  57dbaad0ef8af          Itabuna        177      B      TV   \n",
       "\n",
       "                            Entidade  Latitude_Estação Longitude_Estação  UF  \\\n",
       "0  REDE DE COMUNICACOES ACREANA LTDA   -7,631111111111            -72,67  AC   \n",
       "1                  X-MEDIAGROUP S.A.  -7,6141666666667  -72,895833333333  AC   \n",
       "2        TELEVISAO OESTE BAIANO LTDA  -12,102222222222  -44,994444444444  BA   \n",
       "3          TELEVISAO SANTA CRUZ LTDA  -14,780555555555  -39,261944444444  BA   \n",
       "4                   TV CABRALIA LTDA            -14,78  -39,260833333333  BA   \n",
       "\n",
       "  Status            CNPJ       Fistel  \n",
       "0  TV-C1  01865469000156  50442889933  \n",
       "1  TV-C1  03211814000163  50410887137  \n",
       "2  TV-C4  16395923000120  06030116240  \n",
       "3  TV-C2  13476833000175  06020355110  \n",
       "4  TV-C4  13494265000135  06020354903  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plano_basico_df = _read_plano_basico('../dados/canais.zip')\n",
    "print(plano_basico_df.dtypes)\n",
    "print(len(plano_basico_df.index))\n",
    "plano_basico_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_mosaico(df: pd.DataFrame, # DataFrame com os dados de Estações e Plano_Básico mesclados \n",
    "                pasta: Union[str, Path], # Pasta com os dados de municípios para imputar coordenadas ausentes\n",
    ") -> pd.DataFrame: # DataFrame com os dados mesclados e limpos\n",
    "    \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        df.loc[df[col_x].isna(), col_x] = df.loc[df[col_x].isna(), col_y]\n",
    "        df.loc[df[col_y].isna(), col_y] = df.loc[df[col_y].isna(), col_x]\n",
    "        if df[col_x].notna().sum() > df[col_y].notna().sum():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    # df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor == \"\", \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor == \"\", \"Longitude_Estação\"\n",
    "    # ]\n",
    "    \n",
    "    # df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "    #     df.Latitude_Transmissor.isna(), \"Latitude_Estação\"\n",
    "    # ]\n",
    "    # df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "    #     df.Longitude_Transmissor.isna(), \"Longitude_Estação\"\n",
    "    # ]\n",
    "    # df.drop([\"Latitude_Estação\", \"Longitude_Estação\"], axis=1, inplace=True)\n",
    "    # df.rename(\n",
    "    #     columns={\n",
    "    #         \"Latitude_Transmissor\": \"Latitude\",\n",
    "    #         \"Longitude_Transmissor\": \"Longitude\",\n",
    "    #     },\n",
    "    #     inplace=True,\n",
    "    # )\n",
    "\n",
    "    df = input_coordenates(df, pasta)\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.str.replace(\",\", \".\")    \n",
    "    df = df[df.Frequência.notna()].reset_index(drop=True)\n",
    "\n",
    "    # Removido o código abaixo devido a inconsistência no Mosaico\n",
    "    # if freq_nans := df[df.Frequência.isna()].Id.tolist():\n",
    "    #     complement_df = scrape_dataframe(freq_nans)\n",
    "    #     df.loc[\n",
    "    #         df.Frequência.isna(),\n",
    "    #         [\n",
    "    #             \"Status\",\n",
    "    #             \"Entidade\",\n",
    "    #             \"Fistel\",\n",
    "    #             \"Frequência\",\n",
    "    #             \"Classe\",\n",
    "    #             \"Num_Serviço\",\n",
    "    #             \"Município\",\n",
    "    #             \"UF\",\n",
    "    #         ],\n",
    "    #     ] = complement_df.values\n",
    "\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "    df.loc[df.Serviço == \"OM\", \"Frequência\"] = df.loc[\n",
    "        df.Serviço == \"OM\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    return df.drop_duplicates(keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48223\n",
      "30163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Serviço</th>\n",
       "      <th>Id</th>\n",
       "      <th>Número_Estação</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Validade_RF</th>\n",
       "      <th>Município</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Serviço</th>\n",
       "      <th>Entidade</th>\n",
       "      <th>UF</th>\n",
       "      <th>Status</th>\n",
       "      <th>CNPJ</th>\n",
       "      <th>Fistel</th>\n",
       "      <th>Coordenadas_do_Município</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248</td>\n",
       "      <td>57dbaad04f6cc</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-7.631111111111</td>\n",
       "      <td>-72.67</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cruzeiro do Sul</td>\n",
       "      <td>207.0</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>REDE DE COMUNICACOES ACREANA LTDA</td>\n",
       "      <td>AC</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>01865469000156</td>\n",
       "      <td>50442889933</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "      <td>57dbaad053c60</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-7.6141666666667</td>\n",
       "      <td>-72.895833333333</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Mâncio Lima</td>\n",
       "      <td>539.0</td>\n",
       "      <td>C</td>\n",
       "      <td>TV</td>\n",
       "      <td>X-MEDIAGROUP S.A.</td>\n",
       "      <td>AC</td>\n",
       "      <td>TV-C1</td>\n",
       "      <td>03211814000163</td>\n",
       "      <td>50410887137</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248</td>\n",
       "      <td>57dbaad0dc4e3</td>\n",
       "      <td>322647029</td>\n",
       "      <td>-12.101388888889</td>\n",
       "      <td>-44.993611111111</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Barreiras</td>\n",
       "      <td>79.0</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>TELEVISAO OESTE BAIANO LTDA</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>16395923000120</td>\n",
       "      <td>06030116240</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248</td>\n",
       "      <td>57dbaad0eb54a</td>\n",
       "      <td>322623553</td>\n",
       "      <td>-14.779444444444</td>\n",
       "      <td>-39.262222222222</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Itabuna</td>\n",
       "      <td>69.0</td>\n",
       "      <td>A</td>\n",
       "      <td>TV</td>\n",
       "      <td>TELEVISAO SANTA CRUZ LTDA</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C2</td>\n",
       "      <td>13476833000175</td>\n",
       "      <td>06020355110</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248</td>\n",
       "      <td>57dbaad0ef8af</td>\n",
       "      <td>322623537</td>\n",
       "      <td>-14.78167</td>\n",
       "      <td>-39.26167</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Itabuna</td>\n",
       "      <td>177.0</td>\n",
       "      <td>B</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV CABRALIA LTDA</td>\n",
       "      <td>BA</td>\n",
       "      <td>TV-C4</td>\n",
       "      <td>13494265000135</td>\n",
       "      <td>06020354903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Num_Serviço             Id Número_Estação          Latitude  \\\n",
       "0         248  57dbaad04f6cc           <NA>   -7.631111111111   \n",
       "1         248  57dbaad053c60           <NA>  -7.6141666666667   \n",
       "2         248  57dbaad0dc4e3      322647029  -12.101388888889   \n",
       "3         248  57dbaad0eb54a      322623553  -14.779444444444   \n",
       "4         248  57dbaad0ef8af      322623537         -14.78167   \n",
       "\n",
       "          Longitude Validade_RF        Município Frequência Classe Serviço  \\\n",
       "0            -72.67        <NA>  Cruzeiro do Sul      207.0      A      TV   \n",
       "1  -72.895833333333        <NA>      Mâncio Lima      539.0      C      TV   \n",
       "2  -44.993611111111  2023-12-31        Barreiras       79.0      A      TV   \n",
       "3  -39.262222222222  2023-12-31          Itabuna       69.0      A      TV   \n",
       "4         -39.26167  2023-12-31          Itabuna      177.0      B      TV   \n",
       "\n",
       "                            Entidade  UF Status            CNPJ       Fistel  \\\n",
       "0  REDE DE COMUNICACOES ACREANA LTDA  AC  TV-C1  01865469000156  50442889933   \n",
       "1                  X-MEDIAGROUP S.A.  AC  TV-C1  03211814000163  50410887137   \n",
       "2        TELEVISAO OESTE BAIANO LTDA  BA  TV-C4  16395923000120  06030116240   \n",
       "3          TELEVISAO SANTA CRUZ LTDA  BA  TV-C2  13476833000175  06020355110   \n",
       "4                   TV CABRALIA LTDA  BA  TV-C4  13494265000135  06020354903   \n",
       "\n",
       "   Coordenadas_do_Município  \n",
       "0                     False  \n",
       "1                     False  \n",
       "2                     False  \n",
       "3                     False  \n",
       "4                     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mosaico_df = estacoes_df.merge(plano_basico_df, on=\"Id\", how=\"left\")\n",
    "print(len(mosaico_df.index))\n",
    "mosaico_df = clean_mosaico(mosaico_df, '../dados')\n",
    "print(len(mosaico_df.index))\n",
    "display(mosaico_df.head())\n",
    "# mosaico_df.to_csv('../dados/mosaico_df_xml.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_df(df: pd.DataFrame, folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Format, Save and return a dataframe\"\"\"\n",
    "    df = format_types(df, stem)\n",
    "    df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    df = df.dropna(subset=['Latitude', 'Longitude']).reset_index(drop=True)\n",
    "    try:\n",
    "        file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "        df.to_parquet(file, compression=\"gzip\", index=False)\n",
    "    except (ArrowInvalid, ArrowTypeError):\n",
    "        file.unlink(missing_ok=True)\n",
    "        try:\n",
    "            file = Path(f\"{folder}/{stem}.fth\")\n",
    "            df.to_feather(file)\n",
    "        except (ArrowInvalid, ArrowTypeError):\n",
    "            file.unlink(missing_ok=True)\n",
    "            try:\n",
    "                file = Path(f\"{folder}/{stem}.xlsx\")\n",
    "                with pd.ExcelWriter(file) as wb:\n",
    "                    df.to_excel(\n",
    "                        wb, sheet_name=\"DataBase\", engine=\"openpyxl\", index=False\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Could not save {stem} to {file}\") from e\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_radcom(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    "        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            return _save_df(df, folder, \"radcom\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_stel(\n",
    "        conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "        folder:Union[str, Path] # Pasta onde salvar os arquivos        \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"bouncingBall\",\n",
    "    ) as status:\n",
    "        try:            \n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            return _save_df(df, folder, \"stel\")\n",
    "        except pyodbc.OperationalError as e:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "            raise ConnectionError from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">(  ●   )</span> <span style=\"color: #800000; text-decoration-color: #800000\">Lendo o Banco de Dados do STEL. Processo Lento, aguarde...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m(  ●   )\u001b[0m \u001b[31mLendo o Banco de Dados do STEL. Processo Lento, aguarde...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stel = update_stel(Path.cwd().parent / 'dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stel.to_parquet(Path.cwd().parent / 'dados' / 'stel.parquet.gzip', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_mosaico(        \n",
    "        clientMongoDB: MongoClient, # Ojeto de conexão com o MongoDB\n",
    "        folder: Union[str, Path] # Pasta onde salvar os arquivos\n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    \"\"\"Atualiza a tabela local do Mosaico. É baixado e processado arquivos xml zipados da página pública do Spectrum E\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"Consolidando os dados do Mosaico...\", spinner=\"clock\"\n",
    "    ) as status:  \n",
    "        \n",
    "        # stations, _ = urlretrieve(ESTACOES, f\"{folder}/estações.zip\")\n",
    "        # pb, _ = urlretrieve(PLANO_BASICO, f\"{folder}/canais.zip\")\n",
    "        # estações = _read_estações(stations)\n",
    "        # plano_basico = _read_plano_basico(pb)\n",
    "        df = ConsultaSRD(clientMongoDB)\n",
    "        df = clean_mosaico(df, folder)\n",
    "    return _save_df(df, folder, \"mosaico\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='install \"ipywidgets\" for Jupyter support')\n",
    "\n",
    "df = update_mosaico(Path.cwd().parent / 'dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def update_base(\n",
    "    conn: pyodbc.Connection, # Objeto de conexão de banco\n",
    "    clientMongoDB: MongoClient, # Ojeto de conexão com o MongoDB\n",
    "    folder: Union[str, Path] # Pasta onde salvar os arquivos    \n",
    ") -> pd.DataFrame: # DataFrame com os dados atualizados\n",
    "    # sourcery skip: use-fstring-for-concatenation\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na folder `folder`\"\"\"\n",
    "    stel = update_stel(conn, folder, ).loc[:, TELECOM]\n",
    "    radcom = update_radcom(conn, folder).loc[:, SRD]\n",
    "    mosaico = update_mosaico(clientMongoDB, folder).loc[:, RADIODIFUSAO]    \n",
    "    radcom[\"Num_Serviço\"] = \"231\"\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe_Emissão\"] = pd.NA\n",
    "    radcom[\"Largura_Emissão\"] = BW_MAP[\"231\"]\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Validade_RF\"] = pd.NA\n",
    "    radcom[\"Fonte\"] = \"SRD\"\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    mosaico[\"Fonte\"] = \"MOS\"\n",
    "    mosaico[\"Classe_Emissão\"] = pd.NA\n",
    "    mosaico[\"Largura_Emissão\"] = mosaico.Num_Serviço.map(BW_MAP)\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel])\n",
    "        .sort_values([\"Frequência\", \"Latitude\", \"Longitude\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd = rd.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    rd[\"BW(kHz)\"] = rd.Largura_Emissão.astype('string').fillna('-1').apply(parse_bw)\n",
    "    return _save_df(rd, folder, \"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "folder = Path.cwd().parent / 'dados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import Request, urlopen\n",
    "# from urllib.error import URLError\n",
    "# req = Request(ESTACAO)\n",
    "# try:\n",
    "#     response = urlopen(req)\n",
    "# except URLError as e:\n",
    "#     if hasattr(e, 'reason'):\n",
    "#         print('We failed to reach a server.')\n",
    "#         print('Reason: ', e.reason)\n",
    "#     elif hasattr(e, 'code'):\n",
    "#         print('The server couldn\\'t fulfill the request.')\n",
    "#         print('Error code: ', e.code)\n",
    "# else:\n",
    "#     Path.cwd().joinpath('estações.zip').write_bytes(response.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('anateldb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37a0fa21125bc68b41a424f43d92a26fa97b5ebccfac6eecdcaf85c09668024f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
