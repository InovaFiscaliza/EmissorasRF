{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasources.base\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys,os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "os.chdir(Path.cwd().parent / \"extracao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Base\n",
    "> Módulo para encapsular a extração e processamento comum às diferentes fontes de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from functools import cached_property\n",
    "from typing import Tuple, Union, List\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fastcore.xtras import Path, listify\n",
    "from pyarrow import ArrowInvalid, ArrowTypeError\n",
    "\n",
    "from extracao.constants import BW, RE_BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide: true\n",
    "# | eval:false\n",
    "__file__ = Path.cwd().parent / \"extracao\" / \"datasources.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Base:\n",
    "    folder: Union[str, Path] = Path(__file__).parent / \"arquivos\" / \"saida\"\n",
    "\n",
    "    def _read(self, stem: str) -> pd.DataFrame:\n",
    "        \"\"\"Lê o dataframe formado por self.folder / self.stem.parquet.gzip\"\"\"\n",
    "        file = Path(f\"{self.folder}/{stem}.parquet.gzip\")\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "        except (ArrowInvalid, FileNotFoundError) as e:\n",
    "            raise ValueError(f\"Error when reading {file}\") from e\n",
    "        return df\n",
    "\n",
    "    def _save(\n",
    "        self, df: pd.DataFrame, folder: Union[str, Path], stem: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Format, Save and return a dataframe\"\"\"\n",
    "        df = df.astype(\"string\").drop_duplicates(keep=\"first\", ignore_index=True)\n",
    "        try:\n",
    "            file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "            df.to_parquet(file, compression=\"gzip\", index=False)\n",
    "        except (ArrowInvalid, ArrowTypeError) as e:\n",
    "            raise e(f\"Não foi possível salvar o arquivo parquet {file}\") from e\n",
    "        return df\n",
    "\n",
    "    @cached_property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            df = self._read(self.stem)\n",
    "        except (ArrowInvalid, FileNotFoundError):\n",
    "            df = self._format(self.extraction)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_bw(\n",
    "        bw: str,  # Designação de Emissão (Largura + Classe) codificada como string\n",
    "    ) -> Tuple[str, str]:  # Largura e Classe de Emissão\n",
    "        \"\"\"Parse the bandwidth string\"\"\"\n",
    "        if match := re.match(RE_BW, bw):\n",
    "            multiplier = BW[match[2]]\n",
    "            if mantissa := match[3]:\n",
    "                number = float(f\"{match[1]}.{mantissa}\")\n",
    "            else:\n",
    "                number = float(match[1])\n",
    "            classe = match[4]\n",
    "            return str(multiplier * number), str(classe)\n",
    "        return pd.NA, pd.NA\n",
    "\n",
    "    @cached_property\n",
    "    def discarded(self) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(columns=self.columns)\n",
    "        df[\"Log\"] = \"\"\n",
    "        return df\n",
    "\n",
    "    def append2discarded(self, dfs: Union[pd.DataFrame, List]) -> None:\n",
    "        \"\"\"Receives one of more dataframes and append to the discarded dataframe\"\"\"\n",
    "        self.discarded = pd.concat([self.discarded] + listify(dfs), ignore_index=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def register_log(df: pd.DataFrame, log: str, row_filter: pd.Series = None):\n",
    "        \"\"\"Register a log in the dataframe\"\"\"\n",
    "        if row_filter is None:\n",
    "            row_filter = pd.Series(True, index=df.index)\n",
    "        df.loc[row_filter, \"Log\"] = df.loc[row_filter, \"Log\"] + \"|\" + log\n",
    "        return df\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        raise NotImplementedError(\n",
    "            \"Subclasses devem implementar a propriedade 'columns'\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def cols_mapping(self):\n",
    "        raise NotImplementedError(\n",
    "            \"Subclasses devem implementar a propriedade 'cols_mapping'\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def stem(self):\n",
    "        raise NotImplementedError(\"Subclasses devem setar a propriedade stem!\")\n",
    "\n",
    "    def extraction(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError(\"Subclasses devem implementar o método extract\")\n",
    "\n",
    "    def _format(\n",
    "        self,\n",
    "        df: pd.DataFrame,  # DataFrame com os dados de Estações\n",
    "    ) -> pd.DataFrame:  # DataFrame formatado\n",
    "        \"\"\"Formata, limpa e padroniza os dados provenientes da query no banco\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses devem implementar o método _format\")\n",
    "\n",
    "    def update(self):\n",
    "        self.df = self._format(self.extraction)\n",
    "\n",
    "    def save(self, folder: Union[str, Path] = None):\n",
    "        if folder is None:\n",
    "            folder = self.folder\n",
    "        self._save(self.df, folder, self.stem)\n",
    "        self._save(self.discarded, folder, f\"{self.stem}_discarded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.doclinks import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: []\n",
       " Index: []]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listify(pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
