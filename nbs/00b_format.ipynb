{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp format\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys, os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "import re\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fastcore.utils import listify\n",
    "from fastcore.xtras import Path\n",
    "from geopy.distance import geodesic\n",
    "from pyarrow import ArrowInvalid\n",
    "\n",
    "from extracao.constants import APP_ANALISE_EN, APP_ANALISE_PT, BW, RE_BW\n",
    "\n",
    "MAX_DIST = 10  # Km\n",
    "LIMIT_FREQ = 84812.50\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_df(folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Lê o dataframe formado por folder / stem.[parquet.gzip | fth | xslx]\"\"\"\n",
    "    file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file)\n",
    "    except (ArrowInvalid, FileNotFoundError) as e:\n",
    "        raise e(f\"Error when reading {file}\") from e\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação\n",
    "\n",
    "> Este módulo possui funções auxiliares de formatação dos dados das várias fontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def parse_bw(\n",
    "    bw: str,  # Designação de Emissão (Largura + Classe) codificada como string\n",
    ") -> Tuple[str, str]:  # Largura e Classe de Emissão\n",
    "    \"\"\"Parse the bandwidth string\"\"\"\n",
    "    if match := re.match(RE_BW, bw):\n",
    "        multiplier = BW[match[2]]\n",
    "        if mantissa := match[3]:\n",
    "            number = float(f\"{match[1]}.{mantissa}\")\n",
    "        else:\n",
    "            number = float(match[1])\n",
    "        classe = match[4]\n",
    "        return str(multiplier * number), str(classe)\n",
    "    return pd.NA, pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _filter_matlab(\n",
    "    df: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "    \"\"\"Recebe a base de dados da Anatel e formata as colunas para leitura de acordo com os requisitos do Matlab\"\"\"\n",
    "    df[\"#Estação\"] = df[\"Estação\"]\n",
    "    df.loc[df.Multiplicidade != \"1\", \"#Estação\"] = (\n",
    "        df.loc[df.Multiplicidade != \"1\", \"Estação\"]\n",
    "        + \"+\"\n",
    "        + df.loc[df.Multiplicidade != \"1\", \"Multiplicidade\"]\n",
    "    )\n",
    "    cols_desc = [\n",
    "        \"Fonte\",\n",
    "        \"Status\",\n",
    "        \"Classe\",\n",
    "        \"Entidade\",\n",
    "        \"Fistel\",\n",
    "        \"#Estação\",\n",
    "        \"Município_IBGE\",\n",
    "        \"UF\",\n",
    "    ]\n",
    "    df.loc[:, cols_desc] = df.loc[:, cols_desc].astype(\"string\").fillna(\"NI\")\n",
    "\n",
    "    df[\"Descrição\"] = (\n",
    "        \"[\"\n",
    "        + df.Fonte\n",
    "        + \"] \"\n",
    "        + df.Status\n",
    "        + \", \"\n",
    "        + df.Classe\n",
    "        + \", \"\n",
    "        + df.Entidade.str.title()\n",
    "        + \" (\"\n",
    "        + df.Fistel\n",
    "        + \", \"\n",
    "        + df[\"#Estação\"]\n",
    "        + \"), \"\n",
    "        + df.Município_IBGE\n",
    "        + \"/\"\n",
    "        + df.UF\n",
    "    )\n",
    "\n",
    "    bad_coords = df.Coords_Valida_IBGE == \"0\"\n",
    "\n",
    "    df.loc[bad_coords, \"Descrição\"] = df.loc[bad_coords, \"Descrição\"] + \"*\"\n",
    "\n",
    "    df.loc[bad_coords, [\"Latitude\", \"Longitude\"]] = df.loc[\n",
    "        bad_coords, [\"Latitude_IBGE\", \"Longitude_IBGE\"]\n",
    "    ].values\n",
    "\n",
    "    df = df.loc[:, APP_ANALISE_PT]\n",
    "    df.columns = APP_ANALISE_EN\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _format_matlab(\n",
    "    df: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "    \"\"\"Formata o arquivo final de dados para o formato esperado pela aplicação em Matlab\"\"\"\n",
    "    df = df.astype(\"string\")\n",
    "    df.loc[len(df), :] = [\n",
    "        \"-1\",\n",
    "        \"-15.7801\",\n",
    "        \"-47.9292\",\n",
    "        \"[TEMP] L, FX, Estação do SMP licenciada (cadastro temporário)\",\n",
    "        \"10\",\n",
    "        \"999999999\",\n",
    "        \"NI\",\n",
    "        \"-1\",\n",
    "    ]  # Paliativo...\n",
    "    for c in df.columns:\n",
    "        if c not in [\"Description\", \"Class\"]:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    for c in [\"Latitude\", \"Longitude\"]:\n",
    "        df[c] = df[c].fillna(-1).astype(\"float32\")\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(\"float64\")\n",
    "    df[\"Service\"] = df.Service.fillna(-1).astype(\"int16\")\n",
    "    df[\"Station\"] = df.Station.fillna(-1).astype(\"int32\")\n",
    "    df[\"BW\"] = df[\"BW\"].fillna(-1).astype(\"float32\")\n",
    "    df.loc[df[\"Class\"].isin([\"\", \"-1\"]), \"Class\"] = pd.NA\n",
    "    df[\"Class\"] = df.Class.fillna(\"NI\").astype(\"category\")\n",
    "    df = df[df.Frequency <= LIMIT_FREQ]\n",
    "    df.sort_values(\n",
    "        by=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"], inplace=True\n",
    "    )\n",
    "    unique_columns = df.columns.tolist()\n",
    "    unique_columns.remove(\"Description\")\n",
    "    df = df.drop_duplicates(subset=unique_columns, keep=\"last\").reset_index(drop=True)\n",
    "    df[\"Id\"] = [f\"#{i+1}\" for i in df.index]\n",
    "    df[\"Id\"] = df.Id.astype(\"string\")\n",
    "    df.loc[df.Description == \"\", \"Description\"] = pd.NA\n",
    "    df[\"Description\"] = df[\"Description\"].astype(\"string\").fillna(\"NI\")\n",
    "    return df[[\"Id\"] + list(APP_ANALISE_EN)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclagem\n",
    "Função auxiliar para mesclar registros que são iguais das diversas bases, i.e. estão a uma distância menor que `MAX_DIST` e verificar a validade da mesclagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_km_distance(row):\n",
    "    return geodesic((row.iloc[0], row.iloc[1]), (row.iloc[2], row.iloc[3])).km\n",
    "\n",
    "\n",
    "def merge_on_frequency(\n",
    "    df_left: pd.DataFrame,  # DataFrame da esquerda a ser mesclado\n",
    "    df_right: pd.DataFrame,  # DataFrame da direira a ser mesclado\n",
    "    on: str = \"Frequência\",  # Coluna usada como chave de mesclagem\n",
    "    cols2merge: Tuple = (\"Entidade\", \"Fonte\"),  # Colunas a serem mescladas\n",
    ") -> pd.DataFrame:  # DataFrame resultante da mesclagem\n",
    "    \"\"\"Mescla os dataframes baseados na frequência\n",
    "    É assumido que as colunas de ambos uma é subconjunto ou idêntica à outra, caso contrário os filtros não irão funcionar como esperado\n",
    "    \"\"\"\n",
    "    df_left[\"Frequência\"] = df_left[\"Frequência\"].astype(\n",
    "        \"string[pyarrow]\"\n",
    "    )  # .drop_duplicates(ignore_index=True)\n",
    "    df_right[\"Frequência\"] = df_right[\"Frequência\"].astype(\n",
    "        \"string[pyarrow]\"\n",
    "    )  # .drop_duplicates(ignore_index=True)\n",
    "    df: pd.DataFrame = pd.merge(\n",
    "        df_left,\n",
    "        df_right,\n",
    "        on=on,\n",
    "        how=\"outer\",\n",
    "        indicator=True,\n",
    "        copy=False,\n",
    "    )\n",
    "\n",
    "    left_suffix, right_suffix = \"_x\", \"_y\"\n",
    "    lat, long = \"Latitude\", \"Longitude\"\n",
    "\n",
    "    left_only = df._merge == \"left_only\"\n",
    "    right_only = df._merge == \"right_only\"\n",
    "    both = df._merge == \"both\"\n",
    "    df = df.drop(columns=[\"_merge\"])\n",
    "\n",
    "    # Disjuntos\n",
    "    if df[both].empty:\n",
    "        return pd.concat([df_left, df_right], ignore_index=True)\n",
    "\n",
    "    left_cols = [c for c in df.columns if right_suffix not in c]\n",
    "    right_cols = [c for c in df.columns if left_suffix not in c]\n",
    "\n",
    "    only_left = (\n",
    "        df.loc[left_only, left_cols]\n",
    "        .copy()\n",
    "        .drop_duplicates(subset=left_cols, ignore_index=True)\n",
    "    )\n",
    "    only_left.columns = [c.replace(left_suffix, \"\") for c in left_cols]\n",
    "\n",
    "    only_right = (\n",
    "        df.loc[right_only, right_cols]\n",
    "        .copy()\n",
    "        .drop_duplicates(subset=right_cols, ignore_index=True)\n",
    "    )\n",
    "    only_right.columns = [c.replace(right_suffix, \"\") for c in right_cols]\n",
    "\n",
    "    intersection_left = len(df_left) - len(only_left)\n",
    "    intersection_right = len(df_right) - len(only_right)\n",
    "\n",
    "    both_columns = [\n",
    "        f\"{lat}{left_suffix}\",\n",
    "        f\"{long}{left_suffix}\",\n",
    "        f\"{lat}{right_suffix}\",\n",
    "        f\"{long}{right_suffix}\",\n",
    "    ]\n",
    "    df.loc[both, \"Distance\"] = df.loc[both, both_columns].apply(get_km_distance, axis=1)\n",
    "\n",
    "    df_both = df[both].sort_values(\"Distance\", ignore_index=True)\n",
    "\n",
    "    filter_left_cols = df_both.columns[: len(df_left.columns)].to_list()\n",
    "    filter_right_cols = (\n",
    "        listify(on) + df_both.columns[len(df_left.columns) : -1].to_list()\n",
    "    )  # the -1 is to eliminate the distance\n",
    "\n",
    "    # keep only the closer merged rows in the outer join\n",
    "    df_both_left = df_both.copy().drop_duplicates(\n",
    "        filter_left_cols, keep=\"first\", ignore_index=True\n",
    "    )\n",
    "    df_both_right = df_both.copy().drop_duplicates(\n",
    "        filter_right_cols, keep=\"first\", ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Sanity Checks\n",
    "    assert (\n",
    "        len(df_both_left) == intersection_left\n",
    "    ), f\"Grouping by unique columns has unexpected length: {len(df_both_left)}!= {intersection_left}\"\n",
    "\n",
    "    assert (\n",
    "        len(df_both_right) == intersection_right\n",
    "    ), f\"Grouping by unique columns has unexpected length: {len(df_both_right)}!= {intersection_right}\"\n",
    "\n",
    "    # Separate according the MAX_DIST\n",
    "    df_both_far_left = df_both_left[df_both_left.Distance > MAX_DIST]\n",
    "    df_both_far_right = df_both_right[df_both_right.Distance > MAX_DIST]\n",
    "\n",
    "    df_both_left = df_both_left[df_both_left.Distance <= MAX_DIST]\n",
    "    df_both_right = df_both_right[df_both_right.Distance <= MAX_DIST]\n",
    "\n",
    "    merge_cols = df_both.columns.to_list()\n",
    "    merge_cols.remove(\"Distance\")\n",
    "    # Since it's an outer join, keep only the columns that are in both\n",
    "    df_close_merge = (\n",
    "        pd.merge(df_both_left, df_both_right, how=\"inner\", on=merge_cols, copy=False)\n",
    "        .drop(\"Distance_y\", axis=1)\n",
    "        .rename(columns={\"Distance_x\": \"Distance\"})\n",
    "    )\n",
    "\n",
    "    df_both_left = _left_filter(df_both_left, df_close_merge, merge_cols)\n",
    "    df_both_right = _left_filter(df_both_right, df_close_merge, merge_cols)\n",
    "\n",
    "    assert pd.merge(\n",
    "        df_both_left, df_both_right, how=\"inner\", on=merge_cols\n",
    "    ).empty, \"Check merging steps, df_both_left and df_both_right should be disjoint\"\n",
    "\n",
    "    df_final_merge = pd.concat(\n",
    "        [df_close_merge, df_both_left, df_both_right], ignore_index=True\n",
    "    )\n",
    "\n",
    "    assert len(df_both_far_left) + len(df_close_merge) + len(df_both_left) == (\n",
    "        len(df_left) - len(only_left)\n",
    "    ), \"Check merging steps, validation failed!\"\n",
    "\n",
    "    assert len(df_both_far_right) + len(df_close_merge) + len(df_both_right) == (\n",
    "        len(df_right) - len(only_right)\n",
    "    ), \"Check merging steps, validation failed!\"\n",
    "\n",
    "    original_cols = df_both.columns.to_list()\n",
    "    df_both = (\n",
    "        pd.merge(\n",
    "            df_both, df_final_merge, how=\"left\", on=filter_left_cols, indicator=True\n",
    "        )\n",
    "        .loc[lambda x: x[\"_merge\"] == \"left_only\"]\n",
    "        .iloc[:, range(len(original_cols))]\n",
    "    )\n",
    "    df_both.columns = original_cols\n",
    "\n",
    "    df_both = (\n",
    "        pd.merge(\n",
    "            df_both, df_final_merge, how=\"left\", on=filter_right_cols, indicator=True\n",
    "        )\n",
    "        .loc[lambda x: x[\"_merge\"] == \"left_only\"]\n",
    "        .iloc[:, range(len(original_cols))]\n",
    "    )\n",
    "    df_both.columns = original_cols\n",
    "\n",
    "    assert (\n",
    "        df_both.Distance > MAX_DIST\n",
    "    ).all(), \"Check merging steps, validation failed!\"\n",
    "\n",
    "    assert (\n",
    "        pd.merge(\n",
    "            df_both,\n",
    "            df_both_far_left,\n",
    "            how=\"left\",\n",
    "            on=filter_left_cols,\n",
    "            indicator=True,\n",
    "            copy=False,\n",
    "        )\n",
    "        .loc[lambda x: x[\"_merge\"] == \"left_only\"]\n",
    "        .iloc[:, range(len(original_cols))]\n",
    "        .empty\n",
    "    ), \"Check merging steps, validation failed!\"\n",
    "\n",
    "    assert (\n",
    "        pd.merge(\n",
    "            df_both,\n",
    "            df_both_far_right,\n",
    "            how=\"left\",\n",
    "            on=filter_right_cols,\n",
    "            indicator=True,\n",
    "            copy=False,\n",
    "        )\n",
    "        .loc[lambda x: x[\"_merge\"] == \"left_only\"]\n",
    "        .iloc[:, range(len(original_cols))]\n",
    "        .empty\n",
    "    ), \"Check merging steps, validation failed!\"\n",
    "\n",
    "    for col in cols2merge:\n",
    "        df_final_merge[f\"{col}{left_suffix}\"] = (\n",
    "            df_final_merge[f\"{col}{left_suffix}\"]\n",
    "            + \" | \"\n",
    "            + df_final_merge[f\"{col}{right_suffix}\"]\n",
    "        )\n",
    "\n",
    "    df_final_merge = df_final_merge[left_cols]\n",
    "    df_final_merge.columns = only_left.columns\n",
    "\n",
    "    df_both_far_left = df_both_far_left[left_cols]\n",
    "    df_both_far_left.columns = only_left.columns\n",
    "\n",
    "    df_both_far_right = df_both_far_right[right_cols]\n",
    "    df_both_far_right.columns = only_right.columns\n",
    "\n",
    "    return pd.concat(\n",
    "        [only_left, df_both_far_left, df_final_merge, only_right, df_both_far_right],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def _left_filter(df, df_close_merge, merge_cols):\n",
    "    df = pd.merge(\n",
    "        df, df_close_merge, how=\"left\", on=merge_cols, indicator=True, copy=False\n",
    "    )\n",
    "    df = df.loc[df[\"_merge\"] == \"left_only\"]\n",
    "    return df.drop([\"_merge\", \"Distance_y\"], axis=1).rename(\n",
    "        columns={\"Distance_x\": \"Distance\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "folder = Path.cwd().parent / \"dados\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
