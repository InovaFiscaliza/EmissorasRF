{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp format\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sys, os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "import re\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fastcore.utils import listify\n",
    "from fastcore.xtras import Path\n",
    "from geopy.distance import geodesic\n",
    "from pyarrow import ArrowInvalid\n",
    "\n",
    "from extracao.constants import APP_ANALISE_EN, APP_ANALISE_PT, BW, RE_BW\n",
    "\n",
    "MAX_DIST = 10  # Km\n",
    "LIMIT_FREQ = 84812.50\n",
    "load_dotenv(find_dotenv(), override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_df(folder: Union[str, Path], stem: str) -> pd.DataFrame:\n",
    "    \"\"\"Lê o dataframe formado por folder / stem.[parquet.gzip | fth | xslx]\"\"\"\n",
    "    file = Path(f\"{folder}/{stem}.parquet.gzip\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file)\n",
    "    except (ArrowInvalid, FileNotFoundError) as e:\n",
    "        raise e(f\"Error when reading {file}\") from e\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação\n",
    "\n",
    "> Este módulo possui funções auxiliares de formatação dos dados das várias fontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def parse_bw(\n",
    "\tbw: str,  # Designação de Emissão (Largura + Classe) codificada como string\n",
    ") -> Tuple[str, str]:  # Largura e Classe de Emissão\n",
    "\t\"\"\"Parse the bandwidth string\"\"\"\n",
    "\tif match := re.match(RE_BW, bw):\n",
    "\t\tmultiplier = BW[match[2]]\n",
    "\t\tif mantissa := match[3]:\n",
    "\t\t\tnumber = float(f'{match[1]}.{mantissa}')\n",
    "\t\telse:\n",
    "\t\t\tnumber = float(match[1])\n",
    "\t\tclasse = match[4]\n",
    "\t\treturn str(multiplier * number), str(classe)\n",
    "\treturn pd.NA, pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _filter_matlab(\n",
    "\tdf: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "\t\"\"\"Recebe a base de dados da Anatel e formata as colunas para leitura de acordo com os requisitos do Matlab\"\"\"\n",
    "\tdf['#Estação'] = df['Número_Estação']\n",
    "\tdf.loc[df.Multiplicidade != '1', '#Estação'] = (\n",
    "\t\tdf.loc[df.Multiplicidade != '1', 'Número_Estação']\n",
    "\t\t+ '+'\n",
    "\t\t+ df.loc[df.Multiplicidade != '1', 'Multiplicidade']\n",
    "\t)\n",
    "\tcols_desc = [\n",
    "\t\t'Fonte',\n",
    "\t\t'Status',\n",
    "\t\t'Classe',\n",
    "\t\t'Entidade',\n",
    "\t\t'Fistel',\n",
    "\t\t'#Estação',\n",
    "\t\t'Município_IBGE',\n",
    "\t\t'UF',\n",
    "\t]\n",
    "\tdf.loc[:, cols_desc] = df.loc[:, cols_desc].astype('string').fillna('NI')\n",
    "\n",
    "\tdf['Descrição'] = (\n",
    "\t\t'['\n",
    "\t\t+ df.Fonte\n",
    "\t\t+ '] '\n",
    "\t\t+ df.Status\n",
    "\t\t+ ', '\n",
    "\t\t+ df.Classe\n",
    "\t\t+ ', '\n",
    "\t\t+ df.Entidade.str.title()\n",
    "\t\t+ ' ('\n",
    "\t\t+ df.Fistel\n",
    "\t\t+ ', '\n",
    "\t\t+ df['#Estação']\n",
    "\t\t+ '), '\n",
    "\t\t+ df.Município_IBGE\n",
    "\t\t+ '/'\n",
    "\t\t+ df.UF\n",
    "\t)\n",
    "\n",
    "\tbad_coords = df.Coords_Valida_IBGE == '0'\n",
    "\n",
    "\tdf.loc[bad_coords, 'Descrição'] = df.loc[bad_coords, 'Descrição'] + '*'\n",
    "\n",
    "\tdf.loc[bad_coords, ['Latitude', 'Longitude']] = df.loc[\n",
    "\t\tbad_coords, ['Latitude_IBGE', 'Longitude_IBGE']\n",
    "\t].values\n",
    "\n",
    "\tdf = df.loc[:, APP_ANALISE_PT]\n",
    "\tdf.columns = APP_ANALISE_EN\n",
    "\treturn df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _format_matlab(\n",
    "\tdf: pd.DataFrame,  # Arquivo de Dados Base de Entrada\n",
    ") -> pd.DataFrame:  # Arquivo de Dados formatado para leitura no Matlab\n",
    "\t\"\"\"Formata o arquivo final de dados para o formato esperado pela aplicação em Matlab\"\"\"\n",
    "\tdf = df.astype('string')\n",
    "\tdf.loc[len(df), :] = [\n",
    "\t\t'-1',\n",
    "\t\t'-15.7801',\n",
    "\t\t'-47.9292',\n",
    "\t\t'[TEMP] L, FX, Estação do SMP licenciada (cadastro temporário)',\n",
    "\t\t'10',\n",
    "\t\t'999999999',\n",
    "\t\t'NI',\n",
    "\t\t'-1',\n",
    "\t]  # Paliativo...\n",
    "\tfor c in df.columns:\n",
    "\t\tif c not in ['Description', 'Class']:\n",
    "\t\t\tdf[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\tfor c in ['Latitude', 'Longitude']:\n",
    "\t\tdf[c] = df[c].fillna(-1).astype('float32')\n",
    "\tdf['Frequency'] = df['Frequency'].astype('float64')\n",
    "\tdf['Service'] = df.Service.fillna(-1).astype('int16')\n",
    "\tdf['Station'] = df.Station.fillna(-1).astype('int32')\n",
    "\tdf['BW'] = df['BW'].fillna(-1).astype('float32')\n",
    "\tdf.loc[df['Class'].isin(['', '-1']), 'Class'] = pd.NA\n",
    "\tdf['Class'] = df.Class.fillna('NI').astype('category')\n",
    "\tdf = df[df.Frequency <= LIMIT_FREQ]\n",
    "\tdf.sort_values(by=['Frequency', 'Latitude', 'Longitude', 'Description'], inplace=True)\n",
    "\tunique_columns = df.columns.tolist()\n",
    "\tunique_columns.remove('Description')\n",
    "\tdf = df.drop_duplicates(subset=unique_columns, keep='last').reset_index(drop=True)\n",
    "\tdf['Id'] = [f'#{i+1}' for i in df.index]\n",
    "\tdf['Id'] = df.Id.astype('string')\n",
    "\tdf.loc[df.Description == '', 'Description'] = pd.NA\n",
    "\tdf['Description'] = df['Description'].astype('string').fillna('NI')\n",
    "\treturn df[['Id'] + list(APP_ANALISE_EN)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesclagem\n",
    "Função auxiliar para mesclar registros que são iguais das diversas bases, i.e. estão a uma distância menor que `MAX_DIST` e verificar a validade da mesclagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_km_distance(row):\n",
    "\treturn geodesic((row[0], row[1]), (row[2], row[3])).km\n",
    "\n",
    "\n",
    "def merge_on_frequency(\n",
    "\tdf_left: pd.DataFrame,  # DataFrame da esquerda a ser mesclado\n",
    "\tdf_right: pd.DataFrame,  # DataFrame da direira a ser mesclado\n",
    "\ton: str = 'Frequência',  # Coluna usada como chave de mesclagem\n",
    "\tcoords: Tuple[str] = ('Latitude', 'Longitude'),  # Coordenadas usadas para avaliar a distância\n",
    "\tcols2merge: str = ('Entidade', 'Fonte'),  # Colunas a serem mescladas\n",
    "\tsuffixes: Tuple[str] = ('_x', '_y'),  # Sufixo para as colunas que foram criadas\n",
    ") -> pd.DataFrame:  # DataFrame resultante da mesclagem\n",
    "\t\"\"\"Mescla os dataframes baseados na frequência\n",
    "\tÉ assumido que as colunas de ambos uma é subconjunto ou idêntica à outra, caso contrário os filtros não irão funcionar como esperado\n",
    "\t\"\"\"\n",
    "\tdf_left = df_left.astype('string').drop_duplicates(ignore_index=True)\n",
    "\tdf_right = df_right.astype('string').drop_duplicates(ignore_index=True)\n",
    "\tdf: pd.DataFrame = pd.merge(\n",
    "\t\tdf_left,\n",
    "\t\tdf_right,\n",
    "\t\ton=on,\n",
    "\t\thow='outer',\n",
    "\t\tsuffixes=suffixes,\n",
    "\t\tindicator=True,\n",
    "\t\tcopy=False,\n",
    "\t)\n",
    "\n",
    "\tx, y = suffixes\n",
    "\tlat, long = coords\n",
    "\n",
    "\tleft = df._merge == 'left_only'\n",
    "\tright = df._merge == 'right_only'\n",
    "\tboth = df._merge == 'both'\n",
    "\tdf = df.drop(columns=['_merge'])\n",
    "\n",
    "\tleft_cols: List[str] = [c for c in df.columns if y not in c]\n",
    "\tright_cols: List[str] = [c for c in df.columns if x not in c]\n",
    "\n",
    "\tonly_left = df.loc[left, left_cols].drop_duplicates(subset=left_cols, ignore_index=True)\n",
    "\tonly_left.columns = [c.replace(x, '') for c in left_cols]\n",
    "\n",
    "\tonly_right = df.loc[right, right_cols].drop_duplicates(subset=right_cols, ignore_index=True)\n",
    "\tonly_right.columns = [c.replace(y, '') for c in right_cols]\n",
    "\n",
    "\tintersection_left = len(df_left) - len(only_left)\n",
    "\tintersection_right = len(df_right) - len(only_right)\n",
    "\n",
    "\tif not intersection_left or not intersection_right:\n",
    "\t\treturn pd.concat([df_left, df_right], ignore_index=True)\n",
    "\n",
    "\tboth_columns = [f'{lat}{x}', f'{long}{x}', f'{lat}{y}', f'{long}{y}']\n",
    "\tdf.loc[both, 'Distance'] = df.loc[both, both_columns].apply(get_km_distance, axis=1)\n",
    "\n",
    "\tdf_both = df[both].sort_values('Distance', ignore_index=True)\n",
    "\n",
    "\tfilter_left_cols = df_both.columns[: len(df_left.columns)].to_list()\n",
    "\tfilter_right_cols = (\n",
    "\t\tlistify(on) + df_both.columns[len(df_left.columns) : -1].to_list()\n",
    "\t)  # the -1 is to eliminate the distance\n",
    "\n",
    "\tdf_both_left = df_both.groupby(filter_left_cols, as_index=False).first()\n",
    "\tdf_both_right = df_both.groupby(filter_right_cols, as_index=False).first()\n",
    "\n",
    "\tassert (\n",
    "\t\tlen(df_both_left) == intersection_left\n",
    "\t), f'O Agrupamento por colunas únicas não tem o comprimento esperado: {len(df_both_left)}!= {intersection_left}'\n",
    "\n",
    "\tassert (\n",
    "\t\tlen(df_both_right) == intersection_right\n",
    "\t), f'Error: {len(df_both_right)}!= {intersection_right}'\n",
    "\n",
    "\tdf_both_far_left = df_both_left[df_both_left.Distance > MAX_DIST]\n",
    "\tdf_both_far_right = df_both_right[df_both_right.Distance > MAX_DIST]\n",
    "\n",
    "\tdf_both_left = df_both_left[df_both_left.Distance <= MAX_DIST]\n",
    "\tdf_both_right = df_both_right[df_both_right.Distance <= MAX_DIST]\n",
    "\n",
    "\tmerge_cols = df_both.columns.to_list()\n",
    "\tmerge_cols.remove('Distance')\n",
    "\tdf_close_merge = (\n",
    "\t\tpd.merge(df_both_left, df_both_right, how='inner', on=merge_cols, copy=False)\n",
    "\t\t.drop('Distance_y', axis=1)\n",
    "\t\t.rename(columns={'Distance_x': 'Distance'})\n",
    "\t)\n",
    "\n",
    "\tdf_both_left = _left_filter(df_both_left, df_close_merge, merge_cols)\n",
    "\tdf_both_right = _left_filter(df_both_right, df_close_merge, merge_cols)\n",
    "\n",
    "\tassert pd.merge(\n",
    "\t\tdf_both_left, df_both_right, how='inner', on=merge_cols\n",
    "\t).empty, 'Verifique os passos de mesclagem, df_both_left e df_both_right deveria ser disjuntos'\n",
    "\n",
    "\tdf_final_merge = pd.concat([df_close_merge, df_both_left, df_both_right], ignore_index=True)\n",
    "\n",
    "\tassert len(df_both_far_left) + len(df_close_merge) + len(df_both_left) == (\n",
    "\t\tlen(df_left) - len(only_left)\n",
    "\t), 'Verifique os passos de mesclagem, validação falhou!'\n",
    "\n",
    "\tassert len(df_both_far_right) + len(df_close_merge) + len(df_both_right) == (\n",
    "\t\tlen(df_right) - len(only_right)\n",
    "\t), 'Verifique os passos de mesclagem, validação falhou!'\n",
    "\n",
    "\toriginal_cols = df_both.columns.to_list()\n",
    "\tdf_both = (\n",
    "\t\tpd.merge(df_both, df_final_merge, how='left', on=filter_left_cols, indicator=True)\n",
    "\t\t.loc[lambda x: x['_merge'] == 'left_only']\n",
    "\t\t.iloc[:, range(len(original_cols))]\n",
    "\t)\n",
    "\tdf_both.columns = original_cols\n",
    "\n",
    "\tdf_both = (\n",
    "\t\tpd.merge(df_both, df_final_merge, how='left', on=filter_right_cols, indicator=True)\n",
    "\t\t.loc[lambda x: x['_merge'] == 'left_only']\n",
    "\t\t.iloc[:, range(len(original_cols))]\n",
    "\t)\n",
    "\tdf_both.columns = original_cols\n",
    "\n",
    "\tassert (\n",
    "\t\tdf_both.Distance > MAX_DIST\n",
    "\t).all(), 'Verifique os passos de mesclagem, validação falhou!'\n",
    "\n",
    "\tassert (\n",
    "\t\tpd.merge(\n",
    "\t\t\tdf_both,\n",
    "\t\t\tdf_both_far_left,\n",
    "\t\t\thow='left',\n",
    "\t\t\ton=filter_left_cols,\n",
    "\t\t\tindicator=True,\n",
    "\t\t\tcopy=False,\n",
    "\t\t)\n",
    "\t\t.loc[lambda x: x['_merge'] == 'left_only']\n",
    "\t\t.iloc[:, range(len(original_cols))]\n",
    "\t\t.empty\n",
    "\t), 'Verifique os passos de mesclagem, validação falhou!'\n",
    "\n",
    "\tassert (\n",
    "\t\tpd.merge(\n",
    "\t\t\tdf_both,\n",
    "\t\t\tdf_both_far_right,\n",
    "\t\t\thow='left',\n",
    "\t\t\ton=filter_right_cols,\n",
    "\t\t\tindicator=True,\n",
    "\t\t\tcopy=False,\n",
    "\t\t)\n",
    "\t\t.loc[lambda x: x['_merge'] == 'left_only']\n",
    "\t\t.iloc[:, range(len(original_cols))]\n",
    "\t\t.empty\n",
    "\t), 'Verifique os passos de mesclagem, validação falhou!'\n",
    "\n",
    "\tfor col in cols2merge:\n",
    "\t\tdf_final_merge[f'{col}{x}'] = (\n",
    "\t\t\tdf_final_merge[f'{col}{x}'] + ' | ' + df_final_merge[f'{col}{y}']\n",
    "\t\t)\n",
    "\n",
    "\tdf_final_merge = df_final_merge[left_cols]\n",
    "\tdf_final_merge.columns = only_left.columns\n",
    "\n",
    "\tdf_both_far_left = df_both_far_left[left_cols]\n",
    "\tdf_both_far_left.columns = only_left.columns\n",
    "\n",
    "\tdf_both_far_right = df_both_far_right[right_cols]\n",
    "\tdf_both_far_right.columns = only_right.columns\n",
    "\n",
    "\tmerged_df = pd.concat(\n",
    "\t\t[only_left, df_both_far_left, df_final_merge, only_right, df_both_far_right],\n",
    "\t\tignore_index=True,\n",
    "\t)\n",
    "\treturn merged_df.astype('string').drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "def _left_filter(df, df_close_merge, merge_cols):\n",
    "\tdf = pd.merge(df, df_close_merge, how='left', on=merge_cols, indicator=True, copy=False)\n",
    "\tdf = df.loc[df['_merge'] == 'left_only']\n",
    "\treturn df.drop(['_merge', 'Distance_y'], axis=1).rename(columns={'Distance_x': 'Distance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "folder = Path.cwd().parent / \"dados\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
