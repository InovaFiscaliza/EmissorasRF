# AUTOGENERATED! DO NOT EDIT! File to edit: ..\nbs\main.ipynb.

# %% auto 0
__all__ = ['bump_version', 'get_modtimes', 'get_db']

# %% ..\nbs\main.ipynb 2
from pathlib import Path
import json
from typing import Union
from datetime import datetime
from tqdm.auto import tqdm

import pandas as pd
from fastcore.test import *
from rich import print
import pyodbc
from pymongo import MongoClient
from dotenv import load_dotenv

from .constants import APP_ANALISE
from .reading import read_base, read_aero
from .format import merge_close_rows

load_dotenv()

# %% ..\nbs\main.ipynb 3
def bump_version(
    version: str,  # String com a versão atual
    part: int = 2,  # Parte da versão que será incrementada
) -> str:  # Retorna a versão atualizada
    version = version.split(".")
    version[part] = str(int(version[part]) + 1)
    for i in range(part + 1, 3):
        version[i] = "0"
    return ".".join(version)

# %% ..\nbs\main.ipynb 4
def get_modtimes(
    pasta: Union[str, Path],  # Pasta onde estão os arquivos esperados de monitoramento
) -> dict:    # Retorna o mtime de todos os arquivos pertinentes da pasta
    """
    Retorna a data de modificação dos arquivos de dados contidos na pasta
    """
    # Pasta
    pasta = Path(pasta)
    if not pasta.is_dir():
        raise FileNotFoundError(f"Pasta {pasta} não encontrada")
    # Arquivos
    if not (base := pasta / "base.parquet.gzip").is_file():
        raise FileNotFoundError(f"Arquivo {base} não encontrado")
    if not (aero := pasta / "aero.parquet.gzip").is_file():
        raise FileNotFoundError(f"Arquivo {aero} não encontrado")

    # Modificação
    mod_base = datetime.fromtimestamp(base.stat().st_mtime).strftime(
        "%d/%m/%Y %H:%M:%S"
    )
    mod_aero = datetime.fromtimestamp(aero.stat().st_mtime).strftime(
        "%d/%m/%Y %H:%M:%S"
    )
    
    return {
        "ANATEL": mod_base,
        "AERONAUTICA": mod_aero,
    }

# %% ..\nbs\main.ipynb 5
def get_db(
    path: Union[str, Path],  # Pasta onde salvar os arquivos",
    connSQL: pyodbc.Connection = None,  # Objeto de conexão do banco SQL Server
    clientMongoDB: MongoClient = None,  # Objeto de conexão do banco MongoDB
) -> pd.DataFrame:  # Retorna o DataFrame com as bases da Anatel e da Aeronáutica
    """Lê e opcionalmente atualiza as bases da Anatel, mescla as bases da Aeronáutica, salva e retorna o arquivo
    A atualização junto às bases de dados da Anatel é efetuada caso ambos objetos de banco `connSQL` e `clientMongoDB` forem válidos`
    """
    dest = Path(path)
    dest.mkdir(parents=True, exist_ok=True)
    print(":scroll:[green]Lendo as bases de dados da Anatel...")
#     if not all([connSQL, clientMongoDB]):
#         raise ConnectionError(f"Verifique os conectores de banco de dados: {connSQL} e {clientMongoDB}")
    rd = read_base(path, connSQL, clientMongoDB)
    rd["#Estação"] = rd["Número_Estação"]
    rd.loc[rd.Multiplicidade != "1", "#Estação"] = (
        rd.loc[rd.Multiplicidade != "1", "Número_Estação"]
        + "+"
        + rd.loc[rd.Multiplicidade != "1", "Multiplicidade"]
    )
    rd["Descrição"] = (
        "["
        + rd.Fonte.fillna("NI")
        + "] "
        + rd.Status.fillna("NI")
        + ", "
        + rd.Classe.fillna("NI")
        + ", "
        + rd.Entidade.fillna("NI").str.title()
        + " ("
        + rd.Fistel.fillna("NI")
        + ", "
        + rd["#Estação"].fillna("NI")
        + "), "
        + rd.Município.fillna("NI")
        + "/"
        + rd.UF.fillna("NI")
    )

    rd.loc[rd.Coords_Valida == "0", "Descrição"] = (
        rd.loc[rd.Coords_Valida == "0", "Descrição"] + "*"
    )

    export_columns = [
        "Frequência",
        "Latitude",
        "Longitude",
        "Descrição",
        "Num_Serviço",
        "Número_Estação",
        "Classe_Emissão",
        "Largura_Emissão(kHz)",
    ]
    rd = rd.loc[:, export_columns]
    rd.columns = APP_ANALISE
    print(":airplane:[blue]Requisitando os dados da Aeronáutica.")
    aero = read_aero(path, update=True)
    print(":spoon:[yellow]Mesclando os dados da Aeronáutica.")
    rd = merge_close_rows(rd, aero)
    print(":card_file_box:[green]Salvando os arquivos...")
    versiondb = json.loads((dest.parent / "VersionFile.json").read_text())
    mod_times = get_modtimes(path)
    mod_times["ReleaseDate"] = datetime.today().strftime("%d/%m/%Y %H:%M:%S")
    for c in ["Latitude", "Longitude"]:
        rd.loc[:, c] = rd.loc[:, c].fillna(-1).astype("float32")
    rd["Frequency"] = rd["Frequency"].astype("float64")
    rd.loc[rd.Description == '', 'Description'] = pd.NA
    rd["Description"] = rd["Description"].astype("string").fillna("NI")
    rd.loc[rd.Service == '', 'Service'] = pd.NA
    rd["Service"] = rd.Service.fillna("-1").astype("int16")
    rd.loc[rd.Station == "", "Station"] = pd.NA
    rd["Station"] = rd.Station.fillna("-1").astype("int32")
    rd.loc[rd.BW == "", "BW"] = pd.NA
    rd["BW"] = rd["BW"].astype("float32").fillna(-1)
    rd["Class"] = rd.Class.fillna("NI").astype("category")
    rd = (
        rd.drop_duplicates(keep="first")
        .sort_values(by=["Frequency", "Latitude", "Longitude"])
        .reset_index(drop=True)
    )
    rd["Id"] = [f"#{i+1}" for i in rd.index]
    rd["Id"] = rd.Id.astype("string")
    rd = rd.loc[
        :,
        [
            "Id",
            "Frequency",
            "Latitude",
            "Longitude",
            "Description",
            "Service",
            "Station",
            "Class",
            "BW",
        ],
    ]
    rd.to_parquet(f"{dest}/AnatelDB.parquet.gzip", compression="gzip", index=False)
    versiondb["anateldb"].update(mod_times)
    json.dump(versiondb, (dest.parent / "VersionFile.json").open("w"))
    print("Sucesso :zap:")
    return rd
