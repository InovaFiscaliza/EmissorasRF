# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01b_datasources.ipynb.

# %% auto 0
__all__ = ['SQLSERVER_PARAMS', 'MONGO_URI', 'Base', 'Sitarweb', 'Mosaico', 'SRD', 'Telecom', 'SMP']

# %% ../nbs/01b_datasources.ipynb 3
import os
import re
from dataclasses import dataclass
from decimal import Decimal, getcontext
from functools import cached_property
from typing import Tuple, Union

import pandas as pd
from dotenv import find_dotenv, load_dotenv
from fastcore.foundation import GetAttr
from fastcore.xtras import Path
from pyarrow import ArrowInvalid, ArrowTypeError

from .connectors import MongoDB, SQLServer
from extracao.constants import (
    BW,
    BW_MAP,
    COLS_SMP,
    COLS_SRD,
    COLS_TELECOM,
    COLUNAS,
    MONGO_SMP,
    MONGO_SRD,
    MONGO_TELECOM,
    PROJECTION_SRD,
    RE_BW,
)

# %% ../nbs/01b_datasources.ipynb 4
getcontext().prec = 5
load_dotenv(find_dotenv())

# %% ../nbs/01b_datasources.ipynb 6
SQLSERVER_PARAMS = dict(
    driver="{ODBC Driver 17 for SQL Server}",
    server="ANATELBDRO05",
    database="SITARWEB",
    trusted_conn=True,
    mult_results=True,
    username=None,
    password=None,
    timeout=1000,
)

MONGO_URI = os.environ.get("MONGO_URI")


@dataclass
class Base:
    folder: Union[str, Path] = Path(__file__).parent / "dados"

    def _read(self, stem: str) -> pd.DataFrame:
        """Lê o dataframe formado por self.folder / self.stem.parquet.gzip"""
        file = Path(f"{self.folder}/{stem}.parquet.gzip")
        try:
            df = pd.read_parquet(file)
        except (ArrowInvalid, FileNotFoundError) as e:
            raise e(f"Error when reading {file}") from e
        return df

    @cached_property
    def df(self):
        raise NotImplementedError

    @cached_property
    def extract(self):
        raise NotImplementedError

    def _format(self, df: pd.DataFrame) -> pd.DataFrame:
        raise NotImplementedError

    def update(self):
        raise NotImplementedError

    def save(self, folder: Union[str, Path]) -> pd.DataFrame:
        """Format, Save and return a dataframe"""
        df = self.df.astype("string")
        df = df.drop_duplicates(keep="first", ignore_index=True)
        try:
            file = Path(f"{folder}/{self.stem}.parquet.gzip")
            df.to_parquet(file, compression="gzip", index=False)
        except (ArrowInvalid, ArrowTypeError) as e:
            raise e(f"Não foi possível salvar o arquivo parquet {file}") from e
        return df

# %% ../nbs/01b_datasources.ipynb 7
class Sitarweb(Base, GetAttr):
    def __init__(self, sql_params: dict = SQLSERVER_PARAMS):
        self.default = SQLServer(sql_params)

# %% ../nbs/01b_datasources.ipynb 8
class Mosaico(Base, GetAttr):
    def __init__(self, mongo_uri: str = MONGO_URI):
        self.database = "sms"
        self.default = MongoDB(mongo_uri)

    def _extract(self, collection: str, pipeline: list):
        client = self.connect()
        database = client[self.database]
        collection = database[collection]
        result = collection.aggregate(pipeline)
        df = pd.DataFrame(list(result))
        df = df.drop(columns=["_id"])
        return df.astype("string")

    @staticmethod
    def parse_bw(
        bw: str,  # Designação de Emissão (Largura + Classe) codificada como string
    ) -> Tuple[str, str]:  # Largura e Classe de Emissão
        """Parse the bandwidth string"""
        if match := re.match(RE_BW, bw):
            multiplier = BW[match[2]]
            if mantissa := match[3]:
                number = float(f"{match[1]}.{mantissa}")
            else:
                number = float(match[1])
            classe = match[4]
            return str(multiplier * number), str(classe)
        return pd.NA, pd.NA

    @staticmethod
    def split_designacao(
        df: pd.DataFrame,  # DataFrame com coluna original DesignacaoEmissao
    ) -> (
        pd.DataFrame
    ):  # DataFrame com novas colunas Largura_Emissão(kHz) e Classe_Emissão
        """Parse a bandwidth string to extract the numerical component and a character class"""
        df["Designação_Emissão"] = (
            df["Designação_Emissão"].str.replace(",", " ").str.strip().str.upper()
        )
        df["Designação_Emissão"] = df["Designação_Emissão"].str.split(" ")
        df = df.explode("Designação_Emissão")
        df = df[df["Designação_Emissão"] != "/"]  # Removes empty rows
        df[["Largura_Emissão(kHz)", "Classe_Emissão"]] = (
            df["Designação_Emissão"].apply(Mosaico.parse_bw).tolist()
        )
        df[["Largura_Emissão(kHz)", "Classe_Emissão"]] = df[
            ["Largura_Emissão(kHz)", "Classe_Emissão"]
        ].astype("string")
        return df.drop("Designação_Emissão", axis=1)

    def extract(self) -> pd.DataFrame:
        raise NotImplementedError

# %% ../nbs/01b_datasources.ipynb 9
class SRD(GetAttr):
    """Classe para encapsular a lógica de extração de Radiodifusão"""

    def __init__(self, mongo_uri: str = MONGO_URI) -> None:
        self.stem = "srd"
        self.default = Mosaico(mongo_uri)
        self.collection = "srd"
        self.query = MONGO_SRD
        self.projection = PROJECTION_SRD
        self.columns = COLS_SRD

    @cached_property
    def df(self) -> pd.DataFrame:
        return self._read(self.stem)

    @cached_property
    def extract(self) -> pd.DataFrame:
        pipeline = [
            # match the documents that satisfy your query
            {"$match": self.query},
            # project the fields that you want to keep
            {"$project": self.projection},
        ]
        df = self._extract(self.collection, pipeline)
        df.loc[df["estacao"] == "[]", "estacao"] = "{}"
        cols = ["srd_planobasico", "estacao", "habilitacao", "Status"]
        for col in cols:
            df = df.join(pd.json_normalize(df[col].apply(eval)))
        df = df.drop(columns=cols)
        # Substitui strings vazias e somente com espaços por nulo
        return df.replace(r"^\s*$", pd.NA, regex=True)

    def _format(
        self,
        df: pd.DataFrame,  # DataFrame com os dados de Estações e Plano_Básico mesclados
    ) -> pd.DataFrame:  # DataFrame com os dados mesclados e limpos
        """Clean the merged dataframe with the data from the MOSAICO page"""
        df = df.rename(columns=self.columns)
        df = df[
            df.Status.str.contains("-C1$|-C2$|-C3$|-C4$|-C7|-C98$", na=False)
        ].reset_index(drop=True)
        df["Frequência"] = (
            df.Frequência.astype("string").str.replace(",", ".").astype("float")
        )
        df = df.dropna(subset="Frequência", ignore_index=True)
        df.loc[df["Num_Serviço"] == "205", "Frequência"] = df.loc[
            df["Num_Serviço"] == "205", "Frequência"
        ].apply(lambda x: Decimal(x) / Decimal(1000))
        df["Validade_RF"] = df.Validade_RF.astype("string").str.slice(0, 10)
        df["Fonte"] = "MOS"
        df["Num_Serviço"] = df["Num_Serviço"].fillna("")
        df["Designação_Emissão"] = (
            df.Num_Serviço.astype("string").fillna("").map(BW_MAP)
        )
        df = self.split_designacao(df)
        df["Multiplicidade"] = 1
        return df.loc[:, COLUNAS]

    def update(self):
        self.df = self._format(self.extract)

# %% ../nbs/01b_datasources.ipynb 14
class Telecom(GetAttr):
    """Classe para encapsular a lógica de extração dos serviços de Telecomunições distintos de SMP"""

    def __init__(self, mongo_uri: str = MONGO_URI) -> None:
        self.default = Mosaico(mongo_uri)
        self.collection = "licenciamento"
        self.query = MONGO_TELECOM
        self.columns = COLS_TELECOM

    def format(self):
        pass

# %% ../nbs/01b_datasources.ipynb 15
class SMP(GetAttr):
    """Classe para encapsular a lógica de extração do SMP"""

    def __init__(self, mongo_uri: str = MONGO_URI) -> None:
        self.default = Mosaico(mongo_uri)
        self.collection = "licenciamento"
        self.query = MONGO_SMP
        self.columns = COLS_SMP
